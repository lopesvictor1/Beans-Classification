{"cells":[{"cell_type":"markdown","metadata":{"id":"VMpZC5eq6HNR"},"source":["Experimento 6 - KNN Imputer, MAD outlier detection, min max normalization, MLP classifier"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":25912,"status":"ok","timestamp":1704300823555,"user":{"displayName":"Victor Hugo Schneider Lopes","userId":"10992764016890176856"},"user_tz":180},"id":"cP53TLVS5xq-"},"outputs":[],"source":["import pandas as pd\n","import seaborn as sns\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn.objects as so\n","from ucimlrepo import fetch_ucirepo"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":479,"status":"ok","timestamp":1704300824021,"user":{"displayName":"Victor Hugo Schneider Lopes","userId":"10992764016890176856"},"user_tz":180},"id":"0owuQnJm6Vl5"},"outputs":[],"source":["beans = fetch_ucirepo(id=602)\n","df = beans.data.features\n","targets = beans.data.targets"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1704300824023,"user":{"displayName":"Victor Hugo Schneider Lopes","userId":"10992764016890176856"},"user_tz":180},"id":"_jMLf_dB6aIn"},"outputs":[],"source":["cols = ['Area', 'Perimeter', 'MajorAxisLength', 'MinorAxisLength', 'AspectRatio', 'Eccentricity', 'ConvexArea', 'EquivDiameter', 'Extent', 'Solidity', 'Roundness', 'Compactness', 'ShapeFactor1', 'ShapeFactor2', 'ShapeFactor3', 'ShapeFactor4']"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11294,"status":"ok","timestamp":1704300835306,"user":{"displayName":"Victor Hugo Schneider Lopes","userId":"10992764016890176856"},"user_tz":180},"id":"dCOP0sV96rrX","outputId":"73372595-cca5-454a-ddfb-4becb07c2780"},"outputs":[],"source":["import random\n","\n","#Introducing Missing values (5%)\n","\n","for index, i in enumerate(df):\n","  for jndex, j in enumerate(df[i]):\n","    if random.randint(0,100) < 5:\n","      df.loc[jndex,i] = np.NaN"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32,"status":"ok","timestamp":1704300835308,"user":{"displayName":"Victor Hugo Schneider Lopes","userId":"10992764016890176856"},"user_tz":180},"id":"eUet-44k838X","outputId":"779578ed-262a-4e83-c6fe-03232cc6447e"},"outputs":[{"data":{"text/plain":["Area               687\n","Perimeter          661\n","MajorAxisLength    646\n","MinorAxisLength    717\n","AspectRatio        680\n","Eccentricity       648\n","ConvexArea         677\n","EquivDiameter      636\n","Extent             659\n","Solidity           715\n","Roundness          666\n","Compactness        654\n","ShapeFactor1       666\n","ShapeFactor2       636\n","ShapeFactor3       664\n","ShapeFactor4       651\n","dtype: int64"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["df.isna().sum()"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":444},"executionInfo":{"elapsed":31,"status":"ok","timestamp":1704300835311,"user":{"displayName":"Victor Hugo Schneider Lopes","userId":"10992764016890176856"},"user_tz":180},"id":"U7Qgx3nODiaS","outputId":"3cee363c-a55d-44d1-9da2-3975ad081895"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Area</th>\n","      <th>Perimeter</th>\n","      <th>MajorAxisLength</th>\n","      <th>MinorAxisLength</th>\n","      <th>AspectRatio</th>\n","      <th>Eccentricity</th>\n","      <th>ConvexArea</th>\n","      <th>EquivDiameter</th>\n","      <th>Extent</th>\n","      <th>Solidity</th>\n","      <th>Roundness</th>\n","      <th>Compactness</th>\n","      <th>ShapeFactor1</th>\n","      <th>ShapeFactor2</th>\n","      <th>ShapeFactor3</th>\n","      <th>ShapeFactor4</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>28395.0</td>\n","      <td>610.291</td>\n","      <td>208.178117</td>\n","      <td>173.888747</td>\n","      <td>1.197191</td>\n","      <td>0.549812</td>\n","      <td>NaN</td>\n","      <td>190.141097</td>\n","      <td>0.763923</td>\n","      <td>0.988856</td>\n","      <td>0.958027</td>\n","      <td>0.913358</td>\n","      <td>0.007332</td>\n","      <td>0.003147</td>\n","      <td>0.834222</td>\n","      <td>0.998724</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>28734.0</td>\n","      <td>638.018</td>\n","      <td>200.524796</td>\n","      <td>182.734419</td>\n","      <td>1.097356</td>\n","      <td>0.411785</td>\n","      <td>29172.0</td>\n","      <td>191.272751</td>\n","      <td>0.783968</td>\n","      <td>0.984986</td>\n","      <td>0.887034</td>\n","      <td>0.953861</td>\n","      <td>0.006979</td>\n","      <td>0.003564</td>\n","      <td>0.909851</td>\n","      <td>0.998430</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>29380.0</td>\n","      <td>624.110</td>\n","      <td>212.826130</td>\n","      <td>175.931143</td>\n","      <td>1.209713</td>\n","      <td>0.562727</td>\n","      <td>29690.0</td>\n","      <td>193.410904</td>\n","      <td>0.778113</td>\n","      <td>NaN</td>\n","      <td>0.947849</td>\n","      <td>0.908774</td>\n","      <td>0.007244</td>\n","      <td>0.003048</td>\n","      <td>0.825871</td>\n","      <td>0.999066</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>30008.0</td>\n","      <td>645.884</td>\n","      <td>NaN</td>\n","      <td>182.516516</td>\n","      <td>1.153638</td>\n","      <td>0.498616</td>\n","      <td>NaN</td>\n","      <td>195.467062</td>\n","      <td>0.782681</td>\n","      <td>0.976696</td>\n","      <td>0.903936</td>\n","      <td>0.928329</td>\n","      <td>NaN</td>\n","      <td>0.003215</td>\n","      <td>0.861794</td>\n","      <td>0.994199</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>30140.0</td>\n","      <td>620.134</td>\n","      <td>201.847882</td>\n","      <td>190.279279</td>\n","      <td>1.060798</td>\n","      <td>0.333680</td>\n","      <td>30417.0</td>\n","      <td>195.896503</td>\n","      <td>0.773098</td>\n","      <td>0.990893</td>\n","      <td>0.984877</td>\n","      <td>0.970516</td>\n","      <td>0.006697</td>\n","      <td>0.003665</td>\n","      <td>0.941900</td>\n","      <td>0.999166</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>13606</th>\n","      <td>42097.0</td>\n","      <td>759.696</td>\n","      <td>288.721612</td>\n","      <td>185.944705</td>\n","      <td>1.552728</td>\n","      <td>0.765002</td>\n","      <td>42508.0</td>\n","      <td>231.515799</td>\n","      <td>0.714574</td>\n","      <td>0.990331</td>\n","      <td>0.916603</td>\n","      <td>0.801865</td>\n","      <td>0.006858</td>\n","      <td>0.001749</td>\n","      <td>0.642988</td>\n","      <td>0.998385</td>\n","    </tr>\n","    <tr>\n","      <th>13607</th>\n","      <td>42101.0</td>\n","      <td>757.499</td>\n","      <td>281.576392</td>\n","      <td>190.713136</td>\n","      <td>NaN</td>\n","      <td>0.735702</td>\n","      <td>42494.0</td>\n","      <td>231.526798</td>\n","      <td>0.799943</td>\n","      <td>0.990752</td>\n","      <td>0.922015</td>\n","      <td>0.822252</td>\n","      <td>0.006688</td>\n","      <td>0.001886</td>\n","      <td>0.676099</td>\n","      <td>0.998219</td>\n","    </tr>\n","    <tr>\n","      <th>13608</th>\n","      <td>42139.0</td>\n","      <td>759.321</td>\n","      <td>281.539928</td>\n","      <td>191.187979</td>\n","      <td>1.472582</td>\n","      <td>0.734065</td>\n","      <td>42569.0</td>\n","      <td>231.631261</td>\n","      <td>0.729932</td>\n","      <td>NaN</td>\n","      <td>0.918424</td>\n","      <td>0.822730</td>\n","      <td>0.006681</td>\n","      <td>0.001888</td>\n","      <td>0.676884</td>\n","      <td>0.996767</td>\n","    </tr>\n","    <tr>\n","      <th>13609</th>\n","      <td>42147.0</td>\n","      <td>763.779</td>\n","      <td>283.382636</td>\n","      <td>190.275731</td>\n","      <td>1.489326</td>\n","      <td>0.741055</td>\n","      <td>42667.0</td>\n","      <td>231.653247</td>\n","      <td>0.705389</td>\n","      <td>0.987813</td>\n","      <td>0.907906</td>\n","      <td>0.817457</td>\n","      <td>0.006724</td>\n","      <td>0.001852</td>\n","      <td>NaN</td>\n","      <td>0.995222</td>\n","    </tr>\n","    <tr>\n","      <th>13610</th>\n","      <td>42159.0</td>\n","      <td>NaN</td>\n","      <td>295.142741</td>\n","      <td>182.204716</td>\n","      <td>1.619841</td>\n","      <td>0.786693</td>\n","      <td>42600.0</td>\n","      <td>231.686223</td>\n","      <td>0.788962</td>\n","      <td>0.989648</td>\n","      <td>0.888380</td>\n","      <td>0.784997</td>\n","      <td>0.007001</td>\n","      <td>0.001640</td>\n","      <td>0.616221</td>\n","      <td>0.998180</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>13611 rows Ã— 16 columns</p>\n","</div>"],"text/plain":["          Area  Perimeter  MajorAxisLength  MinorAxisLength  AspectRatio  \\\n","0      28395.0    610.291       208.178117       173.888747     1.197191   \n","1      28734.0    638.018       200.524796       182.734419     1.097356   \n","2      29380.0    624.110       212.826130       175.931143     1.209713   \n","3      30008.0    645.884              NaN       182.516516     1.153638   \n","4      30140.0    620.134       201.847882       190.279279     1.060798   \n","...        ...        ...              ...              ...          ...   \n","13606  42097.0    759.696       288.721612       185.944705     1.552728   \n","13607  42101.0    757.499       281.576392       190.713136          NaN   \n","13608  42139.0    759.321       281.539928       191.187979     1.472582   \n","13609  42147.0    763.779       283.382636       190.275731     1.489326   \n","13610  42159.0        NaN       295.142741       182.204716     1.619841   \n","\n","       Eccentricity  ConvexArea  EquivDiameter    Extent  Solidity  Roundness  \\\n","0          0.549812         NaN     190.141097  0.763923  0.988856   0.958027   \n","1          0.411785     29172.0     191.272751  0.783968  0.984986   0.887034   \n","2          0.562727     29690.0     193.410904  0.778113       NaN   0.947849   \n","3          0.498616         NaN     195.467062  0.782681  0.976696   0.903936   \n","4          0.333680     30417.0     195.896503  0.773098  0.990893   0.984877   \n","...             ...         ...            ...       ...       ...        ...   \n","13606      0.765002     42508.0     231.515799  0.714574  0.990331   0.916603   \n","13607      0.735702     42494.0     231.526798  0.799943  0.990752   0.922015   \n","13608      0.734065     42569.0     231.631261  0.729932       NaN   0.918424   \n","13609      0.741055     42667.0     231.653247  0.705389  0.987813   0.907906   \n","13610      0.786693     42600.0     231.686223  0.788962  0.989648   0.888380   \n","\n","       Compactness  ShapeFactor1  ShapeFactor2  ShapeFactor3  ShapeFactor4  \n","0         0.913358      0.007332      0.003147      0.834222      0.998724  \n","1         0.953861      0.006979      0.003564      0.909851      0.998430  \n","2         0.908774      0.007244      0.003048      0.825871      0.999066  \n","3         0.928329           NaN      0.003215      0.861794      0.994199  \n","4         0.970516      0.006697      0.003665      0.941900      0.999166  \n","...            ...           ...           ...           ...           ...  \n","13606     0.801865      0.006858      0.001749      0.642988      0.998385  \n","13607     0.822252      0.006688      0.001886      0.676099      0.998219  \n","13608     0.822730      0.006681      0.001888      0.676884      0.996767  \n","13609     0.817457      0.006724      0.001852           NaN      0.995222  \n","13610     0.784997      0.007001      0.001640      0.616221      0.998180  \n","\n","[13611 rows x 16 columns]"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["df"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":444},"executionInfo":{"elapsed":871,"status":"ok","timestamp":1704300836156,"user":{"displayName":"Victor Hugo Schneider Lopes","userId":"10992764016890176856"},"user_tz":180},"id":"WJH40wejA9LZ","outputId":"9b61147a-873a-41d1-f9b0-7b4227ced5d2"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Area</th>\n","      <th>Perimeter</th>\n","      <th>MajorAxisLength</th>\n","      <th>MinorAxisLength</th>\n","      <th>AspectRatio</th>\n","      <th>Eccentricity</th>\n","      <th>ConvexArea</th>\n","      <th>EquivDiameter</th>\n","      <th>Extent</th>\n","      <th>Solidity</th>\n","      <th>Roundness</th>\n","      <th>Compactness</th>\n","      <th>ShapeFactor1</th>\n","      <th>ShapeFactor2</th>\n","      <th>ShapeFactor3</th>\n","      <th>ShapeFactor4</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>28395.0</td>\n","      <td>610.291</td>\n","      <td>208.178117</td>\n","      <td>173.888747</td>\n","      <td>1.197191</td>\n","      <td>0.549812</td>\n","      <td>28024.2</td>\n","      <td>190.141097</td>\n","      <td>0.763923</td>\n","      <td>0.988856</td>\n","      <td>0.958027</td>\n","      <td>0.913358</td>\n","      <td>0.007332</td>\n","      <td>0.003147</td>\n","      <td>0.834222</td>\n","      <td>0.998724</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>28734.0</td>\n","      <td>638.018</td>\n","      <td>200.524796</td>\n","      <td>182.734419</td>\n","      <td>1.097356</td>\n","      <td>0.411785</td>\n","      <td>29172.0</td>\n","      <td>191.272751</td>\n","      <td>0.783968</td>\n","      <td>0.984986</td>\n","      <td>0.887034</td>\n","      <td>0.953861</td>\n","      <td>0.006979</td>\n","      <td>0.003564</td>\n","      <td>0.909851</td>\n","      <td>0.998430</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>29380.0</td>\n","      <td>624.110</td>\n","      <td>212.826130</td>\n","      <td>175.931143</td>\n","      <td>1.209713</td>\n","      <td>0.562727</td>\n","      <td>29690.0</td>\n","      <td>193.410904</td>\n","      <td>0.778113</td>\n","      <td>0.989977</td>\n","      <td>0.947849</td>\n","      <td>0.908774</td>\n","      <td>0.007244</td>\n","      <td>0.003048</td>\n","      <td>0.825871</td>\n","      <td>0.999066</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>30008.0</td>\n","      <td>645.884</td>\n","      <td>238.443731</td>\n","      <td>182.516516</td>\n","      <td>1.153638</td>\n","      <td>0.498616</td>\n","      <td>34862.4</td>\n","      <td>195.467062</td>\n","      <td>0.782681</td>\n","      <td>0.976696</td>\n","      <td>0.903936</td>\n","      <td>0.928329</td>\n","      <td>0.006944</td>\n","      <td>0.003215</td>\n","      <td>0.861794</td>\n","      <td>0.994199</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>30140.0</td>\n","      <td>620.134</td>\n","      <td>201.847882</td>\n","      <td>190.279279</td>\n","      <td>1.060798</td>\n","      <td>0.333680</td>\n","      <td>30417.0</td>\n","      <td>195.896503</td>\n","      <td>0.773098</td>\n","      <td>0.990893</td>\n","      <td>0.984877</td>\n","      <td>0.970516</td>\n","      <td>0.006697</td>\n","      <td>0.003665</td>\n","      <td>0.941900</td>\n","      <td>0.999166</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>13606</th>\n","      <td>42097.0</td>\n","      <td>759.696</td>\n","      <td>288.721612</td>\n","      <td>185.944705</td>\n","      <td>1.552728</td>\n","      <td>0.765002</td>\n","      <td>42508.0</td>\n","      <td>231.515799</td>\n","      <td>0.714574</td>\n","      <td>0.990331</td>\n","      <td>0.916603</td>\n","      <td>0.801865</td>\n","      <td>0.006858</td>\n","      <td>0.001749</td>\n","      <td>0.642988</td>\n","      <td>0.998385</td>\n","    </tr>\n","    <tr>\n","      <th>13607</th>\n","      <td>42101.0</td>\n","      <td>757.499</td>\n","      <td>281.576392</td>\n","      <td>190.713136</td>\n","      <td>1.546565</td>\n","      <td>0.735702</td>\n","      <td>42494.0</td>\n","      <td>231.526798</td>\n","      <td>0.799943</td>\n","      <td>0.990752</td>\n","      <td>0.922015</td>\n","      <td>0.822252</td>\n","      <td>0.006688</td>\n","      <td>0.001886</td>\n","      <td>0.676099</td>\n","      <td>0.998219</td>\n","    </tr>\n","    <tr>\n","      <th>13608</th>\n","      <td>42139.0</td>\n","      <td>759.321</td>\n","      <td>281.539928</td>\n","      <td>191.187979</td>\n","      <td>1.472582</td>\n","      <td>0.734065</td>\n","      <td>42569.0</td>\n","      <td>231.631261</td>\n","      <td>0.729932</td>\n","      <td>0.988311</td>\n","      <td>0.918424</td>\n","      <td>0.822730</td>\n","      <td>0.006681</td>\n","      <td>0.001888</td>\n","      <td>0.676884</td>\n","      <td>0.996767</td>\n","    </tr>\n","    <tr>\n","      <th>13609</th>\n","      <td>42147.0</td>\n","      <td>763.779</td>\n","      <td>283.382636</td>\n","      <td>190.275731</td>\n","      <td>1.489326</td>\n","      <td>0.741055</td>\n","      <td>42667.0</td>\n","      <td>231.653247</td>\n","      <td>0.705389</td>\n","      <td>0.987813</td>\n","      <td>0.907906</td>\n","      <td>0.817457</td>\n","      <td>0.006724</td>\n","      <td>0.001852</td>\n","      <td>0.633767</td>\n","      <td>0.995222</td>\n","    </tr>\n","    <tr>\n","      <th>13610</th>\n","      <td>42159.0</td>\n","      <td>779.060</td>\n","      <td>295.142741</td>\n","      <td>182.204716</td>\n","      <td>1.619841</td>\n","      <td>0.786693</td>\n","      <td>42600.0</td>\n","      <td>231.686223</td>\n","      <td>0.788962</td>\n","      <td>0.989648</td>\n","      <td>0.888380</td>\n","      <td>0.784997</td>\n","      <td>0.007001</td>\n","      <td>0.001640</td>\n","      <td>0.616221</td>\n","      <td>0.998180</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>13611 rows Ã— 16 columns</p>\n","</div>"],"text/plain":["          Area  Perimeter  MajorAxisLength  MinorAxisLength  AspectRatio  \\\n","0      28395.0    610.291       208.178117       173.888747     1.197191   \n","1      28734.0    638.018       200.524796       182.734419     1.097356   \n","2      29380.0    624.110       212.826130       175.931143     1.209713   \n","3      30008.0    645.884       238.443731       182.516516     1.153638   \n","4      30140.0    620.134       201.847882       190.279279     1.060798   \n","...        ...        ...              ...              ...          ...   \n","13606  42097.0    759.696       288.721612       185.944705     1.552728   \n","13607  42101.0    757.499       281.576392       190.713136     1.546565   \n","13608  42139.0    759.321       281.539928       191.187979     1.472582   \n","13609  42147.0    763.779       283.382636       190.275731     1.489326   \n","13610  42159.0    779.060       295.142741       182.204716     1.619841   \n","\n","       Eccentricity  ConvexArea  EquivDiameter    Extent  Solidity  Roundness  \\\n","0          0.549812     28024.2     190.141097  0.763923  0.988856   0.958027   \n","1          0.411785     29172.0     191.272751  0.783968  0.984986   0.887034   \n","2          0.562727     29690.0     193.410904  0.778113  0.989977   0.947849   \n","3          0.498616     34862.4     195.467062  0.782681  0.976696   0.903936   \n","4          0.333680     30417.0     195.896503  0.773098  0.990893   0.984877   \n","...             ...         ...            ...       ...       ...        ...   \n","13606      0.765002     42508.0     231.515799  0.714574  0.990331   0.916603   \n","13607      0.735702     42494.0     231.526798  0.799943  0.990752   0.922015   \n","13608      0.734065     42569.0     231.631261  0.729932  0.988311   0.918424   \n","13609      0.741055     42667.0     231.653247  0.705389  0.987813   0.907906   \n","13610      0.786693     42600.0     231.686223  0.788962  0.989648   0.888380   \n","\n","       Compactness  ShapeFactor1  ShapeFactor2  ShapeFactor3  ShapeFactor4  \n","0         0.913358      0.007332      0.003147      0.834222      0.998724  \n","1         0.953861      0.006979      0.003564      0.909851      0.998430  \n","2         0.908774      0.007244      0.003048      0.825871      0.999066  \n","3         0.928329      0.006944      0.003215      0.861794      0.994199  \n","4         0.970516      0.006697      0.003665      0.941900      0.999166  \n","...            ...           ...           ...           ...           ...  \n","13606     0.801865      0.006858      0.001749      0.642988      0.998385  \n","13607     0.822252      0.006688      0.001886      0.676099      0.998219  \n","13608     0.822730      0.006681      0.001888      0.676884      0.996767  \n","13609     0.817457      0.006724      0.001852      0.633767      0.995222  \n","13610     0.784997      0.007001      0.001640      0.616221      0.998180  \n","\n","[13611 rows x 16 columns]"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["#Imputing Missing Values with KNN Imputer\n","from sklearn.impute import KNNImputer as knni\n","\n","imputer = knni(n_neighbors=5)\n","df_imputed = pd.DataFrame(imputer.fit_transform(df), columns = df.columns)\n","df_imputed"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":42,"status":"ok","timestamp":1704300836158,"user":{"displayName":"Victor Hugo Schneider Lopes","userId":"10992764016890176856"},"user_tz":180},"id":"dsT5e4MCtxV0","outputId":"7a1a5dee-730a-41a9-a682-2cd6d1d181a4"},"outputs":[{"name":"stdout","output_type":"stream","text":["          Area Perimeter MajorAxisLength MinorAxisLength AspectRatio  \\\n","         count     count           count           count       count   \n","Class                                                                  \n","BARBUNYA  1322      1322            1322            1322        1322   \n","BOMBAY     522       522             522             522         522   \n","CALI      1630      1630            1630            1630        1630   \n","DERMASON  3546      3546            3546            3546        3546   \n","HOROZ     1928      1928            1928            1928        1928   \n","SEKER     2027      2027            2027            2027        2027   \n","SIRA      2636      2636            2636            2636        2636   \n","\n","         Eccentricity ConvexArea EquivDiameter Extent Solidity Roundness  \\\n","                count      count         count  count    count     count   \n","Class                                                                      \n","BARBUNYA         1322       1322          1322   1322     1322      1322   \n","BOMBAY            522        522           522    522      522       522   \n","CALI             1630       1630          1630   1630     1630      1630   \n","DERMASON         3546       3546          3546   3546     3546      3546   \n","HOROZ            1928       1928          1928   1928     1928      1928   \n","SEKER            2027       2027          2027   2027     2027      2027   \n","SIRA             2636       2636          2636   2636     2636      2636   \n","\n","         Compactness ShapeFactor1 ShapeFactor2 ShapeFactor3 ShapeFactor4  \n","               count        count        count        count        count  \n","Class                                                                     \n","BARBUNYA        1322         1322         1322         1322         1322  \n","BOMBAY           522          522          522          522          522  \n","CALI            1630         1630         1630         1630         1630  \n","DERMASON        3546         3546         3546         3546         3546  \n","HOROZ           1928         1928         1928         1928         1928  \n","SEKER           2027         2027         2027         2027         2027  \n","SIRA            2636         2636         2636         2636         2636  \n"]}],"source":["#adding the labels\n","df_imputed['Class'] = targets\n","df_pre_missing_values = df.copy()\n","print(df_imputed.groupby('Class').agg(['count']))\n","df_imputed['Class'] = df_imputed['Class'].transform(lambda x: 0 if x == 'BARBUNYA' else (1 if x == 'BOMBAY' else (2 if x == 'CALI' else (3 if x == 'DERMASON' else (4 if x == 'HOROZ' else (5 if x == 'SEKER' else 6))))))"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":818,"status":"ok","timestamp":1704300836943,"user":{"displayName":"Victor Hugo Schneider Lopes","userId":"10992764016890176856"},"user_tz":180},"id":"ML8h0BGivuxc","outputId":"4b37a046-5af9-4153-9123-9a0f7a6ccf7a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Pre Outlier Shape: (13611, 17)\n","[5 0 1 2 4 6 3]\n","Pos Outlier Shape: (12043, 17)\n"]}],"source":["#Outlier Removal with MAD\n","from scipy import stats\n","\n","print(f'Pre Outlier Shape: {df_imputed.shape}')\n","\n","df_no_outliers = df_imputed.copy()\n","print(df_no_outliers['Class'].unique())\n","for i in df_no_outliers['Class'].unique():\n","    class_unique = df_no_outliers[df_no_outliers['Class'] == i]\n","    for feature in class_unique:\n","      mad = 1.4826 * np.median(np.absolute(class_unique[feature] - class_unique[feature].median()))\n","      upper = class_unique[feature].median() + (3 * mad)\n","      lower = class_unique[feature].median() - (3 * mad)\n","      excluded_lower = pd.Series(class_unique[class_unique[feature] < lower].index)\n","      excluded_upper = pd.Series(class_unique[class_unique[feature] > upper].index)\n","      df_no_outliers.drop(excluded_lower.values, inplace = True, errors='ignore')\n","      df_no_outliers.drop(excluded_upper.values, inplace = True, errors='ignore')\n","\n","\n","print(f'Pos Outlier Shape: {df_no_outliers.shape}')"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":47,"status":"ok","timestamp":1704300836944,"user":{"displayName":"Victor Hugo Schneider Lopes","userId":"10992764016890176856"},"user_tz":180},"id":"LlYPv-ra64um","outputId":"d4602f4e-ae3c-4a4b-92b7-5d8f5ffb6f42"},"outputs":[{"name":"stdout","output_type":"stream","text":["         index  Area Perimeter MajorAxisLength MinorAxisLength AspectRatio  \\\n","         count count     count           count           count       count   \n","Class                                                                        \n","BARBUNYA  1194  1194      1194            1194            1194        1194   \n","BOMBAY     432   432       432             432             432         432   \n","CALI      1508  1508      1508            1508            1508        1508   \n","DERMASON  3188  3188      3188            3188            3188        3188   \n","HOROZ     1587  1587      1587            1587            1587        1587   \n","SEKER     1736  1736      1736            1736            1736        1736   \n","SIRA      2398  2398      2398            2398            2398        2398   \n","\n","         Eccentricity ConvexArea EquivDiameter Extent Solidity Roundness  \\\n","                count      count         count  count    count     count   \n","Class                                                                      \n","BARBUNYA         1194       1194          1194   1194     1194      1194   \n","BOMBAY            432        432           432    432      432       432   \n","CALI             1508       1508          1508   1508     1508      1508   \n","DERMASON         3188       3188          3188   3188     3188      3188   \n","HOROZ            1587       1587          1587   1587     1587      1587   \n","SEKER            1736       1736          1736   1736     1736      1736   \n","SIRA             2398       2398          2398   2398     2398      2398   \n","\n","         Compactness ShapeFactor1 ShapeFactor2 ShapeFactor3 ShapeFactor4  \n","               count        count        count        count        count  \n","Class                                                                     \n","BARBUNYA        1194         1194         1194         1194         1194  \n","BOMBAY           432          432          432          432          432  \n","CALI            1508         1508         1508         1508         1508  \n","DERMASON        3188         3188         3188         3188         3188  \n","HOROZ           1587         1587         1587         1587         1587  \n","SEKER           1736         1736         1736         1736         1736  \n","SIRA            2398         2398         2398         2398         2398  \n"]}],"source":["df_no_outliers['Class'] = df_no_outliers['Class'].transform(lambda x: 'BARBUNYA' if x == 0 else ('BOMBAY' if x == 1 else ('CALI' if x == 2 else ('DERMASON' if x == 3 else ('HOROZ' if x == 4 else ('SEKER' if x == 5 else 'SIRA'))))))\n","df_no_outliers = df_no_outliers.reset_index()\n","print(df_no_outliers.groupby('Class').agg(['count']))"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":444},"executionInfo":{"elapsed":38,"status":"ok","timestamp":1704300836945,"user":{"displayName":"Victor Hugo Schneider Lopes","userId":"10992764016890176856"},"user_tz":180},"id":"T8INyItCFB8j","outputId":"20e63003-f3a3-45ba-f409-947619171859"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Area</th>\n","      <th>Perimeter</th>\n","      <th>MajorAxisLength</th>\n","      <th>MinorAxisLength</th>\n","      <th>AspectRatio</th>\n","      <th>Eccentricity</th>\n","      <th>ConvexArea</th>\n","      <th>EquivDiameter</th>\n","      <th>Extent</th>\n","      <th>Solidity</th>\n","      <th>Roundness</th>\n","      <th>Compactness</th>\n","      <th>ShapeFactor1</th>\n","      <th>ShapeFactor2</th>\n","      <th>ShapeFactor3</th>\n","      <th>ShapeFactor4</th>\n","      <th>Class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>28395.0</td>\n","      <td>610.291</td>\n","      <td>208.178117</td>\n","      <td>173.888747</td>\n","      <td>1.197191</td>\n","      <td>0.549812</td>\n","      <td>28024.2</td>\n","      <td>190.141097</td>\n","      <td>0.763923</td>\n","      <td>0.988856</td>\n","      <td>0.958027</td>\n","      <td>0.913358</td>\n","      <td>0.007332</td>\n","      <td>0.003147</td>\n","      <td>0.834222</td>\n","      <td>0.998724</td>\n","      <td>SEKER</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>29380.0</td>\n","      <td>624.110</td>\n","      <td>212.826130</td>\n","      <td>175.931143</td>\n","      <td>1.209713</td>\n","      <td>0.562727</td>\n","      <td>29690.0</td>\n","      <td>193.410904</td>\n","      <td>0.778113</td>\n","      <td>0.989977</td>\n","      <td>0.947849</td>\n","      <td>0.908774</td>\n","      <td>0.007244</td>\n","      <td>0.003048</td>\n","      <td>0.825871</td>\n","      <td>0.999066</td>\n","      <td>SEKER</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>30279.0</td>\n","      <td>634.927</td>\n","      <td>212.560556</td>\n","      <td>181.510182</td>\n","      <td>1.171067</td>\n","      <td>0.520401</td>\n","      <td>30600.0</td>\n","      <td>196.347702</td>\n","      <td>0.775688</td>\n","      <td>0.989510</td>\n","      <td>0.943852</td>\n","      <td>0.923726</td>\n","      <td>0.007020</td>\n","      <td>0.003153</td>\n","      <td>0.853270</td>\n","      <td>0.999236</td>\n","      <td>SEKER</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>30519.0</td>\n","      <td>629.727</td>\n","      <td>212.996755</td>\n","      <td>182.737204</td>\n","      <td>1.165591</td>\n","      <td>0.513760</td>\n","      <td>30847.0</td>\n","      <td>197.124320</td>\n","      <td>0.770682</td>\n","      <td>0.989367</td>\n","      <td>0.967109</td>\n","      <td>0.925480</td>\n","      <td>0.006979</td>\n","      <td>0.003158</td>\n","      <td>0.856514</td>\n","      <td>0.998345</td>\n","      <td>SEKER</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>30685.0</td>\n","      <td>635.681</td>\n","      <td>213.534145</td>\n","      <td>171.715505</td>\n","      <td>1.165852</td>\n","      <td>0.514081</td>\n","      <td>31044.0</td>\n","      <td>197.659696</td>\n","      <td>0.771561</td>\n","      <td>0.988436</td>\n","      <td>0.954240</td>\n","      <td>0.925658</td>\n","      <td>0.006959</td>\n","      <td>0.003152</td>\n","      <td>0.856844</td>\n","      <td>0.998953</td>\n","      <td>SEKER</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>12038</th>\n","      <td>42097.0</td>\n","      <td>759.696</td>\n","      <td>288.721612</td>\n","      <td>185.944705</td>\n","      <td>1.552728</td>\n","      <td>0.765002</td>\n","      <td>42508.0</td>\n","      <td>231.515799</td>\n","      <td>0.714574</td>\n","      <td>0.990331</td>\n","      <td>0.916603</td>\n","      <td>0.801865</td>\n","      <td>0.006858</td>\n","      <td>0.001749</td>\n","      <td>0.642988</td>\n","      <td>0.998385</td>\n","      <td>DERMASON</td>\n","    </tr>\n","    <tr>\n","      <th>12039</th>\n","      <td>42101.0</td>\n","      <td>757.499</td>\n","      <td>281.576392</td>\n","      <td>190.713136</td>\n","      <td>1.546565</td>\n","      <td>0.735702</td>\n","      <td>42494.0</td>\n","      <td>231.526798</td>\n","      <td>0.799943</td>\n","      <td>0.990752</td>\n","      <td>0.922015</td>\n","      <td>0.822252</td>\n","      <td>0.006688</td>\n","      <td>0.001886</td>\n","      <td>0.676099</td>\n","      <td>0.998219</td>\n","      <td>DERMASON</td>\n","    </tr>\n","    <tr>\n","      <th>12040</th>\n","      <td>42139.0</td>\n","      <td>759.321</td>\n","      <td>281.539928</td>\n","      <td>191.187979</td>\n","      <td>1.472582</td>\n","      <td>0.734065</td>\n","      <td>42569.0</td>\n","      <td>231.631261</td>\n","      <td>0.729932</td>\n","      <td>0.988311</td>\n","      <td>0.918424</td>\n","      <td>0.822730</td>\n","      <td>0.006681</td>\n","      <td>0.001888</td>\n","      <td>0.676884</td>\n","      <td>0.996767</td>\n","      <td>DERMASON</td>\n","    </tr>\n","    <tr>\n","      <th>12041</th>\n","      <td>42147.0</td>\n","      <td>763.779</td>\n","      <td>283.382636</td>\n","      <td>190.275731</td>\n","      <td>1.489326</td>\n","      <td>0.741055</td>\n","      <td>42667.0</td>\n","      <td>231.653247</td>\n","      <td>0.705389</td>\n","      <td>0.987813</td>\n","      <td>0.907906</td>\n","      <td>0.817457</td>\n","      <td>0.006724</td>\n","      <td>0.001852</td>\n","      <td>0.633767</td>\n","      <td>0.995222</td>\n","      <td>DERMASON</td>\n","    </tr>\n","    <tr>\n","      <th>12042</th>\n","      <td>42159.0</td>\n","      <td>779.060</td>\n","      <td>295.142741</td>\n","      <td>182.204716</td>\n","      <td>1.619841</td>\n","      <td>0.786693</td>\n","      <td>42600.0</td>\n","      <td>231.686223</td>\n","      <td>0.788962</td>\n","      <td>0.989648</td>\n","      <td>0.888380</td>\n","      <td>0.784997</td>\n","      <td>0.007001</td>\n","      <td>0.001640</td>\n","      <td>0.616221</td>\n","      <td>0.998180</td>\n","      <td>DERMASON</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>12043 rows Ã— 17 columns</p>\n","</div>"],"text/plain":["          Area  Perimeter  MajorAxisLength  MinorAxisLength  AspectRatio  \\\n","0      28395.0    610.291       208.178117       173.888747     1.197191   \n","1      29380.0    624.110       212.826130       175.931143     1.209713   \n","2      30279.0    634.927       212.560556       181.510182     1.171067   \n","3      30519.0    629.727       212.996755       182.737204     1.165591   \n","4      30685.0    635.681       213.534145       171.715505     1.165852   \n","...        ...        ...              ...              ...          ...   \n","12038  42097.0    759.696       288.721612       185.944705     1.552728   \n","12039  42101.0    757.499       281.576392       190.713136     1.546565   \n","12040  42139.0    759.321       281.539928       191.187979     1.472582   \n","12041  42147.0    763.779       283.382636       190.275731     1.489326   \n","12042  42159.0    779.060       295.142741       182.204716     1.619841   \n","\n","       Eccentricity  ConvexArea  EquivDiameter    Extent  Solidity  Roundness  \\\n","0          0.549812     28024.2     190.141097  0.763923  0.988856   0.958027   \n","1          0.562727     29690.0     193.410904  0.778113  0.989977   0.947849   \n","2          0.520401     30600.0     196.347702  0.775688  0.989510   0.943852   \n","3          0.513760     30847.0     197.124320  0.770682  0.989367   0.967109   \n","4          0.514081     31044.0     197.659696  0.771561  0.988436   0.954240   \n","...             ...         ...            ...       ...       ...        ...   \n","12038      0.765002     42508.0     231.515799  0.714574  0.990331   0.916603   \n","12039      0.735702     42494.0     231.526798  0.799943  0.990752   0.922015   \n","12040      0.734065     42569.0     231.631261  0.729932  0.988311   0.918424   \n","12041      0.741055     42667.0     231.653247  0.705389  0.987813   0.907906   \n","12042      0.786693     42600.0     231.686223  0.788962  0.989648   0.888380   \n","\n","       Compactness  ShapeFactor1  ShapeFactor2  ShapeFactor3  ShapeFactor4  \\\n","0         0.913358      0.007332      0.003147      0.834222      0.998724   \n","1         0.908774      0.007244      0.003048      0.825871      0.999066   \n","2         0.923726      0.007020      0.003153      0.853270      0.999236   \n","3         0.925480      0.006979      0.003158      0.856514      0.998345   \n","4         0.925658      0.006959      0.003152      0.856844      0.998953   \n","...            ...           ...           ...           ...           ...   \n","12038     0.801865      0.006858      0.001749      0.642988      0.998385   \n","12039     0.822252      0.006688      0.001886      0.676099      0.998219   \n","12040     0.822730      0.006681      0.001888      0.676884      0.996767   \n","12041     0.817457      0.006724      0.001852      0.633767      0.995222   \n","12042     0.784997      0.007001      0.001640      0.616221      0.998180   \n","\n","          Class  \n","0         SEKER  \n","1         SEKER  \n","2         SEKER  \n","3         SEKER  \n","4         SEKER  \n","...         ...  \n","12038  DERMASON  \n","12039  DERMASON  \n","12040  DERMASON  \n","12041  DERMASON  \n","12042  DERMASON  \n","\n","[12043 rows x 17 columns]"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["df_no_outliers = df_no_outliers.drop(['index'], axis='columns')\n","df_no_outliers"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":444},"executionInfo":{"elapsed":32,"status":"ok","timestamp":1704300836946,"user":{"displayName":"Victor Hugo Schneider Lopes","userId":"10992764016890176856"},"user_tz":180},"id":"nSe3jkEjynF6","outputId":"55685acc-0fe5-484a-b204-b0843ad09458"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Area</th>\n","      <th>Perimeter</th>\n","      <th>MajorAxisLength</th>\n","      <th>MinorAxisLength</th>\n","      <th>AspectRatio</th>\n","      <th>Eccentricity</th>\n","      <th>ConvexArea</th>\n","      <th>EquivDiameter</th>\n","      <th>Extent</th>\n","      <th>Solidity</th>\n","      <th>Roundness</th>\n","      <th>Compactness</th>\n","      <th>ShapeFactor1</th>\n","      <th>ShapeFactor2</th>\n","      <th>ShapeFactor3</th>\n","      <th>ShapeFactor4</th>\n","      <th>Class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.033153</td>\n","      <td>0.061039</td>\n","      <td>0.031866</td>\n","      <td>0.130253</td>\n","      <td>0.096582</td>\n","      <td>0.293183</td>\n","      <td>0.033486</td>\n","      <td>0.074517</td>\n","      <td>0.688236</td>\n","      <td>0.765887</td>\n","      <td>0.896273</td>\n","      <td>0.860745</td>\n","      <td>0.669818</td>\n","      <td>0.904005</td>\n","      <td>0.809404</td>\n","      <td>0.948254</td>\n","      <td>SEKER</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.037765</td>\n","      <td>0.071341</td>\n","      <td>0.040616</td>\n","      <td>0.136911</td>\n","      <td>0.106074</td>\n","      <td>0.318656</td>\n","      <td>0.041178</td>\n","      <td>0.083000</td>\n","      <td>0.735054</td>\n","      <td>0.810988</td>\n","      <td>0.863948</td>\n","      <td>0.846023</td>\n","      <td>0.656551</td>\n","      <td>0.868804</td>\n","      <td>0.793221</td>\n","      <td>0.965812</td>\n","      <td>SEKER</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.041974</td>\n","      <td>0.079404</td>\n","      <td>0.040116</td>\n","      <td>0.155099</td>\n","      <td>0.076777</td>\n","      <td>0.235172</td>\n","      <td>0.045380</td>\n","      <td>0.090618</td>\n","      <td>0.727054</td>\n","      <td>0.792180</td>\n","      <td>0.851250</td>\n","      <td>0.894046</td>\n","      <td>0.622647</td>\n","      <td>0.905946</td>\n","      <td>0.846311</td>\n","      <td>0.974516</td>\n","      <td>SEKER</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.043098</td>\n","      <td>0.075528</td>\n","      <td>0.040937</td>\n","      <td>0.159099</td>\n","      <td>0.072625</td>\n","      <td>0.222073</td>\n","      <td>0.046520</td>\n","      <td>0.092633</td>\n","      <td>0.710536</td>\n","      <td>0.786432</td>\n","      <td>0.925119</td>\n","      <td>0.899681</td>\n","      <td>0.616450</td>\n","      <td>0.907893</td>\n","      <td>0.852597</td>\n","      <td>0.928794</td>\n","      <td>SEKER</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.043875</td>\n","      <td>0.079966</td>\n","      <td>0.041948</td>\n","      <td>0.123168</td>\n","      <td>0.072823</td>\n","      <td>0.222706</td>\n","      <td>0.047430</td>\n","      <td>0.094022</td>\n","      <td>0.713438</td>\n","      <td>0.748987</td>\n","      <td>0.884244</td>\n","      <td>0.900253</td>\n","      <td>0.613384</td>\n","      <td>0.905512</td>\n","      <td>0.853236</td>\n","      <td>0.960007</td>\n","      <td>SEKER</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>12038</th>\n","      <td>0.097306</td>\n","      <td>0.172413</td>\n","      <td>0.183479</td>\n","      <td>0.169555</td>\n","      <td>0.366116</td>\n","      <td>0.717622</td>\n","      <td>0.100364</td>\n","      <td>0.181854</td>\n","      <td>0.525427</td>\n","      <td>0.825214</td>\n","      <td>0.764705</td>\n","      <td>0.502647</td>\n","      <td>0.598174</td>\n","      <td>0.409626</td>\n","      <td>0.438857</td>\n","      <td>0.930881</td>\n","      <td>DERMASON</td>\n","    </tr>\n","    <tr>\n","      <th>12039</th>\n","      <td>0.097325</td>\n","      <td>0.170775</td>\n","      <td>0.170029</td>\n","      <td>0.185100</td>\n","      <td>0.361443</td>\n","      <td>0.659831</td>\n","      <td>0.100299</td>\n","      <td>0.181882</td>\n","      <td>0.807074</td>\n","      <td>0.842120</td>\n","      <td>0.781895</td>\n","      <td>0.568127</td>\n","      <td>0.572370</td>\n","      <td>0.457976</td>\n","      <td>0.503014</td>\n","      <td>0.922335</td>\n","      <td>DERMASON</td>\n","    </tr>\n","    <tr>\n","      <th>12040</th>\n","      <td>0.097503</td>\n","      <td>0.172133</td>\n","      <td>0.169960</td>\n","      <td>0.186648</td>\n","      <td>0.305356</td>\n","      <td>0.656601</td>\n","      <td>0.100646</td>\n","      <td>0.182153</td>\n","      <td>0.576096</td>\n","      <td>0.743958</td>\n","      <td>0.770489</td>\n","      <td>0.569661</td>\n","      <td>0.571325</td>\n","      <td>0.458837</td>\n","      <td>0.504536</td>\n","      <td>0.847875</td>\n","      <td>DERMASON</td>\n","    </tr>\n","    <tr>\n","      <th>12041</th>\n","      <td>0.097540</td>\n","      <td>0.175457</td>\n","      <td>0.173429</td>\n","      <td>0.183674</td>\n","      <td>0.318050</td>\n","      <td>0.670388</td>\n","      <td>0.101098</td>\n","      <td>0.182210</td>\n","      <td>0.495123</td>\n","      <td>0.723926</td>\n","      <td>0.737083</td>\n","      <td>0.552727</td>\n","      <td>0.577755</td>\n","      <td>0.446021</td>\n","      <td>0.420989</td>\n","      <td>0.768620</td>\n","      <td>DERMASON</td>\n","    </tr>\n","    <tr>\n","      <th>12042</th>\n","      <td>0.097596</td>\n","      <td>0.186848</td>\n","      <td>0.195566</td>\n","      <td>0.157363</td>\n","      <td>0.416994</td>\n","      <td>0.760405</td>\n","      <td>0.100789</td>\n","      <td>0.182296</td>\n","      <td>0.770847</td>\n","      <td>0.797733</td>\n","      <td>0.675066</td>\n","      <td>0.448470</td>\n","      <td>0.619715</td>\n","      <td>0.370986</td>\n","      <td>0.386991</td>\n","      <td>0.920332</td>\n","      <td>DERMASON</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>12043 rows Ã— 17 columns</p>\n","</div>"],"text/plain":["           Area  Perimeter  MajorAxisLength  MinorAxisLength  AspectRatio  \\\n","0      0.033153   0.061039         0.031866         0.130253     0.096582   \n","1      0.037765   0.071341         0.040616         0.136911     0.106074   \n","2      0.041974   0.079404         0.040116         0.155099     0.076777   \n","3      0.043098   0.075528         0.040937         0.159099     0.072625   \n","4      0.043875   0.079966         0.041948         0.123168     0.072823   \n","...         ...        ...              ...              ...          ...   \n","12038  0.097306   0.172413         0.183479         0.169555     0.366116   \n","12039  0.097325   0.170775         0.170029         0.185100     0.361443   \n","12040  0.097503   0.172133         0.169960         0.186648     0.305356   \n","12041  0.097540   0.175457         0.173429         0.183674     0.318050   \n","12042  0.097596   0.186848         0.195566         0.157363     0.416994   \n","\n","       Eccentricity  ConvexArea  EquivDiameter    Extent  Solidity  Roundness  \\\n","0          0.293183    0.033486       0.074517  0.688236  0.765887   0.896273   \n","1          0.318656    0.041178       0.083000  0.735054  0.810988   0.863948   \n","2          0.235172    0.045380       0.090618  0.727054  0.792180   0.851250   \n","3          0.222073    0.046520       0.092633  0.710536  0.786432   0.925119   \n","4          0.222706    0.047430       0.094022  0.713438  0.748987   0.884244   \n","...             ...         ...            ...       ...       ...        ...   \n","12038      0.717622    0.100364       0.181854  0.525427  0.825214   0.764705   \n","12039      0.659831    0.100299       0.181882  0.807074  0.842120   0.781895   \n","12040      0.656601    0.100646       0.182153  0.576096  0.743958   0.770489   \n","12041      0.670388    0.101098       0.182210  0.495123  0.723926   0.737083   \n","12042      0.760405    0.100789       0.182296  0.770847  0.797733   0.675066   \n","\n","       Compactness  ShapeFactor1  ShapeFactor2  ShapeFactor3  ShapeFactor4  \\\n","0         0.860745      0.669818      0.904005      0.809404      0.948254   \n","1         0.846023      0.656551      0.868804      0.793221      0.965812   \n","2         0.894046      0.622647      0.905946      0.846311      0.974516   \n","3         0.899681      0.616450      0.907893      0.852597      0.928794   \n","4         0.900253      0.613384      0.905512      0.853236      0.960007   \n","...            ...           ...           ...           ...           ...   \n","12038     0.502647      0.598174      0.409626      0.438857      0.930881   \n","12039     0.568127      0.572370      0.457976      0.503014      0.922335   \n","12040     0.569661      0.571325      0.458837      0.504536      0.847875   \n","12041     0.552727      0.577755      0.446021      0.420989      0.768620   \n","12042     0.448470      0.619715      0.370986      0.386991      0.920332   \n","\n","          Class  \n","0         SEKER  \n","1         SEKER  \n","2         SEKER  \n","3         SEKER  \n","4         SEKER  \n","...         ...  \n","12038  DERMASON  \n","12039  DERMASON  \n","12040  DERMASON  \n","12041  DERMASON  \n","12042  DERMASON  \n","\n","[12043 rows x 17 columns]"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["#Normalization with min max\n","from sklearn.preprocessing import MinMaxScaler\n","\n","scaler = MinMaxScaler()\n","scaler.fit_transform(df_no_outliers[cols])\n","df_scaled = pd.DataFrame(scaler.transform(df_no_outliers[cols]), columns = cols)\n","\n","df_scaled['Class'] = df_no_outliers['Class']\n","df_scaled"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29909,"status":"ok","timestamp":1704300867289,"user":{"displayName":"Victor Hugo Schneider Lopes","userId":"10992764016890176856"},"user_tz":180},"id":"0dBs8lW22D02","outputId":"0fa3b061-0e30-4033-8c3b-8f0f60d37402"},"outputs":[{"name":"stdout","output_type":"stream","text":["Iteration 1, loss = 1.24393342\n","Iteration 2, loss = 0.82054310\n","Iteration 3, loss = 0.64186418\n","Iteration 4, loss = 0.58027638\n","Iteration 5, loss = 0.52336870\n","Iteration 6, loss = 0.55901682\n","Iteration 7, loss = 0.56485624\n","Iteration 8, loss = 0.63271652\n","Iteration 9, loss = 0.50669119\n","Iteration 10, loss = 0.41013126\n","Iteration 11, loss = 0.32476191\n","Iteration 12, loss = 0.31328542\n","Iteration 13, loss = 0.27145275\n","Iteration 14, loss = 0.27402131\n","Iteration 15, loss = 0.21839103\n","Iteration 16, loss = 0.20370343\n","Iteration 17, loss = 0.18178921\n","Iteration 18, loss = 0.17435121\n","Iteration 19, loss = 0.17430570\n","Iteration 20, loss = 0.16153712\n","Iteration 21, loss = 0.15385462\n","Iteration 22, loss = 0.15649515\n","Iteration 23, loss = 0.14930619\n","Iteration 24, loss = 0.16513692\n","Iteration 25, loss = 0.16652061\n","Iteration 26, loss = 0.16941522\n","Iteration 27, loss = 0.20280500\n","Iteration 28, loss = 0.16321548\n","Iteration 29, loss = 0.16180867\n","Iteration 30, loss = 0.16407801\n","Iteration 31, loss = 0.14721432\n","Iteration 32, loss = 0.15939207\n","Iteration 33, loss = 0.15546543\n","Iteration 34, loss = 0.15395262\n","Iteration 35, loss = 0.14604603\n","Iteration 36, loss = 0.14891224\n","Iteration 37, loss = 0.19807904\n","Iteration 38, loss = 0.17473971\n","Iteration 39, loss = 0.16452724\n","Iteration 40, loss = 0.15673499\n","Iteration 41, loss = 0.15478780\n","Iteration 42, loss = 0.15965879\n","Iteration 43, loss = 0.15641650\n","Iteration 44, loss = 0.17580724\n","Iteration 45, loss = 0.17637524\n","Iteration 46, loss = 0.15318059\n","Training loss did not improve more than tol=0.001000 for 10 consecutive epochs. Stopping.\n","Iteration 1, loss = 1.27684146\n","Iteration 2, loss = 0.89961552\n","Iteration 3, loss = 0.54145411\n","Iteration 4, loss = 0.40421828\n","Iteration 5, loss = 0.38375807\n","Iteration 6, loss = 0.34687258\n","Iteration 7, loss = 0.30220217\n","Iteration 8, loss = 0.27160553\n","Iteration 9, loss = 0.23948290\n","Iteration 10, loss = 0.23842046\n","Iteration 11, loss = 0.23305005\n","Iteration 12, loss = 0.24871375\n","Iteration 13, loss = 0.23272573\n","Iteration 14, loss = 0.22077838\n","Iteration 15, loss = 0.22496934\n","Iteration 16, loss = 0.25535648\n","Iteration 17, loss = 0.22541742\n","Iteration 18, loss = 0.23723799\n","Iteration 19, loss = 0.23159752\n","Iteration 20, loss = 0.22829308\n","Iteration 21, loss = 0.23136345\n","Iteration 22, loss = 0.21935764\n","Iteration 23, loss = 0.21939306\n","Iteration 24, loss = 0.23406898\n","Iteration 25, loss = 0.23211804\n","Iteration 26, loss = 0.21093329\n","Iteration 27, loss = 0.24034749\n","Iteration 28, loss = 0.23689167\n","Iteration 29, loss = 0.23472141\n","Iteration 30, loss = 0.22790499\n","Iteration 31, loss = 0.22152987\n","Iteration 32, loss = 0.22870792\n","Iteration 33, loss = 0.22783019\n","Iteration 34, loss = 0.21732591\n","Iteration 35, loss = 0.21089708\n","Iteration 36, loss = 0.21998212\n","Iteration 37, loss = 0.22648730\n","Training loss did not improve more than tol=0.001000 for 10 consecutive epochs. Stopping.\n","Iteration 1, loss = 1.28864057\n","Iteration 2, loss = 0.87488135\n","Iteration 3, loss = 0.50626058\n","Iteration 4, loss = 0.42163527\n","Iteration 5, loss = 0.37941145\n","Iteration 6, loss = 0.34602225\n","Iteration 7, loss = 0.34022852\n","Iteration 8, loss = 0.35412684\n","Iteration 9, loss = 0.32985366\n","Iteration 10, loss = 0.33812977\n","Iteration 11, loss = 0.32814788\n","Iteration 12, loss = 0.37118931\n","Iteration 13, loss = 0.33414635\n","Iteration 14, loss = 0.31228813\n","Iteration 15, loss = 0.29032208\n","Iteration 16, loss = 0.27027789\n","Iteration 17, loss = 0.24717030\n","Iteration 18, loss = 0.26383324\n","Iteration 19, loss = 0.24871236\n","Iteration 20, loss = 0.23675880\n","Iteration 21, loss = 0.25388286\n","Iteration 22, loss = 0.23901506\n","Iteration 23, loss = 0.21745683\n","Iteration 24, loss = 0.24665050\n","Iteration 25, loss = 0.24224814\n","Iteration 26, loss = 0.25513296\n","Iteration 27, loss = 0.24350303\n","Iteration 28, loss = 0.25683114\n","Iteration 29, loss = 0.23331974\n","Iteration 30, loss = 0.23437036\n","Iteration 31, loss = 0.22747214\n","Iteration 32, loss = 0.25637023\n","Iteration 33, loss = 0.24713471\n","Iteration 34, loss = 0.26172990\n","Training loss did not improve more than tol=0.001000 for 10 consecutive epochs. Stopping.\n","Iteration 1, loss = 1.36900634\n","Iteration 2, loss = 1.04825690\n","Iteration 3, loss = 0.99259735\n","Iteration 4, loss = 0.96860040\n","Iteration 5, loss = 0.95817284\n","Iteration 6, loss = 0.75962519\n","Iteration 7, loss = 0.44667098\n","Iteration 8, loss = 0.39453761\n","Iteration 9, loss = 0.39702336\n","Iteration 10, loss = 0.37805740\n","Iteration 11, loss = 0.41693533\n","Iteration 12, loss = 0.36120227\n","Iteration 13, loss = 0.35826129\n","Iteration 14, loss = 0.36121685\n","Iteration 15, loss = 0.33514813\n","Iteration 16, loss = 0.35362362\n","Iteration 17, loss = 0.39038560\n","Iteration 18, loss = 0.34678920\n","Iteration 19, loss = 0.34985267\n","Iteration 20, loss = 0.35522024\n","Iteration 21, loss = 0.34310567\n","Iteration 22, loss = 0.41860991\n","Iteration 23, loss = 0.32780572\n","Iteration 24, loss = 0.36766426\n","Iteration 25, loss = 0.34721919\n","Iteration 26, loss = 0.36071170\n","Iteration 27, loss = 0.32661791\n","Iteration 28, loss = 0.33108391\n","Iteration 29, loss = 0.36230247\n","Iteration 30, loss = 0.32511224\n","Iteration 31, loss = 0.33085908\n","Iteration 32, loss = 0.32151137\n","Iteration 33, loss = 0.32037120\n","Iteration 34, loss = 0.30135792\n","Iteration 35, loss = 0.32063586\n","Iteration 36, loss = 0.29946316\n","Iteration 37, loss = 0.34256725\n","Iteration 38, loss = 0.29698520\n","Iteration 39, loss = 0.32119097\n","Iteration 40, loss = 0.31779499\n","Iteration 41, loss = 0.30549659\n","Iteration 42, loss = 0.31901966\n","Iteration 43, loss = 0.34491002\n","Iteration 44, loss = 0.30135415\n","Iteration 45, loss = 0.30720498\n","Iteration 46, loss = 0.31149840\n","Iteration 47, loss = 0.29094670\n","Iteration 48, loss = 0.29267716\n","Iteration 49, loss = 0.29022870\n","Iteration 50, loss = 0.29152783\n","Iteration 51, loss = 0.30980624\n","Iteration 52, loss = 0.30858759\n","Iteration 53, loss = 0.28541117\n","Iteration 54, loss = 0.29652043\n","Iteration 55, loss = 0.29498919\n","Iteration 56, loss = 0.28438030\n","Iteration 57, loss = 0.34644905\n","Iteration 58, loss = 0.29680487\n","Iteration 59, loss = 0.29188900\n","Iteration 60, loss = 0.28160172\n","Iteration 61, loss = 0.29431999\n","Iteration 62, loss = 0.31155269\n","Iteration 63, loss = 0.30428900\n","Iteration 64, loss = 0.30199020\n","Iteration 65, loss = 0.30600426\n","Iteration 66, loss = 0.30853722\n","Iteration 67, loss = 0.28332832\n","Iteration 68, loss = 0.30359889\n","Iteration 69, loss = 0.30496024\n","Iteration 70, loss = 0.29486570\n","Iteration 71, loss = 0.28627120\n","Training loss did not improve more than tol=0.001000 for 10 consecutive epochs. Stopping.\n","Iteration 1, loss = 1.36683353\n","Iteration 2, loss = 1.06004095\n","Iteration 3, loss = 0.99229495\n","Iteration 4, loss = 0.97148564\n","Iteration 5, loss = 0.97242073\n","Iteration 6, loss = 0.90915775\n","Iteration 7, loss = 0.82433178\n","Iteration 8, loss = 0.80636699\n","Iteration 9, loss = 0.83967517\n","Iteration 10, loss = 0.76719764\n","Iteration 11, loss = 0.61228075\n","Iteration 12, loss = 0.61429287\n","Iteration 13, loss = 0.55679719\n","Iteration 14, loss = 0.60321132\n","Iteration 15, loss = 0.54042683\n","Iteration 16, loss = 0.52868928\n","Iteration 17, loss = 0.51601170\n","Iteration 18, loss = 0.49798942\n","Iteration 19, loss = 0.48617898\n","Iteration 20, loss = 0.45222494\n","Iteration 21, loss = 0.44058366\n","Iteration 22, loss = 0.41615439\n","Iteration 23, loss = 0.35401518\n","Iteration 24, loss = 0.43334038\n","Iteration 25, loss = 0.34085424\n","Iteration 26, loss = 0.43383571\n","Iteration 27, loss = 0.35142945\n","Iteration 28, loss = 0.46955545\n","Iteration 29, loss = 0.33381807\n","Iteration 30, loss = 0.32494414\n","Iteration 31, loss = 0.33955486\n","Iteration 32, loss = 0.31273981\n","Iteration 33, loss = 0.33015256\n","Iteration 34, loss = 0.32940306\n","Iteration 35, loss = 0.34955355\n","Iteration 36, loss = 0.30350382\n","Iteration 37, loss = 0.32608608\n","Iteration 38, loss = 0.27259713\n","Iteration 39, loss = 0.27855743\n","Iteration 40, loss = 0.26516137\n","Iteration 41, loss = 0.28427082\n","Iteration 42, loss = 0.30282805\n","Iteration 43, loss = 0.27534128\n","Iteration 44, loss = 0.26418837\n","Iteration 45, loss = 0.28175896\n","Iteration 46, loss = 0.27068130\n","Iteration 47, loss = 0.24743744\n","Iteration 48, loss = 0.25472458\n","Iteration 49, loss = 0.24788195\n","Iteration 50, loss = 0.24115735\n","Iteration 51, loss = 0.26258795\n","Iteration 52, loss = 0.24771642\n","Iteration 53, loss = 0.26230296\n","Iteration 54, loss = 0.25654281\n","Iteration 55, loss = 0.27076952\n","Iteration 56, loss = 0.24785306\n","Iteration 57, loss = 0.25744400\n","Iteration 58, loss = 0.23354263\n","Iteration 59, loss = 0.24399475\n","Iteration 60, loss = 0.23076986\n","Iteration 61, loss = 0.26205366\n","Iteration 62, loss = 0.25875465\n","Iteration 63, loss = 0.25833871\n","Iteration 64, loss = 0.26202949\n","Iteration 65, loss = 0.25512175\n","Iteration 66, loss = 0.26064063\n","Iteration 67, loss = 0.25486751\n","Iteration 68, loss = 0.26232445\n","Iteration 69, loss = 0.24955164\n","Iteration 70, loss = 0.24345731\n","Iteration 71, loss = 0.24674814\n","Training loss did not improve more than tol=0.001000 for 10 consecutive epochs. Stopping.\n","Iteration 1, loss = 1.36940190\n","Iteration 2, loss = 1.06319108\n","Iteration 3, loss = 0.99214140\n","Iteration 4, loss = 0.96866251\n","Iteration 5, loss = 0.94738375\n","Iteration 6, loss = 0.74805821\n","Iteration 7, loss = 0.43994082\n","Iteration 8, loss = 0.41776494\n","Iteration 9, loss = 0.39166940\n","Iteration 10, loss = 0.36920149\n","Iteration 11, loss = 0.43329528\n","Iteration 12, loss = 0.37185006\n","Iteration 13, loss = 0.36249516\n","Iteration 14, loss = 0.35338881\n","Iteration 15, loss = 0.35245748\n","Iteration 16, loss = 0.33167248\n","Iteration 17, loss = 0.32924740\n","Iteration 18, loss = 0.34590955\n","Iteration 19, loss = 0.35590262\n","Iteration 20, loss = 0.38762196\n","Iteration 21, loss = 0.33470040\n","Iteration 22, loss = 0.34702892\n","Iteration 23, loss = 0.33852953\n","Iteration 24, loss = 0.36353444\n","Iteration 25, loss = 0.34697043\n","Iteration 26, loss = 0.35643438\n","Iteration 27, loss = 0.31392754\n","Iteration 28, loss = 0.33986537\n","Iteration 29, loss = 0.28902119\n","Iteration 30, loss = 0.32259748\n","Iteration 31, loss = 0.31002552\n","Iteration 32, loss = 0.32902521\n","Iteration 33, loss = 0.33024817\n","Iteration 34, loss = 0.30789153\n","Iteration 35, loss = 0.32234189\n","Iteration 36, loss = 0.29218192\n","Iteration 37, loss = 0.33030324\n","Iteration 38, loss = 0.28861704\n","Iteration 39, loss = 0.30584660\n","Iteration 40, loss = 0.32835983\n","Training loss did not improve more than tol=0.001000 for 10 consecutive epochs. Stopping.\n","Iteration 1, loss = 1.36693653\n","Iteration 2, loss = 1.05883263\n","Iteration 3, loss = 0.99047875\n","Iteration 4, loss = 0.97258076\n","Iteration 5, loss = 0.94393136\n","Iteration 6, loss = 0.64238707\n","Iteration 7, loss = 0.42375104\n","Iteration 8, loss = 0.36873654\n","Iteration 9, loss = 0.38220950\n","Iteration 10, loss = 0.37197042\n","Iteration 11, loss = 0.39262134\n","Iteration 12, loss = 0.36857402\n","Iteration 13, loss = 0.34103531\n","Iteration 14, loss = 0.34319605\n","Iteration 15, loss = 0.33326211\n","Iteration 16, loss = 0.31627915\n","Iteration 17, loss = 0.32234255\n","Iteration 18, loss = 0.32912263\n","Iteration 19, loss = 0.35425886\n","Iteration 20, loss = 0.40158976\n","Iteration 21, loss = 0.32314261\n","Iteration 22, loss = 0.31239922\n","Iteration 23, loss = 0.33502873\n","Iteration 24, loss = 0.34355028\n","Iteration 25, loss = 0.36859321\n","Iteration 26, loss = 0.36111911\n","Iteration 27, loss = 0.31469904\n","Iteration 28, loss = 0.30949295\n","Iteration 29, loss = 0.29684612\n","Iteration 30, loss = 0.32601233\n","Iteration 31, loss = 0.32243470\n","Iteration 32, loss = 0.29039240\n","Iteration 33, loss = 0.30859987\n","Iteration 34, loss = 0.34549282\n","Iteration 35, loss = 0.30516881\n","Iteration 36, loss = 0.29440988\n","Iteration 37, loss = 0.30450187\n","Iteration 38, loss = 0.29021111\n","Iteration 39, loss = 0.30100198\n","Iteration 40, loss = 0.28643281\n","Iteration 41, loss = 0.29283299\n","Iteration 42, loss = 0.30525409\n","Iteration 43, loss = 0.33966474\n","Iteration 44, loss = 0.32023113\n","Iteration 45, loss = 0.30498965\n","Iteration 46, loss = 0.29409809\n","Iteration 47, loss = 0.32045170\n","Iteration 48, loss = 0.29120997\n","Iteration 49, loss = 0.28493797\n","Iteration 50, loss = 0.28427724\n","Iteration 51, loss = 0.28223192\n","Iteration 52, loss = 0.28597178\n","Iteration 53, loss = 0.28622565\n","Iteration 54, loss = 0.26880514\n","Iteration 55, loss = 0.28375665\n","Iteration 56, loss = 0.29436085\n","Iteration 57, loss = 0.28856760\n","Iteration 58, loss = 0.27736584\n","Iteration 59, loss = 0.27437026\n","Iteration 60, loss = 0.27724033\n","Iteration 61, loss = 0.28164611\n","Iteration 62, loss = 0.29031774\n","Iteration 63, loss = 0.28182335\n","Iteration 64, loss = 0.26307790\n","Iteration 65, loss = 0.32243324\n","Iteration 66, loss = 0.29141282\n","Iteration 67, loss = 0.26143277\n","Iteration 68, loss = 0.29280629\n","Iteration 69, loss = 0.30949935\n","Iteration 70, loss = 0.25279784\n","Iteration 71, loss = 0.27910897\n","Iteration 72, loss = 0.25718195\n","Iteration 73, loss = 0.26665530\n","Iteration 74, loss = 0.25195541\n","Iteration 75, loss = 0.26798945\n","Iteration 76, loss = 0.26095402\n","Iteration 77, loss = 0.27218766\n","Iteration 78, loss = 0.27083489\n","Iteration 79, loss = 0.27474686\n","Iteration 80, loss = 0.27108605\n","Iteration 81, loss = 0.26007093\n","Training loss did not improve more than tol=0.001000 for 10 consecutive epochs. Stopping.\n","Iteration 1, loss = 1.36773062\n","Iteration 2, loss = 1.05393595\n","Iteration 3, loss = 0.98788584\n","Iteration 4, loss = 0.95645403\n","Iteration 5, loss = 0.93650272\n","Iteration 6, loss = 0.55476035\n","Iteration 7, loss = 0.41269091\n","Iteration 8, loss = 0.38751218\n","Iteration 9, loss = 0.35453814\n","Iteration 10, loss = 0.37526284\n","Iteration 11, loss = 0.35281967\n","Iteration 12, loss = 0.37306921\n","Iteration 13, loss = 0.34140787\n","Iteration 14, loss = 0.34062627\n","Iteration 15, loss = 0.34413481\n","Iteration 16, loss = 0.33783345\n","Iteration 17, loss = 0.31801443\n","Iteration 18, loss = 0.32794329\n","Iteration 19, loss = 0.33870279\n","Iteration 20, loss = 0.34294289\n","Iteration 21, loss = 0.29607937\n","Iteration 22, loss = 0.33323201\n","Iteration 23, loss = 0.31675231\n","Iteration 24, loss = 0.33275222\n","Iteration 25, loss = 0.30986591\n","Iteration 26, loss = 0.34652191\n","Iteration 27, loss = 0.29879234\n","Iteration 28, loss = 0.31227150\n","Iteration 29, loss = 0.29740603\n","Iteration 30, loss = 0.31152929\n","Iteration 31, loss = 0.29739874\n","Iteration 32, loss = 0.31169535\n","Training loss did not improve more than tol=0.001000 for 10 consecutive epochs. Stopping.\n","Iteration 1, loss = 1.37005735\n","Iteration 2, loss = 1.05620331\n","Iteration 3, loss = 0.97660174\n","Iteration 4, loss = 0.94548777\n","Iteration 5, loss = 0.90828002\n","Iteration 6, loss = 0.52328382\n","Iteration 7, loss = 0.35939405\n","Iteration 8, loss = 0.39023289\n","Iteration 9, loss = 0.34359257\n","Iteration 10, loss = 0.35764005\n","Iteration 11, loss = 0.33905747\n","Iteration 12, loss = 0.34879357\n","Iteration 13, loss = 0.30727448\n","Iteration 14, loss = 0.31227207\n","Iteration 15, loss = 0.32403512\n","Iteration 16, loss = 0.31324387\n","Iteration 17, loss = 0.30413337\n","Iteration 18, loss = 0.30199423\n","Iteration 19, loss = 0.31120244\n","Iteration 20, loss = 0.30665494\n","Iteration 21, loss = 0.27660461\n","Iteration 22, loss = 0.30089154\n","Iteration 23, loss = 0.30917353\n","Iteration 24, loss = 0.30629720\n","Iteration 25, loss = 0.29738287\n","Iteration 26, loss = 0.35406836\n","Iteration 27, loss = 0.28874005\n","Iteration 28, loss = 0.27808365\n","Iteration 29, loss = 0.27903092\n","Iteration 30, loss = 0.29621974\n","Iteration 31, loss = 0.27619211\n","Iteration 32, loss = 0.29547809\n","Training loss did not improve more than tol=0.001000 for 10 consecutive epochs. Stopping.\n","Iteration 1, loss = 1.37430657\n","Iteration 2, loss = 1.02366533\n","Iteration 3, loss = 0.93412115\n","Iteration 4, loss = 0.73908595\n","Iteration 5, loss = 0.66456223\n","Iteration 6, loss = 0.61387011\n","Iteration 7, loss = 0.44823643\n","Iteration 8, loss = 0.39198645\n","Iteration 9, loss = 0.42075375\n","Iteration 10, loss = 0.41044002\n","Iteration 11, loss = 0.33831457\n","Iteration 12, loss = 0.27187839\n","Iteration 13, loss = 0.27635523\n","Iteration 14, loss = 0.26092515\n","Iteration 15, loss = 0.25041726\n","Iteration 16, loss = 0.25834464\n","Iteration 17, loss = 0.24090274\n","Iteration 18, loss = 0.21876793\n","Iteration 19, loss = 0.22108279\n","Iteration 20, loss = 0.24826952\n","Iteration 21, loss = 0.19723612\n","Iteration 22, loss = 0.20233214\n","Iteration 23, loss = 0.20135075\n","Iteration 24, loss = 0.20561507\n","Iteration 25, loss = 0.20256361\n","Iteration 26, loss = 0.22609414\n","Iteration 27, loss = 0.20328307\n","Iteration 28, loss = 0.17425802\n","Iteration 29, loss = 0.18469555\n","Iteration 30, loss = 0.18044957\n","Iteration 31, loss = 0.17366497\n","Iteration 32, loss = 0.20637933\n","Iteration 33, loss = 0.17744780\n","Iteration 34, loss = 0.17379788\n","Iteration 35, loss = 0.18227688\n","Iteration 36, loss = 0.19538089\n","Iteration 37, loss = 0.18496622\n","Iteration 38, loss = 0.19134509\n","Iteration 39, loss = 0.18490270\n","Training loss did not improve more than tol=0.001000 for 10 consecutive epochs. Stopping.\n","Experimento 6\n","AcurÃ¡cia MÃ©dia: 87.25%\n","PrecisÃ£o MÃ©dia: 89.70%\n","RevocaÃ§Ã£o MÃ©dia: 88.95%\n","F1-Score MÃ©dio: 87.77%\n"]}],"source":["from sklearn.neural_network import MLPClassifier\n","from sklearn.model_selection import cross_validate\n","\n","\n","x_train = df_scaled.iloc[:, 0:16]\n","y_train = df_scaled.iloc[:, 16]\n","classifier = MLPClassifier(activation='logistic', solver='adam', alpha=1e-5, hidden_layer_sizes=(12, 3), random_state=1, verbose=True, learning_rate_init=0.3, tol=1e-3, max_iter=500)\n","scoring = {'acc' : 'accuracy',\n","           'prec' : 'precision_macro',\n","           'recall' : 'recall_macro',\n","           'f1' : 'f1_macro'}\n","\n","\n","y_pred = cross_validate(classifier, x_train, y_train, cv=10, scoring=scoring, return_train_score=True)\n","print('Experimento 6')\n","print('AcurÃ¡cia MÃ©dia: ' + '%.2f' % (np.mean(y_pred['test_acc'])*100) + '%')\n","print('PrecisÃ£o MÃ©dia: ' + '%.2f' % (np.mean(y_pred['test_prec'])*100) + '%')\n","print('RevocaÃ§Ã£o MÃ©dia: ' + '%.2f' % (np.mean(y_pred['test_recall'])*100) + '%')\n","print('F1-Score MÃ©dio: ' + '%.2f' % (np.mean(y_pred['test_f1'])*100) + '%')\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMWENDrKLM3xI4ah/PFgyKr","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":0}
