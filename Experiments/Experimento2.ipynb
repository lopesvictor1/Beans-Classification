{"cells":[{"cell_type":"markdown","metadata":{"id":"VMpZC5eq6HNR"},"source":["Experimento 2 - KNN Imputer, 3sigma outlier detection, min max normalization, MLP classifier"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":26715,"status":"ok","timestamp":1704299618201,"user":{"displayName":"Victor Hugo Schneider Lopes","userId":"10992764016890176856"},"user_tz":180},"id":"cP53TLVS5xq-"},"outputs":[],"source":["import pandas as pd\n","import seaborn as sns\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn.objects as so\n","from ucimlrepo import fetch_ucirepo"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":1061,"status":"ok","timestamp":1704299619253,"user":{"displayName":"Victor Hugo Schneider Lopes","userId":"10992764016890176856"},"user_tz":180},"id":"0owuQnJm6Vl5"},"outputs":[],"source":["beans = fetch_ucirepo(id=602)\n","df = beans.data.features\n","targets = beans.data.targets"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1704299619254,"user":{"displayName":"Victor Hugo Schneider Lopes","userId":"10992764016890176856"},"user_tz":180},"id":"_jMLf_dB6aIn"},"outputs":[],"source":["cols = ['Area', 'Perimeter', 'MajorAxisLength', 'MinorAxisLength', 'AspectRatio', 'Eccentricity', 'ConvexArea', 'EquivDiameter', 'Extent', 'Solidity', 'Roundness', 'Compactness', 'ShapeFactor1', 'ShapeFactor2', 'ShapeFactor3', 'ShapeFactor4']"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8014,"status":"ok","timestamp":1704299627260,"user":{"displayName":"Victor Hugo Schneider Lopes","userId":"10992764016890176856"},"user_tz":180},"id":"dCOP0sV96rrX","outputId":"25aec69b-b342-476e-d993-b991fe8b4984"},"outputs":[],"source":["import random\n","\n","#Introducing Missing values (5%)\n","\n","for index, i in enumerate(df):\n","  for jndex, j in enumerate(df[i]):\n","    if random.randint(0,100) < 5:\n","      df.loc[jndex,i] = np.NaN"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27,"status":"ok","timestamp":1704299627260,"user":{"displayName":"Victor Hugo Schneider Lopes","userId":"10992764016890176856"},"user_tz":180},"id":"eUet-44k838X","outputId":"96353556-3cfd-487e-f2e6-d6454e848907"},"outputs":[{"data":{"text/plain":["Area               641\n","Perimeter          676\n","MajorAxisLength    678\n","MinorAxisLength    675\n","AspectRatio        715\n","Eccentricity       713\n","ConvexArea         665\n","EquivDiameter      691\n","Extent             645\n","Solidity           710\n","Roundness          660\n","Compactness        687\n","ShapeFactor1       672\n","ShapeFactor2       668\n","ShapeFactor3       659\n","ShapeFactor4       670\n","dtype: int64"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["df.isna().sum()"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":444},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1704299627261,"user":{"displayName":"Victor Hugo Schneider Lopes","userId":"10992764016890176856"},"user_tz":180},"id":"U7Qgx3nODiaS","outputId":"8f37541c-bd20-44a2-9f82-3749a2f8de10"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Area</th>\n","      <th>Perimeter</th>\n","      <th>MajorAxisLength</th>\n","      <th>MinorAxisLength</th>\n","      <th>AspectRatio</th>\n","      <th>Eccentricity</th>\n","      <th>ConvexArea</th>\n","      <th>EquivDiameter</th>\n","      <th>Extent</th>\n","      <th>Solidity</th>\n","      <th>Roundness</th>\n","      <th>Compactness</th>\n","      <th>ShapeFactor1</th>\n","      <th>ShapeFactor2</th>\n","      <th>ShapeFactor3</th>\n","      <th>ShapeFactor4</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>28395.0</td>\n","      <td>610.291</td>\n","      <td>208.178117</td>\n","      <td>173.888747</td>\n","      <td>1.197191</td>\n","      <td>0.549812</td>\n","      <td>28715.0</td>\n","      <td>190.141097</td>\n","      <td>0.763923</td>\n","      <td>0.988856</td>\n","      <td>0.958027</td>\n","      <td>0.913358</td>\n","      <td>0.007332</td>\n","      <td>0.003147</td>\n","      <td>0.834222</td>\n","      <td>0.998724</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>28734.0</td>\n","      <td>638.018</td>\n","      <td>NaN</td>\n","      <td>182.734419</td>\n","      <td>1.097356</td>\n","      <td>0.411785</td>\n","      <td>29172.0</td>\n","      <td>191.272751</td>\n","      <td>0.783968</td>\n","      <td>0.984986</td>\n","      <td>0.887034</td>\n","      <td>0.953861</td>\n","      <td>0.006979</td>\n","      <td>0.003564</td>\n","      <td>0.909851</td>\n","      <td>0.998430</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>29380.0</td>\n","      <td>624.110</td>\n","      <td>212.826130</td>\n","      <td>175.931143</td>\n","      <td>1.209713</td>\n","      <td>0.562727</td>\n","      <td>29690.0</td>\n","      <td>193.410904</td>\n","      <td>0.778113</td>\n","      <td>0.989559</td>\n","      <td>0.947849</td>\n","      <td>0.908774</td>\n","      <td>0.007244</td>\n","      <td>0.003048</td>\n","      <td>0.825871</td>\n","      <td>0.999066</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>30008.0</td>\n","      <td>645.884</td>\n","      <td>210.557999</td>\n","      <td>182.516516</td>\n","      <td>1.153638</td>\n","      <td>0.498616</td>\n","      <td>30724.0</td>\n","      <td>195.467062</td>\n","      <td>0.782681</td>\n","      <td>0.976696</td>\n","      <td>0.903936</td>\n","      <td>0.928329</td>\n","      <td>0.007017</td>\n","      <td>0.003215</td>\n","      <td>0.861794</td>\n","      <td>0.994199</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>30140.0</td>\n","      <td>620.134</td>\n","      <td>201.847882</td>\n","      <td>190.279279</td>\n","      <td>1.060798</td>\n","      <td>0.333680</td>\n","      <td>30417.0</td>\n","      <td>195.896503</td>\n","      <td>0.773098</td>\n","      <td>0.990893</td>\n","      <td>0.984877</td>\n","      <td>0.970516</td>\n","      <td>0.006697</td>\n","      <td>0.003665</td>\n","      <td>0.941900</td>\n","      <td>0.999166</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>13606</th>\n","      <td>42097.0</td>\n","      <td>759.696</td>\n","      <td>288.721612</td>\n","      <td>185.944705</td>\n","      <td>NaN</td>\n","      <td>0.765002</td>\n","      <td>42508.0</td>\n","      <td>231.515799</td>\n","      <td>0.714574</td>\n","      <td>0.990331</td>\n","      <td>0.916603</td>\n","      <td>0.801865</td>\n","      <td>0.006858</td>\n","      <td>0.001749</td>\n","      <td>0.642988</td>\n","      <td>0.998385</td>\n","    </tr>\n","    <tr>\n","      <th>13607</th>\n","      <td>42101.0</td>\n","      <td>757.499</td>\n","      <td>281.576392</td>\n","      <td>190.713136</td>\n","      <td>1.476439</td>\n","      <td>NaN</td>\n","      <td>42494.0</td>\n","      <td>231.526798</td>\n","      <td>0.799943</td>\n","      <td>0.990752</td>\n","      <td>0.922015</td>\n","      <td>0.822252</td>\n","      <td>0.006688</td>\n","      <td>NaN</td>\n","      <td>0.676099</td>\n","      <td>0.998219</td>\n","    </tr>\n","    <tr>\n","      <th>13608</th>\n","      <td>42139.0</td>\n","      <td>759.321</td>\n","      <td>281.539928</td>\n","      <td>191.187979</td>\n","      <td>1.472582</td>\n","      <td>0.734065</td>\n","      <td>42569.0</td>\n","      <td>231.631261</td>\n","      <td>0.729932</td>\n","      <td>0.989899</td>\n","      <td>NaN</td>\n","      <td>0.822730</td>\n","      <td>0.006681</td>\n","      <td>0.001888</td>\n","      <td>0.676884</td>\n","      <td>0.996767</td>\n","    </tr>\n","    <tr>\n","      <th>13609</th>\n","      <td>42147.0</td>\n","      <td>763.779</td>\n","      <td>283.382636</td>\n","      <td>190.275731</td>\n","      <td>1.489326</td>\n","      <td>0.741055</td>\n","      <td>42667.0</td>\n","      <td>231.653247</td>\n","      <td>0.705389</td>\n","      <td>0.987813</td>\n","      <td>0.907906</td>\n","      <td>0.817457</td>\n","      <td>0.006724</td>\n","      <td>0.001852</td>\n","      <td>NaN</td>\n","      <td>0.995222</td>\n","    </tr>\n","    <tr>\n","      <th>13610</th>\n","      <td>42159.0</td>\n","      <td>NaN</td>\n","      <td>295.142741</td>\n","      <td>182.204716</td>\n","      <td>1.619841</td>\n","      <td>0.786693</td>\n","      <td>42600.0</td>\n","      <td>231.686223</td>\n","      <td>0.788962</td>\n","      <td>0.989648</td>\n","      <td>0.888380</td>\n","      <td>0.784997</td>\n","      <td>0.007001</td>\n","      <td>0.001640</td>\n","      <td>0.616221</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>13611 rows Ã— 16 columns</p>\n","</div>"],"text/plain":["          Area  Perimeter  MajorAxisLength  MinorAxisLength  AspectRatio  \\\n","0      28395.0    610.291       208.178117       173.888747     1.197191   \n","1      28734.0    638.018              NaN       182.734419     1.097356   \n","2      29380.0    624.110       212.826130       175.931143     1.209713   \n","3      30008.0    645.884       210.557999       182.516516     1.153638   \n","4      30140.0    620.134       201.847882       190.279279     1.060798   \n","...        ...        ...              ...              ...          ...   \n","13606  42097.0    759.696       288.721612       185.944705          NaN   \n","13607  42101.0    757.499       281.576392       190.713136     1.476439   \n","13608  42139.0    759.321       281.539928       191.187979     1.472582   \n","13609  42147.0    763.779       283.382636       190.275731     1.489326   \n","13610  42159.0        NaN       295.142741       182.204716     1.619841   \n","\n","       Eccentricity  ConvexArea  EquivDiameter    Extent  Solidity  Roundness  \\\n","0          0.549812     28715.0     190.141097  0.763923  0.988856   0.958027   \n","1          0.411785     29172.0     191.272751  0.783968  0.984986   0.887034   \n","2          0.562727     29690.0     193.410904  0.778113  0.989559   0.947849   \n","3          0.498616     30724.0     195.467062  0.782681  0.976696   0.903936   \n","4          0.333680     30417.0     195.896503  0.773098  0.990893   0.984877   \n","...             ...         ...            ...       ...       ...        ...   \n","13606      0.765002     42508.0     231.515799  0.714574  0.990331   0.916603   \n","13607           NaN     42494.0     231.526798  0.799943  0.990752   0.922015   \n","13608      0.734065     42569.0     231.631261  0.729932  0.989899        NaN   \n","13609      0.741055     42667.0     231.653247  0.705389  0.987813   0.907906   \n","13610      0.786693     42600.0     231.686223  0.788962  0.989648   0.888380   \n","\n","       Compactness  ShapeFactor1  ShapeFactor2  ShapeFactor3  ShapeFactor4  \n","0         0.913358      0.007332      0.003147      0.834222      0.998724  \n","1         0.953861      0.006979      0.003564      0.909851      0.998430  \n","2         0.908774      0.007244      0.003048      0.825871      0.999066  \n","3         0.928329      0.007017      0.003215      0.861794      0.994199  \n","4         0.970516      0.006697      0.003665      0.941900      0.999166  \n","...            ...           ...           ...           ...           ...  \n","13606     0.801865      0.006858      0.001749      0.642988      0.998385  \n","13607     0.822252      0.006688           NaN      0.676099      0.998219  \n","13608     0.822730      0.006681      0.001888      0.676884      0.996767  \n","13609     0.817457      0.006724      0.001852           NaN      0.995222  \n","13610     0.784997      0.007001      0.001640      0.616221           NaN  \n","\n","[13611 rows x 16 columns]"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["df"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":444},"executionInfo":{"elapsed":16058,"status":"ok","timestamp":1704299643302,"user":{"displayName":"Victor Hugo Schneider Lopes","userId":"10992764016890176856"},"user_tz":180},"id":"WJH40wejA9LZ","outputId":"3202a8dc-bc5c-4c3a-9e47-45df4796ef60"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Area</th>\n","      <th>Perimeter</th>\n","      <th>MajorAxisLength</th>\n","      <th>MinorAxisLength</th>\n","      <th>AspectRatio</th>\n","      <th>Eccentricity</th>\n","      <th>ConvexArea</th>\n","      <th>EquivDiameter</th>\n","      <th>Extent</th>\n","      <th>Solidity</th>\n","      <th>Roundness</th>\n","      <th>Compactness</th>\n","      <th>ShapeFactor1</th>\n","      <th>ShapeFactor2</th>\n","      <th>ShapeFactor3</th>\n","      <th>ShapeFactor4</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>28395.0</td>\n","      <td>610.2910</td>\n","      <td>208.178117</td>\n","      <td>173.888747</td>\n","      <td>1.197191</td>\n","      <td>0.549812</td>\n","      <td>28715.0</td>\n","      <td>190.141097</td>\n","      <td>0.763923</td>\n","      <td>0.988856</td>\n","      <td>0.958027</td>\n","      <td>0.913358</td>\n","      <td>0.007332</td>\n","      <td>0.003147</td>\n","      <td>0.834222</td>\n","      <td>0.998724</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>28734.0</td>\n","      <td>638.0180</td>\n","      <td>234.465344</td>\n","      <td>182.734419</td>\n","      <td>1.097356</td>\n","      <td>0.411785</td>\n","      <td>29172.0</td>\n","      <td>191.272751</td>\n","      <td>0.783968</td>\n","      <td>0.984986</td>\n","      <td>0.887034</td>\n","      <td>0.953861</td>\n","      <td>0.006979</td>\n","      <td>0.003564</td>\n","      <td>0.909851</td>\n","      <td>0.998430</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>29380.0</td>\n","      <td>624.1100</td>\n","      <td>212.826130</td>\n","      <td>175.931143</td>\n","      <td>1.209713</td>\n","      <td>0.562727</td>\n","      <td>29690.0</td>\n","      <td>193.410904</td>\n","      <td>0.778113</td>\n","      <td>0.989559</td>\n","      <td>0.947849</td>\n","      <td>0.908774</td>\n","      <td>0.007244</td>\n","      <td>0.003048</td>\n","      <td>0.825871</td>\n","      <td>0.999066</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>30008.0</td>\n","      <td>645.8840</td>\n","      <td>210.557999</td>\n","      <td>182.516516</td>\n","      <td>1.153638</td>\n","      <td>0.498616</td>\n","      <td>30724.0</td>\n","      <td>195.467062</td>\n","      <td>0.782681</td>\n","      <td>0.976696</td>\n","      <td>0.903936</td>\n","      <td>0.928329</td>\n","      <td>0.007017</td>\n","      <td>0.003215</td>\n","      <td>0.861794</td>\n","      <td>0.994199</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>30140.0</td>\n","      <td>620.1340</td>\n","      <td>201.847882</td>\n","      <td>190.279279</td>\n","      <td>1.060798</td>\n","      <td>0.333680</td>\n","      <td>30417.0</td>\n","      <td>195.896503</td>\n","      <td>0.773098</td>\n","      <td>0.990893</td>\n","      <td>0.984877</td>\n","      <td>0.970516</td>\n","      <td>0.006697</td>\n","      <td>0.003665</td>\n","      <td>0.941900</td>\n","      <td>0.999166</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>13606</th>\n","      <td>42097.0</td>\n","      <td>759.6960</td>\n","      <td>288.721612</td>\n","      <td>185.944705</td>\n","      <td>1.540691</td>\n","      <td>0.765002</td>\n","      <td>42508.0</td>\n","      <td>231.515799</td>\n","      <td>0.714574</td>\n","      <td>0.990331</td>\n","      <td>0.916603</td>\n","      <td>0.801865</td>\n","      <td>0.006858</td>\n","      <td>0.001749</td>\n","      <td>0.642988</td>\n","      <td>0.998385</td>\n","    </tr>\n","    <tr>\n","      <th>13607</th>\n","      <td>42101.0</td>\n","      <td>757.4990</td>\n","      <td>281.576392</td>\n","      <td>190.713136</td>\n","      <td>1.476439</td>\n","      <td>0.752034</td>\n","      <td>42494.0</td>\n","      <td>231.526798</td>\n","      <td>0.799943</td>\n","      <td>0.990752</td>\n","      <td>0.922015</td>\n","      <td>0.822252</td>\n","      <td>0.006688</td>\n","      <td>0.001815</td>\n","      <td>0.676099</td>\n","      <td>0.998219</td>\n","    </tr>\n","    <tr>\n","      <th>13608</th>\n","      <td>42139.0</td>\n","      <td>759.3210</td>\n","      <td>281.539928</td>\n","      <td>191.187979</td>\n","      <td>1.472582</td>\n","      <td>0.734065</td>\n","      <td>42569.0</td>\n","      <td>231.631261</td>\n","      <td>0.729932</td>\n","      <td>0.989899</td>\n","      <td>0.920188</td>\n","      <td>0.822730</td>\n","      <td>0.006681</td>\n","      <td>0.001888</td>\n","      <td>0.676884</td>\n","      <td>0.996767</td>\n","    </tr>\n","    <tr>\n","      <th>13609</th>\n","      <td>42147.0</td>\n","      <td>763.7790</td>\n","      <td>283.382636</td>\n","      <td>190.275731</td>\n","      <td>1.489326</td>\n","      <td>0.741055</td>\n","      <td>42667.0</td>\n","      <td>231.653247</td>\n","      <td>0.705389</td>\n","      <td>0.987813</td>\n","      <td>0.907906</td>\n","      <td>0.817457</td>\n","      <td>0.006724</td>\n","      <td>0.001852</td>\n","      <td>0.646197</td>\n","      <td>0.995222</td>\n","    </tr>\n","    <tr>\n","      <th>13610</th>\n","      <td>42159.0</td>\n","      <td>795.6046</td>\n","      <td>295.142741</td>\n","      <td>182.204716</td>\n","      <td>1.619841</td>\n","      <td>0.786693</td>\n","      <td>42600.0</td>\n","      <td>231.686223</td>\n","      <td>0.788962</td>\n","      <td>0.989648</td>\n","      <td>0.888380</td>\n","      <td>0.784997</td>\n","      <td>0.007001</td>\n","      <td>0.001640</td>\n","      <td>0.616221</td>\n","      <td>0.993065</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>13611 rows Ã— 16 columns</p>\n","</div>"],"text/plain":["          Area  Perimeter  MajorAxisLength  MinorAxisLength  AspectRatio  \\\n","0      28395.0   610.2910       208.178117       173.888747     1.197191   \n","1      28734.0   638.0180       234.465344       182.734419     1.097356   \n","2      29380.0   624.1100       212.826130       175.931143     1.209713   \n","3      30008.0   645.8840       210.557999       182.516516     1.153638   \n","4      30140.0   620.1340       201.847882       190.279279     1.060798   \n","...        ...        ...              ...              ...          ...   \n","13606  42097.0   759.6960       288.721612       185.944705     1.540691   \n","13607  42101.0   757.4990       281.576392       190.713136     1.476439   \n","13608  42139.0   759.3210       281.539928       191.187979     1.472582   \n","13609  42147.0   763.7790       283.382636       190.275731     1.489326   \n","13610  42159.0   795.6046       295.142741       182.204716     1.619841   \n","\n","       Eccentricity  ConvexArea  EquivDiameter    Extent  Solidity  Roundness  \\\n","0          0.549812     28715.0     190.141097  0.763923  0.988856   0.958027   \n","1          0.411785     29172.0     191.272751  0.783968  0.984986   0.887034   \n","2          0.562727     29690.0     193.410904  0.778113  0.989559   0.947849   \n","3          0.498616     30724.0     195.467062  0.782681  0.976696   0.903936   \n","4          0.333680     30417.0     195.896503  0.773098  0.990893   0.984877   \n","...             ...         ...            ...       ...       ...        ...   \n","13606      0.765002     42508.0     231.515799  0.714574  0.990331   0.916603   \n","13607      0.752034     42494.0     231.526798  0.799943  0.990752   0.922015   \n","13608      0.734065     42569.0     231.631261  0.729932  0.989899   0.920188   \n","13609      0.741055     42667.0     231.653247  0.705389  0.987813   0.907906   \n","13610      0.786693     42600.0     231.686223  0.788962  0.989648   0.888380   \n","\n","       Compactness  ShapeFactor1  ShapeFactor2  ShapeFactor3  ShapeFactor4  \n","0         0.913358      0.007332      0.003147      0.834222      0.998724  \n","1         0.953861      0.006979      0.003564      0.909851      0.998430  \n","2         0.908774      0.007244      0.003048      0.825871      0.999066  \n","3         0.928329      0.007017      0.003215      0.861794      0.994199  \n","4         0.970516      0.006697      0.003665      0.941900      0.999166  \n","...            ...           ...           ...           ...           ...  \n","13606     0.801865      0.006858      0.001749      0.642988      0.998385  \n","13607     0.822252      0.006688      0.001815      0.676099      0.998219  \n","13608     0.822730      0.006681      0.001888      0.676884      0.996767  \n","13609     0.817457      0.006724      0.001852      0.646197      0.995222  \n","13610     0.784997      0.007001      0.001640      0.616221      0.993065  \n","\n","[13611 rows x 16 columns]"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["#Imputing Missing Values with KNN Imputer\n","from sklearn.impute import KNNImputer as knni\n","\n","imputer = knni(n_neighbors=5)\n","df_imputed = pd.DataFrame(imputer.fit_transform(df), columns = df.columns)\n","df_imputed"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28,"status":"ok","timestamp":1704299643303,"user":{"displayName":"Victor Hugo Schneider Lopes","userId":"10992764016890176856"},"user_tz":180},"id":"dsT5e4MCtxV0","outputId":"ad21aa9a-ce69-49f2-a163-52b65db38016"},"outputs":[{"name":"stdout","output_type":"stream","text":["          Area Perimeter MajorAxisLength MinorAxisLength AspectRatio  \\\n","         count     count           count           count       count   \n","Class                                                                  \n","BARBUNYA  1322      1322            1322            1322        1322   \n","BOMBAY     522       522             522             522         522   \n","CALI      1630      1630            1630            1630        1630   \n","DERMASON  3546      3546            3546            3546        3546   \n","HOROZ     1928      1928            1928            1928        1928   \n","SEKER     2027      2027            2027            2027        2027   \n","SIRA      2636      2636            2636            2636        2636   \n","\n","         Eccentricity ConvexArea EquivDiameter Extent Solidity Roundness  \\\n","                count      count         count  count    count     count   \n","Class                                                                      \n","BARBUNYA         1322       1322          1322   1322     1322      1322   \n","BOMBAY            522        522           522    522      522       522   \n","CALI             1630       1630          1630   1630     1630      1630   \n","DERMASON         3546       3546          3546   3546     3546      3546   \n","HOROZ            1928       1928          1928   1928     1928      1928   \n","SEKER            2027       2027          2027   2027     2027      2027   \n","SIRA             2636       2636          2636   2636     2636      2636   \n","\n","         Compactness ShapeFactor1 ShapeFactor2 ShapeFactor3 ShapeFactor4  \n","               count        count        count        count        count  \n","Class                                                                     \n","BARBUNYA        1322         1322         1322         1322         1322  \n","BOMBAY           522          522          522          522          522  \n","CALI            1630         1630         1630         1630         1630  \n","DERMASON        3546         3546         3546         3546         3546  \n","HOROZ           1928         1928         1928         1928         1928  \n","SEKER           2027         2027         2027         2027         2027  \n","SIRA            2636         2636         2636         2636         2636  \n"]}],"source":["#adding the labels\n","df_imputed['Class'] = targets\n","df_pre_missing_values = df.copy()\n","print(df_imputed.groupby('Class').agg(['count']))\n","df_imputed['Class'] = df_imputed['Class'].transform(lambda x: 0 if x == 'BARBUNYA' else (1 if x == 'BOMBAY' else (2 if x == 'CALI' else (3 if x == 'DERMASON' else (4 if x == 'HOROZ' else (5 if x == 'SEKER' else 6))))))"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1704299643304,"user":{"displayName":"Victor Hugo Schneider Lopes","userId":"10992764016890176856"},"user_tz":180},"id":"ML8h0BGivuxc","outputId":"1b86eee0-6240-47b7-f9ab-b4415b10932e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Pre Outlier Shape: (13611, 17)\n","[5 0 1 2 4 6 3]\n","       Area  Perimeter  MajorAxisLength  MinorAxisLength  AspectRatio  \\\n","Class                                                                   \n","0      1259       1259             1259             1259         1259   \n","1       497        497              497              497          497   \n","2      1580       1580             1580             1580         1580   \n","3      3402       3402             3402             3402         3402   \n","4      1805       1805             1805             1805         1805   \n","5      1890       1890             1890             1890         1890   \n","6      2535       2535             2535             2535         2535   \n","\n","       Eccentricity  ConvexArea  EquivDiameter  Extent  Solidity  Roundness  \\\n","Class                                                                         \n","0              1259        1259           1259    1259      1259       1259   \n","1               497         497            497     497       497        497   \n","2              1580        1580           1580    1580      1580       1580   \n","3              3402        3402           3402    3402      3402       3402   \n","4              1805        1805           1805    1805      1805       1805   \n","5              1890        1890           1890    1890      1890       1890   \n","6              2535        2535           2535    2535      2535       2535   \n","\n","       Compactness  ShapeFactor1  ShapeFactor2  ShapeFactor3  ShapeFactor4  \n","Class                                                                       \n","0             1259          1259          1259          1259          1259  \n","1              497           497           497           497           497  \n","2             1580          1580          1580          1580          1580  \n","3             3402          3402          3402          3402          3402  \n","4             1805          1805          1805          1805          1805  \n","5             1890          1890          1890          1890          1890  \n","6             2535          2535          2535          2535          2535  \n","Pos Outlier Shape: (12968, 17)\n"]}],"source":["#Outlier Removal with 3sigma\n","from scipy import stats\n","\n","\n","print(f'Pre Outlier Shape: {df_imputed.shape}')\n","df_no_outliers = df_imputed.copy()\n","\n","print(df_no_outliers['Class'].unique())\n","for i in df_no_outliers['Class'].unique():\n","    class_unique = df_no_outliers[df_no_outliers['Class'] == i]\n","    for feature in class_unique:\n","      upper = class_unique[feature].mean() + (3 * class_unique[feature].std())\n","      lower = class_unique[feature].mean() - (3 * class_unique[feature].std())\n","      excluded = pd.Series(class_unique[class_unique[feature] < lower].index)\n","      #print(excluded.values)\n","      df_no_outliers.drop(excluded.values, inplace = True, errors='ignore')\n","\n","print(df_no_outliers.groupby('Class').count())\n","print(f'Pos Outlier Shape: {df_no_outliers.shape}')\n"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":477,"status":"ok","timestamp":1704299643771,"user":{"displayName":"Victor Hugo Schneider Lopes","userId":"10992764016890176856"},"user_tz":180},"id":"LlYPv-ra64um","outputId":"aebb9962-bfc6-485c-fd04-c73b01817504"},"outputs":[{"name":"stdout","output_type":"stream","text":["         index  Area Perimeter MajorAxisLength MinorAxisLength AspectRatio  \\\n","         count count     count           count           count       count   \n","Class                                                                        \n","BARBUNYA  1259  1259      1259            1259            1259        1259   \n","BOMBAY     497   497       497             497             497         497   \n","CALI      1580  1580      1580            1580            1580        1580   \n","DERMASON  3402  3402      3402            3402            3402        3402   \n","HOROZ     1805  1805      1805            1805            1805        1805   \n","SEKER     1890  1890      1890            1890            1890        1890   \n","SIRA      2535  2535      2535            2535            2535        2535   \n","\n","         Eccentricity ConvexArea EquivDiameter Extent Solidity Roundness  \\\n","                count      count         count  count    count     count   \n","Class                                                                      \n","BARBUNYA         1259       1259          1259   1259     1259      1259   \n","BOMBAY            497        497           497    497      497       497   \n","CALI             1580       1580          1580   1580     1580      1580   \n","DERMASON         3402       3402          3402   3402     3402      3402   \n","HOROZ            1805       1805          1805   1805     1805      1805   \n","SEKER            1890       1890          1890   1890     1890      1890   \n","SIRA             2535       2535          2535   2535     2535      2535   \n","\n","         Compactness ShapeFactor1 ShapeFactor2 ShapeFactor3 ShapeFactor4  \n","               count        count        count        count        count  \n","Class                                                                     \n","BARBUNYA        1259         1259         1259         1259         1259  \n","BOMBAY           497          497          497          497          497  \n","CALI            1580         1580         1580         1580         1580  \n","DERMASON        3402         3402         3402         3402         3402  \n","HOROZ           1805         1805         1805         1805         1805  \n","SEKER           1890         1890         1890         1890         1890  \n","SIRA            2535         2535         2535         2535         2535  \n"]}],"source":["df_no_outliers['Class'] = df_no_outliers['Class'].transform(lambda x: 'BARBUNYA' if x == 0 else ('BOMBAY' if x == 1 else ('CALI' if x == 2 else ('DERMASON' if x == 3 else ('HOROZ' if x == 4 else ('SEKER' if x == 5 else 'SIRA'))))))\n","df_no_outliers = df_no_outliers.reset_index()\n","print(df_no_outliers.groupby('Class').agg(['count']))"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":444},"executionInfo":{"elapsed":30,"status":"ok","timestamp":1704299643772,"user":{"displayName":"Victor Hugo Schneider Lopes","userId":"10992764016890176856"},"user_tz":180},"id":"T8INyItCFB8j","outputId":"6acb2c39-28f7-429e-d200-d439fb647d74"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Area</th>\n","      <th>Perimeter</th>\n","      <th>MajorAxisLength</th>\n","      <th>MinorAxisLength</th>\n","      <th>AspectRatio</th>\n","      <th>Eccentricity</th>\n","      <th>ConvexArea</th>\n","      <th>EquivDiameter</th>\n","      <th>Extent</th>\n","      <th>Solidity</th>\n","      <th>Roundness</th>\n","      <th>Compactness</th>\n","      <th>ShapeFactor1</th>\n","      <th>ShapeFactor2</th>\n","      <th>ShapeFactor3</th>\n","      <th>ShapeFactor4</th>\n","      <th>Class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>28395.0</td>\n","      <td>610.2910</td>\n","      <td>208.178117</td>\n","      <td>173.888747</td>\n","      <td>1.197191</td>\n","      <td>0.549812</td>\n","      <td>28715.0</td>\n","      <td>190.141097</td>\n","      <td>0.763923</td>\n","      <td>0.988856</td>\n","      <td>0.958027</td>\n","      <td>0.913358</td>\n","      <td>0.007332</td>\n","      <td>0.003147</td>\n","      <td>0.834222</td>\n","      <td>0.998724</td>\n","      <td>SEKER</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>28734.0</td>\n","      <td>638.0180</td>\n","      <td>234.465344</td>\n","      <td>182.734419</td>\n","      <td>1.097356</td>\n","      <td>0.411785</td>\n","      <td>29172.0</td>\n","      <td>191.272751</td>\n","      <td>0.783968</td>\n","      <td>0.984986</td>\n","      <td>0.887034</td>\n","      <td>0.953861</td>\n","      <td>0.006979</td>\n","      <td>0.003564</td>\n","      <td>0.909851</td>\n","      <td>0.998430</td>\n","      <td>SEKER</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>29380.0</td>\n","      <td>624.1100</td>\n","      <td>212.826130</td>\n","      <td>175.931143</td>\n","      <td>1.209713</td>\n","      <td>0.562727</td>\n","      <td>29690.0</td>\n","      <td>193.410904</td>\n","      <td>0.778113</td>\n","      <td>0.989559</td>\n","      <td>0.947849</td>\n","      <td>0.908774</td>\n","      <td>0.007244</td>\n","      <td>0.003048</td>\n","      <td>0.825871</td>\n","      <td>0.999066</td>\n","      <td>SEKER</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>30477.0</td>\n","      <td>670.0330</td>\n","      <td>211.050155</td>\n","      <td>184.039050</td>\n","      <td>1.146768</td>\n","      <td>0.489478</td>\n","      <td>30970.0</td>\n","      <td>196.988633</td>\n","      <td>0.762402</td>\n","      <td>0.984081</td>\n","      <td>0.853080</td>\n","      <td>0.933374</td>\n","      <td>0.006925</td>\n","      <td>0.003242</td>\n","      <td>0.871186</td>\n","      <td>0.999049</td>\n","      <td>SEKER</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>30519.0</td>\n","      <td>666.3366</td>\n","      <td>212.996755</td>\n","      <td>182.737204</td>\n","      <td>1.165591</td>\n","      <td>0.513760</td>\n","      <td>34106.6</td>\n","      <td>197.124320</td>\n","      <td>0.770682</td>\n","      <td>0.989367</td>\n","      <td>0.967109</td>\n","      <td>0.925480</td>\n","      <td>0.006979</td>\n","      <td>0.003158</td>\n","      <td>0.856514</td>\n","      <td>0.998345</td>\n","      <td>SEKER</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>12963</th>\n","      <td>42097.0</td>\n","      <td>759.6960</td>\n","      <td>288.721612</td>\n","      <td>185.944705</td>\n","      <td>1.540691</td>\n","      <td>0.765002</td>\n","      <td>42508.0</td>\n","      <td>231.515799</td>\n","      <td>0.714574</td>\n","      <td>0.990331</td>\n","      <td>0.916603</td>\n","      <td>0.801865</td>\n","      <td>0.006858</td>\n","      <td>0.001749</td>\n","      <td>0.642988</td>\n","      <td>0.998385</td>\n","      <td>DERMASON</td>\n","    </tr>\n","    <tr>\n","      <th>12964</th>\n","      <td>42101.0</td>\n","      <td>757.4990</td>\n","      <td>281.576392</td>\n","      <td>190.713136</td>\n","      <td>1.476439</td>\n","      <td>0.752034</td>\n","      <td>42494.0</td>\n","      <td>231.526798</td>\n","      <td>0.799943</td>\n","      <td>0.990752</td>\n","      <td>0.922015</td>\n","      <td>0.822252</td>\n","      <td>0.006688</td>\n","      <td>0.001815</td>\n","      <td>0.676099</td>\n","      <td>0.998219</td>\n","      <td>DERMASON</td>\n","    </tr>\n","    <tr>\n","      <th>12965</th>\n","      <td>42139.0</td>\n","      <td>759.3210</td>\n","      <td>281.539928</td>\n","      <td>191.187979</td>\n","      <td>1.472582</td>\n","      <td>0.734065</td>\n","      <td>42569.0</td>\n","      <td>231.631261</td>\n","      <td>0.729932</td>\n","      <td>0.989899</td>\n","      <td>0.920188</td>\n","      <td>0.822730</td>\n","      <td>0.006681</td>\n","      <td>0.001888</td>\n","      <td>0.676884</td>\n","      <td>0.996767</td>\n","      <td>DERMASON</td>\n","    </tr>\n","    <tr>\n","      <th>12966</th>\n","      <td>42147.0</td>\n","      <td>763.7790</td>\n","      <td>283.382636</td>\n","      <td>190.275731</td>\n","      <td>1.489326</td>\n","      <td>0.741055</td>\n","      <td>42667.0</td>\n","      <td>231.653247</td>\n","      <td>0.705389</td>\n","      <td>0.987813</td>\n","      <td>0.907906</td>\n","      <td>0.817457</td>\n","      <td>0.006724</td>\n","      <td>0.001852</td>\n","      <td>0.646197</td>\n","      <td>0.995222</td>\n","      <td>DERMASON</td>\n","    </tr>\n","    <tr>\n","      <th>12967</th>\n","      <td>42159.0</td>\n","      <td>795.6046</td>\n","      <td>295.142741</td>\n","      <td>182.204716</td>\n","      <td>1.619841</td>\n","      <td>0.786693</td>\n","      <td>42600.0</td>\n","      <td>231.686223</td>\n","      <td>0.788962</td>\n","      <td>0.989648</td>\n","      <td>0.888380</td>\n","      <td>0.784997</td>\n","      <td>0.007001</td>\n","      <td>0.001640</td>\n","      <td>0.616221</td>\n","      <td>0.993065</td>\n","      <td>DERMASON</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>12968 rows Ã— 17 columns</p>\n","</div>"],"text/plain":["          Area  Perimeter  MajorAxisLength  MinorAxisLength  AspectRatio  \\\n","0      28395.0   610.2910       208.178117       173.888747     1.197191   \n","1      28734.0   638.0180       234.465344       182.734419     1.097356   \n","2      29380.0   624.1100       212.826130       175.931143     1.209713   \n","3      30477.0   670.0330       211.050155       184.039050     1.146768   \n","4      30519.0   666.3366       212.996755       182.737204     1.165591   \n","...        ...        ...              ...              ...          ...   \n","12963  42097.0   759.6960       288.721612       185.944705     1.540691   \n","12964  42101.0   757.4990       281.576392       190.713136     1.476439   \n","12965  42139.0   759.3210       281.539928       191.187979     1.472582   \n","12966  42147.0   763.7790       283.382636       190.275731     1.489326   \n","12967  42159.0   795.6046       295.142741       182.204716     1.619841   \n","\n","       Eccentricity  ConvexArea  EquivDiameter    Extent  Solidity  Roundness  \\\n","0          0.549812     28715.0     190.141097  0.763923  0.988856   0.958027   \n","1          0.411785     29172.0     191.272751  0.783968  0.984986   0.887034   \n","2          0.562727     29690.0     193.410904  0.778113  0.989559   0.947849   \n","3          0.489478     30970.0     196.988633  0.762402  0.984081   0.853080   \n","4          0.513760     34106.6     197.124320  0.770682  0.989367   0.967109   \n","...             ...         ...            ...       ...       ...        ...   \n","12963      0.765002     42508.0     231.515799  0.714574  0.990331   0.916603   \n","12964      0.752034     42494.0     231.526798  0.799943  0.990752   0.922015   \n","12965      0.734065     42569.0     231.631261  0.729932  0.989899   0.920188   \n","12966      0.741055     42667.0     231.653247  0.705389  0.987813   0.907906   \n","12967      0.786693     42600.0     231.686223  0.788962  0.989648   0.888380   \n","\n","       Compactness  ShapeFactor1  ShapeFactor2  ShapeFactor3  ShapeFactor4  \\\n","0         0.913358      0.007332      0.003147      0.834222      0.998724   \n","1         0.953861      0.006979      0.003564      0.909851      0.998430   \n","2         0.908774      0.007244      0.003048      0.825871      0.999066   \n","3         0.933374      0.006925      0.003242      0.871186      0.999049   \n","4         0.925480      0.006979      0.003158      0.856514      0.998345   \n","...            ...           ...           ...           ...           ...   \n","12963     0.801865      0.006858      0.001749      0.642988      0.998385   \n","12964     0.822252      0.006688      0.001815      0.676099      0.998219   \n","12965     0.822730      0.006681      0.001888      0.676884      0.996767   \n","12966     0.817457      0.006724      0.001852      0.646197      0.995222   \n","12967     0.784997      0.007001      0.001640      0.616221      0.993065   \n","\n","          Class  \n","0         SEKER  \n","1         SEKER  \n","2         SEKER  \n","3         SEKER  \n","4         SEKER  \n","...         ...  \n","12963  DERMASON  \n","12964  DERMASON  \n","12965  DERMASON  \n","12966  DERMASON  \n","12967  DERMASON  \n","\n","[12968 rows x 17 columns]"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["df_no_outliers = df_no_outliers.drop(['index'], axis='columns')\n","df_no_outliers"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":444},"executionInfo":{"elapsed":26,"status":"ok","timestamp":1704299643773,"user":{"displayName":"Victor Hugo Schneider Lopes","userId":"10992764016890176856"},"user_tz":180},"id":"nSe3jkEjynF6","outputId":"04b62876-29dc-4492-f654-eab5eaf38733"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Area</th>\n","      <th>Perimeter</th>\n","      <th>MajorAxisLength</th>\n","      <th>MinorAxisLength</th>\n","      <th>AspectRatio</th>\n","      <th>Eccentricity</th>\n","      <th>ConvexArea</th>\n","      <th>EquivDiameter</th>\n","      <th>Extent</th>\n","      <th>Solidity</th>\n","      <th>Roundness</th>\n","      <th>Compactness</th>\n","      <th>ShapeFactor1</th>\n","      <th>ShapeFactor2</th>\n","      <th>ShapeFactor3</th>\n","      <th>ShapeFactor4</th>\n","      <th>Class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.034338</td>\n","      <td>0.060789</td>\n","      <td>0.041240</td>\n","      <td>0.134028</td>\n","      <td>0.111808</td>\n","      <td>0.325651</td>\n","      <td>0.033564</td>\n","      <td>0.071030</td>\n","      <td>0.671024</td>\n","      <td>0.782167</td>\n","      <td>0.900083</td>\n","      <td>0.805007</td>\n","      <td>0.639626</td>\n","      <td>0.861066</td>\n","      <td>0.772174</td>\n","      <td>0.961860</td>\n","      <td>SEKER</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.035806</td>\n","      <td>0.080647</td>\n","      <td>0.088797</td>\n","      <td>0.160782</td>\n","      <td>0.039898</td>\n","      <td>0.068251</td>\n","      <td>0.035495</td>\n","      <td>0.073829</td>\n","      <td>0.735504</td>\n","      <td>0.637342</td>\n","      <td>0.682882</td>\n","      <td>0.924537</td>\n","      <td>0.590062</td>\n","      <td>1.000000</td>\n","      <td>0.909943</td>\n","      <td>0.950760</td>\n","      <td>SEKER</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.038603</td>\n","      <td>0.070686</td>\n","      <td>0.049649</td>\n","      <td>0.140205</td>\n","      <td>0.120827</td>\n","      <td>0.349735</td>\n","      <td>0.037684</td>\n","      <td>0.079116</td>\n","      <td>0.716671</td>\n","      <td>0.808464</td>\n","      <td>0.868945</td>\n","      <td>0.791481</td>\n","      <td>0.627322</td>\n","      <td>0.827843</td>\n","      <td>0.756960</td>\n","      <td>0.974802</td>\n","      <td>SEKER</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.043352</td>\n","      <td>0.103576</td>\n","      <td>0.046436</td>\n","      <td>0.164728</td>\n","      <td>0.075489</td>\n","      <td>0.213136</td>\n","      <td>0.043093</td>\n","      <td>0.087964</td>\n","      <td>0.666131</td>\n","      <td>0.603507</td>\n","      <td>0.579002</td>\n","      <td>0.864076</td>\n","      <td>0.582510</td>\n","      <td>0.892677</td>\n","      <td>0.839510</td>\n","      <td>0.974144</td>\n","      <td>SEKER</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.043534</td>\n","      <td>0.100928</td>\n","      <td>0.049958</td>\n","      <td>0.160791</td>\n","      <td>0.089046</td>\n","      <td>0.258418</td>\n","      <td>0.056347</td>\n","      <td>0.088299</td>\n","      <td>0.692766</td>\n","      <td>0.801283</td>\n","      <td>0.927870</td>\n","      <td>0.840783</td>\n","      <td>0.590131</td>\n","      <td>0.864735</td>\n","      <td>0.812782</td>\n","      <td>0.947517</td>\n","      <td>SEKER</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>12963</th>\n","      <td>0.093662</td>\n","      <td>0.167792</td>\n","      <td>0.186951</td>\n","      <td>0.170492</td>\n","      <td>0.359225</td>\n","      <td>0.726947</td>\n","      <td>0.091848</td>\n","      <td>0.173345</td>\n","      <td>0.512286</td>\n","      <td>0.837368</td>\n","      <td>0.773349</td>\n","      <td>0.475980</td>\n","      <td>0.573181</td>\n","      <td>0.394477</td>\n","      <td>0.423809</td>\n","      <td>0.949055</td>\n","      <td>DERMASON</td>\n","    </tr>\n","    <tr>\n","      <th>12964</th>\n","      <td>0.093680</td>\n","      <td>0.166218</td>\n","      <td>0.174025</td>\n","      <td>0.184915</td>\n","      <td>0.312946</td>\n","      <td>0.702763</td>\n","      <td>0.091788</td>\n","      <td>0.173373</td>\n","      <td>0.786890</td>\n","      <td>0.853099</td>\n","      <td>0.789907</td>\n","      <td>0.536145</td>\n","      <td>0.549250</td>\n","      <td>0.416539</td>\n","      <td>0.484126</td>\n","      <td>0.942756</td>\n","      <td>DERMASON</td>\n","    </tr>\n","    <tr>\n","      <th>12965</th>\n","      <td>0.093844</td>\n","      <td>0.167523</td>\n","      <td>0.173959</td>\n","      <td>0.186351</td>\n","      <td>0.310167</td>\n","      <td>0.669254</td>\n","      <td>0.092105</td>\n","      <td>0.173631</td>\n","      <td>0.561689</td>\n","      <td>0.821186</td>\n","      <td>0.784315</td>\n","      <td>0.537554</td>\n","      <td>0.548281</td>\n","      <td>0.440922</td>\n","      <td>0.485557</td>\n","      <td>0.887875</td>\n","      <td>DERMASON</td>\n","    </tr>\n","    <tr>\n","      <th>12966</th>\n","      <td>0.093879</td>\n","      <td>0.170716</td>\n","      <td>0.177293</td>\n","      <td>0.183592</td>\n","      <td>0.322228</td>\n","      <td>0.682289</td>\n","      <td>0.092519</td>\n","      <td>0.173685</td>\n","      <td>0.482741</td>\n","      <td>0.743124</td>\n","      <td>0.746742</td>\n","      <td>0.521995</td>\n","      <td>0.554244</td>\n","      <td>0.428826</td>\n","      <td>0.429655</td>\n","      <td>0.829460</td>\n","      <td>DERMASON</td>\n","    </tr>\n","    <tr>\n","      <th>12967</th>\n","      <td>0.093931</td>\n","      <td>0.193509</td>\n","      <td>0.198568</td>\n","      <td>0.159180</td>\n","      <td>0.416236</td>\n","      <td>0.767398</td>\n","      <td>0.092236</td>\n","      <td>0.173767</td>\n","      <td>0.751569</td>\n","      <td>0.811799</td>\n","      <td>0.687002</td>\n","      <td>0.426201</td>\n","      <td>0.593159</td>\n","      <td>0.358009</td>\n","      <td>0.375048</td>\n","      <td>0.747866</td>\n","      <td>DERMASON</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>12968 rows Ã— 17 columns</p>\n","</div>"],"text/plain":["           Area  Perimeter  MajorAxisLength  MinorAxisLength  AspectRatio  \\\n","0      0.034338   0.060789         0.041240         0.134028     0.111808   \n","1      0.035806   0.080647         0.088797         0.160782     0.039898   \n","2      0.038603   0.070686         0.049649         0.140205     0.120827   \n","3      0.043352   0.103576         0.046436         0.164728     0.075489   \n","4      0.043534   0.100928         0.049958         0.160791     0.089046   \n","...         ...        ...              ...              ...          ...   \n","12963  0.093662   0.167792         0.186951         0.170492     0.359225   \n","12964  0.093680   0.166218         0.174025         0.184915     0.312946   \n","12965  0.093844   0.167523         0.173959         0.186351     0.310167   \n","12966  0.093879   0.170716         0.177293         0.183592     0.322228   \n","12967  0.093931   0.193509         0.198568         0.159180     0.416236   \n","\n","       Eccentricity  ConvexArea  EquivDiameter    Extent  Solidity  Roundness  \\\n","0          0.325651    0.033564       0.071030  0.671024  0.782167   0.900083   \n","1          0.068251    0.035495       0.073829  0.735504  0.637342   0.682882   \n","2          0.349735    0.037684       0.079116  0.716671  0.808464   0.868945   \n","3          0.213136    0.043093       0.087964  0.666131  0.603507   0.579002   \n","4          0.258418    0.056347       0.088299  0.692766  0.801283   0.927870   \n","...             ...         ...            ...       ...       ...        ...   \n","12963      0.726947    0.091848       0.173345  0.512286  0.837368   0.773349   \n","12964      0.702763    0.091788       0.173373  0.786890  0.853099   0.789907   \n","12965      0.669254    0.092105       0.173631  0.561689  0.821186   0.784315   \n","12966      0.682289    0.092519       0.173685  0.482741  0.743124   0.746742   \n","12967      0.767398    0.092236       0.173767  0.751569  0.811799   0.687002   \n","\n","       Compactness  ShapeFactor1  ShapeFactor2  ShapeFactor3  ShapeFactor4  \\\n","0         0.805007      0.639626      0.861066      0.772174      0.961860   \n","1         0.924537      0.590062      1.000000      0.909943      0.950760   \n","2         0.791481      0.627322      0.827843      0.756960      0.974802   \n","3         0.864076      0.582510      0.892677      0.839510      0.974144   \n","4         0.840783      0.590131      0.864735      0.812782      0.947517   \n","...            ...           ...           ...           ...           ...   \n","12963     0.475980      0.573181      0.394477      0.423809      0.949055   \n","12964     0.536145      0.549250      0.416539      0.484126      0.942756   \n","12965     0.537554      0.548281      0.440922      0.485557      0.887875   \n","12966     0.521995      0.554244      0.428826      0.429655      0.829460   \n","12967     0.426201      0.593159      0.358009      0.375048      0.747866   \n","\n","          Class  \n","0         SEKER  \n","1         SEKER  \n","2         SEKER  \n","3         SEKER  \n","4         SEKER  \n","...         ...  \n","12963  DERMASON  \n","12964  DERMASON  \n","12965  DERMASON  \n","12966  DERMASON  \n","12967  DERMASON  \n","\n","[12968 rows x 17 columns]"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["#Normalization with min max\n","from sklearn.preprocessing import MinMaxScaler\n","\n","scaler = MinMaxScaler()\n","scaler.fit_transform(df_no_outliers[cols])\n","df_scaled = pd.DataFrame(scaler.transform(df_no_outliers[cols]), columns = cols)\n","\n","df_scaled['Class'] = df_no_outliers['Class']\n","df_scaled"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25560,"status":"ok","timestamp":1704300146535,"user":{"displayName":"Victor Hugo Schneider Lopes","userId":"10992764016890176856"},"user_tz":180},"id":"0dBs8lW22D02","outputId":"8d6a3888-7680-4a0b-f55b-0d129742eeda"},"outputs":[{"name":"stdout","output_type":"stream","text":["Iteration 1, loss = 1.22107857\n","Iteration 2, loss = 0.76643404\n","Iteration 3, loss = 0.63213190\n","Iteration 4, loss = 0.52392193\n","Iteration 5, loss = 0.54624648\n","Iteration 6, loss = 0.51383141\n","Iteration 7, loss = 0.40127469\n","Iteration 8, loss = 0.35777908\n","Iteration 9, loss = 0.34143580\n","Iteration 10, loss = 0.31721293\n","Iteration 11, loss = 0.29474276\n","Iteration 12, loss = 0.26661348\n","Iteration 13, loss = 0.26272980\n","Iteration 14, loss = 0.25117106\n","Iteration 15, loss = 0.24245911\n","Iteration 16, loss = 0.24459492\n","Iteration 17, loss = 0.21999182\n","Iteration 18, loss = 0.26594107\n","Iteration 19, loss = 0.21318170\n","Iteration 20, loss = 0.22176277\n","Iteration 21, loss = 0.19917165\n","Iteration 22, loss = 0.21017700\n","Iteration 23, loss = 0.19722509\n","Iteration 24, loss = 0.19222393\n","Iteration 25, loss = 0.18663648\n","Iteration 26, loss = 0.17440378\n","Iteration 27, loss = 0.19096054\n","Iteration 28, loss = 0.18355782\n","Iteration 29, loss = 0.19776407\n","Iteration 30, loss = 0.18853391\n","Iteration 31, loss = 0.18944494\n","Iteration 32, loss = 0.17727277\n","Iteration 33, loss = 0.18016272\n","Iteration 34, loss = 0.18787619\n","Iteration 35, loss = 0.16908949\n","Iteration 36, loss = 0.17634332\n","Iteration 37, loss = 0.17070210\n","Iteration 38, loss = 0.17709858\n","Iteration 39, loss = 0.18583448\n","Iteration 40, loss = 0.19360125\n","Iteration 41, loss = 0.16235075\n","Iteration 42, loss = 0.17866449\n","Iteration 43, loss = 0.17105278\n","Iteration 44, loss = 0.16649475\n","Iteration 45, loss = 0.19390031\n","Iteration 46, loss = 0.17861108\n","Iteration 47, loss = 0.19755378\n","Iteration 48, loss = 0.19372572\n","Iteration 49, loss = 0.19057306\n","Iteration 50, loss = 0.18593866\n","Iteration 51, loss = 0.17887266\n","Iteration 52, loss = 0.16929669\n","Training loss did not improve more than tol=0.001000 for 10 consecutive epochs. Stopping.\n","Iteration 1, loss = 1.24245019\n","Iteration 2, loss = 0.82826396\n","Iteration 3, loss = 0.70583424\n","Iteration 4, loss = 0.58006942\n","Iteration 5, loss = 0.52287217\n","Iteration 6, loss = 0.47153936\n","Iteration 7, loss = 0.46256457\n","Iteration 8, loss = 0.44714179\n","Iteration 9, loss = 0.42337632\n","Iteration 10, loss = 0.44863186\n","Iteration 11, loss = 0.43549055\n","Iteration 12, loss = 0.43134496\n","Iteration 13, loss = 0.42256376\n","Iteration 14, loss = 0.38093621\n","Iteration 15, loss = 0.37735478\n","Iteration 16, loss = 0.38811583\n","Iteration 17, loss = 0.35609644\n","Iteration 18, loss = 0.36462490\n","Iteration 19, loss = 0.34292805\n","Iteration 20, loss = 0.38131606\n","Iteration 21, loss = 0.35878625\n","Iteration 22, loss = 0.32452681\n","Iteration 23, loss = 0.29564221\n","Iteration 24, loss = 0.32579012\n","Iteration 25, loss = 0.30652834\n","Iteration 26, loss = 0.34808216\n","Iteration 27, loss = 0.31983909\n","Iteration 28, loss = 0.31986602\n","Iteration 29, loss = 0.33633624\n","Iteration 30, loss = 0.29512234\n","Iteration 31, loss = 0.29689768\n","Iteration 32, loss = 0.30649212\n","Iteration 33, loss = 0.33061524\n","Iteration 34, loss = 0.28551666\n","Iteration 35, loss = 0.28895353\n","Iteration 36, loss = 0.32932860\n","Iteration 37, loss = 0.29669381\n","Iteration 38, loss = 0.29340528\n","Iteration 39, loss = 0.36600019\n","Iteration 40, loss = 0.33996919\n","Iteration 41, loss = 0.31800858\n","Iteration 42, loss = 0.30864884\n","Iteration 43, loss = 0.32121949\n","Iteration 44, loss = 0.30581388\n","Iteration 45, loss = 0.28247719\n","Iteration 46, loss = 0.29695458\n","Iteration 47, loss = 0.28650544\n","Iteration 48, loss = 0.32902974\n","Iteration 49, loss = 0.30103070\n","Iteration 50, loss = 0.28350381\n","Iteration 51, loss = 0.32098013\n","Iteration 52, loss = 0.28066989\n","Iteration 53, loss = 0.32289667\n","Iteration 54, loss = 0.31139701\n","Iteration 55, loss = 0.28790420\n","Iteration 56, loss = 0.28397488\n","Iteration 57, loss = 0.33589908\n","Iteration 58, loss = 0.29877421\n","Iteration 59, loss = 0.31931026\n","Iteration 60, loss = 0.30246229\n","Iteration 61, loss = 0.30938067\n","Iteration 62, loss = 0.28965199\n","Iteration 63, loss = 0.27358218\n","Iteration 64, loss = 0.28394503\n","Iteration 65, loss = 0.28308345\n","Iteration 66, loss = 0.29676305\n","Iteration 67, loss = 0.29397236\n","Iteration 68, loss = 0.32161725\n","Iteration 69, loss = 0.27922602\n","Iteration 70, loss = 0.29796877\n","Iteration 71, loss = 0.32025356\n","Iteration 72, loss = 0.30015083\n","Iteration 73, loss = 0.28238659\n","Iteration 74, loss = 0.28150368\n","Training loss did not improve more than tol=0.001000 for 10 consecutive epochs. Stopping.\n","Iteration 1, loss = 1.23765439\n","Iteration 2, loss = 0.83826381\n","Iteration 3, loss = 0.71022947\n","Iteration 4, loss = 0.52021897\n","Iteration 5, loss = 0.49795033\n","Iteration 6, loss = 0.44480870\n","Iteration 7, loss = 0.40422634\n","Iteration 8, loss = 0.38894491\n","Iteration 9, loss = 0.36835420\n","Iteration 10, loss = 0.38776268\n","Iteration 11, loss = 0.32797939\n","Iteration 12, loss = 0.31813058\n","Iteration 13, loss = 0.32398347\n","Iteration 14, loss = 0.29859323\n","Iteration 15, loss = 0.30686937\n","Iteration 16, loss = 0.32098796\n","Iteration 17, loss = 0.28653352\n","Iteration 18, loss = 0.28284734\n","Iteration 19, loss = 0.27805998\n","Iteration 20, loss = 0.31607456\n","Iteration 21, loss = 0.27144749\n","Iteration 22, loss = 0.28350175\n","Iteration 23, loss = 0.29677106\n","Iteration 24, loss = 0.30421442\n","Iteration 25, loss = 0.28294795\n","Iteration 26, loss = 0.31533822\n","Iteration 27, loss = 0.26970061\n","Iteration 28, loss = 0.28520648\n","Iteration 29, loss = 0.29113054\n","Iteration 30, loss = 0.30797476\n","Iteration 31, loss = 0.26643792\n","Iteration 32, loss = 0.27909772\n","Iteration 33, loss = 0.26474224\n","Iteration 34, loss = 0.26544542\n","Iteration 35, loss = 0.27464314\n","Iteration 36, loss = 0.28307138\n","Iteration 37, loss = 0.25889122\n","Iteration 38, loss = 0.28210353\n","Iteration 39, loss = 0.29186946\n","Iteration 40, loss = 0.30987184\n","Iteration 41, loss = 0.28325497\n","Iteration 42, loss = 0.25974808\n","Iteration 43, loss = 0.26906751\n","Iteration 44, loss = 0.25536811\n","Iteration 45, loss = 0.26261685\n","Iteration 46, loss = 0.28411462\n","Iteration 47, loss = 0.26123963\n","Iteration 48, loss = 0.29019746\n","Iteration 49, loss = 0.29930068\n","Iteration 50, loss = 0.29445823\n","Iteration 51, loss = 0.29523400\n","Iteration 52, loss = 0.28718446\n","Iteration 53, loss = 0.28841885\n","Iteration 54, loss = 0.28757460\n","Iteration 55, loss = 0.28350555\n","Training loss did not improve more than tol=0.001000 for 10 consecutive epochs. Stopping.\n","Iteration 1, loss = 1.24173878\n","Iteration 2, loss = 0.85083235\n","Iteration 3, loss = 0.65365742\n","Iteration 4, loss = 0.51670243\n","Iteration 5, loss = 0.47162345\n","Iteration 6, loss = 0.37267811\n","Iteration 7, loss = 0.30580656\n","Iteration 8, loss = 0.27801410\n","Iteration 9, loss = 0.30606573\n","Iteration 10, loss = 0.25384838\n","Iteration 11, loss = 0.25259101\n","Iteration 12, loss = 0.26845400\n","Iteration 13, loss = 0.25382532\n","Iteration 14, loss = 0.27508606\n","Iteration 15, loss = 0.27008950\n","Iteration 16, loss = 0.25942305\n","Iteration 17, loss = 0.26590104\n","Iteration 18, loss = 0.26723301\n","Iteration 19, loss = 0.24290352\n","Iteration 20, loss = 0.26173633\n","Iteration 21, loss = 0.24011854\n","Iteration 22, loss = 0.25155703\n","Iteration 23, loss = 0.25792806\n","Iteration 24, loss = 0.25160473\n","Iteration 25, loss = 0.28383659\n","Iteration 26, loss = 0.25546123\n","Iteration 27, loss = 0.26459488\n","Iteration 28, loss = 0.24819703\n","Iteration 29, loss = 0.25255418\n","Iteration 30, loss = 0.26433860\n","Iteration 31, loss = 0.26534691\n","Iteration 32, loss = 0.25165109\n","Training loss did not improve more than tol=0.001000 for 10 consecutive epochs. Stopping.\n","Iteration 1, loss = 1.25107542\n","Iteration 2, loss = 0.84988678\n","Iteration 3, loss = 0.76964311\n","Iteration 4, loss = 0.67363913\n","Iteration 5, loss = 0.55512320\n","Iteration 6, loss = 0.49545018\n","Iteration 7, loss = 0.45601086\n","Iteration 8, loss = 0.45877040\n","Iteration 9, loss = 0.45793708\n","Iteration 10, loss = 0.44335439\n","Iteration 11, loss = 0.45740361\n","Iteration 12, loss = 0.41228332\n","Iteration 13, loss = 0.45321087\n","Iteration 14, loss = 0.42556902\n","Iteration 15, loss = 0.42494019\n","Iteration 16, loss = 0.38207850\n","Iteration 17, loss = 0.35479429\n","Iteration 18, loss = 0.35374759\n","Iteration 19, loss = 0.34088290\n","Iteration 20, loss = 0.38480181\n","Iteration 21, loss = 0.33218549\n","Iteration 22, loss = 0.34200080\n","Iteration 23, loss = 0.32799202\n","Iteration 24, loss = 0.35468330\n","Iteration 25, loss = 0.32244768\n","Iteration 26, loss = 0.35889776\n","Iteration 27, loss = 0.35330517\n","Iteration 28, loss = 0.32724790\n","Iteration 29, loss = 0.33121446\n","Iteration 30, loss = 0.34810805\n","Iteration 31, loss = 0.30958577\n","Iteration 32, loss = 0.30159288\n","Iteration 33, loss = 0.33871359\n","Iteration 34, loss = 0.29869297\n","Iteration 35, loss = 0.31913125\n","Iteration 36, loss = 0.31509494\n","Iteration 37, loss = 0.29948417\n","Iteration 38, loss = 0.31650571\n","Iteration 39, loss = 0.35631920\n","Iteration 40, loss = 0.40115339\n","Iteration 41, loss = 0.33937171\n","Iteration 42, loss = 0.30706698\n","Iteration 43, loss = 0.32965177\n","Iteration 44, loss = 0.32648853\n","Iteration 45, loss = 0.31189263\n","Training loss did not improve more than tol=0.001000 for 10 consecutive epochs. Stopping.\n","Iteration 1, loss = 1.25060594\n","Iteration 2, loss = 0.84543543\n","Iteration 3, loss = 0.78833918\n","Iteration 4, loss = 0.69882436\n","Iteration 5, loss = 0.60088420\n","Iteration 6, loss = 0.50357581\n","Iteration 7, loss = 0.43906076\n","Iteration 8, loss = 0.41287137\n","Iteration 9, loss = 0.39828004\n","Iteration 10, loss = 0.40506513\n","Iteration 11, loss = 0.37363825\n","Iteration 12, loss = 0.34541213\n","Iteration 13, loss = 0.34185674\n","Iteration 14, loss = 0.35592740\n","Iteration 15, loss = 0.40000883\n","Iteration 16, loss = 0.34402210\n","Iteration 17, loss = 0.36390562\n","Iteration 18, loss = 0.32810372\n","Iteration 19, loss = 0.32969886\n","Iteration 20, loss = 0.32572429\n","Iteration 21, loss = 0.32053794\n","Iteration 22, loss = 0.32617037\n","Iteration 23, loss = 0.31252273\n","Iteration 24, loss = 0.33014771\n","Iteration 25, loss = 0.32181924\n","Iteration 26, loss = 0.31817579\n","Iteration 27, loss = 0.32631182\n","Iteration 28, loss = 0.31209693\n","Iteration 29, loss = 0.32033213\n","Iteration 30, loss = 0.28194837\n","Iteration 31, loss = 0.30711036\n","Iteration 32, loss = 0.28978010\n","Iteration 33, loss = 0.30006849\n","Iteration 34, loss = 0.29327186\n","Iteration 35, loss = 0.34427348\n","Iteration 36, loss = 0.31552037\n","Iteration 37, loss = 0.28879035\n","Iteration 38, loss = 0.32003864\n","Iteration 39, loss = 0.33511215\n","Iteration 40, loss = 0.32891452\n","Iteration 41, loss = 0.28098276\n","Training loss did not improve more than tol=0.001000 for 10 consecutive epochs. Stopping.\n","Iteration 1, loss = 1.26279939\n","Iteration 2, loss = 0.86115473\n","Iteration 3, loss = 0.78364618\n","Iteration 4, loss = 0.71215786\n","Iteration 5, loss = 0.51133515\n","Iteration 6, loss = 0.41113405\n","Iteration 7, loss = 0.37453391\n","Iteration 8, loss = 0.42237264\n","Iteration 9, loss = 0.39726912\n","Iteration 10, loss = 0.37512379\n","Iteration 11, loss = 0.35882594\n","Iteration 12, loss = 0.36219338\n","Iteration 13, loss = 0.35227584\n","Iteration 14, loss = 0.37039715\n","Iteration 15, loss = 0.40062663\n","Iteration 16, loss = 0.36445386\n","Iteration 17, loss = 0.35208405\n","Iteration 18, loss = 0.33810355\n","Iteration 19, loss = 0.35221273\n","Iteration 20, loss = 0.34268478\n","Iteration 21, loss = 0.37714854\n","Iteration 22, loss = 0.33947344\n","Iteration 23, loss = 0.33069907\n","Iteration 24, loss = 0.29024040\n","Iteration 25, loss = 0.33453774\n","Iteration 26, loss = 0.29624624\n","Iteration 27, loss = 0.30102104\n","Iteration 28, loss = 0.29848520\n","Iteration 29, loss = 0.30118448\n","Iteration 30, loss = 0.30512331\n","Iteration 31, loss = 0.28327329\n","Iteration 32, loss = 0.30435190\n","Iteration 33, loss = 0.29486677\n","Iteration 34, loss = 0.29269259\n","Iteration 35, loss = 0.30340036\n","Iteration 36, loss = 0.30862206\n","Iteration 37, loss = 0.28431016\n","Iteration 38, loss = 0.26795957\n","Iteration 39, loss = 0.31637320\n","Iteration 40, loss = 0.26926538\n","Iteration 41, loss = 0.28830338\n","Iteration 42, loss = 0.30866298\n","Iteration 43, loss = 0.28189695\n","Iteration 44, loss = 0.27620106\n","Iteration 45, loss = 0.29042095\n","Iteration 46, loss = 0.34633595\n","Iteration 47, loss = 0.29691194\n","Iteration 48, loss = 0.28908365\n","Iteration 49, loss = 0.28327524\n","Training loss did not improve more than tol=0.001000 for 10 consecutive epochs. Stopping.\n","Iteration 1, loss = 1.24433655\n","Iteration 2, loss = 0.84838959\n","Iteration 3, loss = 0.68739103\n","Iteration 4, loss = 0.54984287\n","Iteration 5, loss = 0.51926017\n","Iteration 6, loss = 0.44512562\n","Iteration 7, loss = 0.43269177\n","Iteration 8, loss = 0.38110563\n","Iteration 9, loss = 0.37345393\n","Iteration 10, loss = 0.34185175\n","Iteration 11, loss = 0.35429852\n","Iteration 12, loss = 0.30727258\n","Iteration 13, loss = 0.29685325\n","Iteration 14, loss = 0.29865090\n","Iteration 15, loss = 0.29959426\n","Iteration 16, loss = 0.26390187\n","Iteration 17, loss = 0.26730436\n","Iteration 18, loss = 0.27430741\n","Iteration 19, loss = 0.26335569\n","Iteration 20, loss = 0.27874971\n","Iteration 21, loss = 0.26122949\n","Iteration 22, loss = 0.28655102\n","Iteration 23, loss = 0.26144046\n","Iteration 24, loss = 0.25464767\n","Iteration 25, loss = 0.26746417\n","Iteration 26, loss = 0.26320162\n","Iteration 27, loss = 0.25799757\n","Iteration 28, loss = 0.26263679\n","Iteration 29, loss = 0.26323674\n","Iteration 30, loss = 0.26650613\n","Iteration 31, loss = 0.26241930\n","Iteration 32, loss = 0.25199566\n","Iteration 33, loss = 0.27202719\n","Iteration 34, loss = 0.25149359\n","Iteration 35, loss = 0.24337829\n","Iteration 36, loss = 0.25657405\n","Iteration 37, loss = 0.25651214\n","Iteration 38, loss = 0.27372779\n","Iteration 39, loss = 0.28413888\n","Iteration 40, loss = 0.26299541\n","Iteration 41, loss = 0.27499591\n","Iteration 42, loss = 0.26541527\n","Iteration 43, loss = 0.28581653\n","Iteration 44, loss = 0.25421438\n","Iteration 45, loss = 0.24437065\n","Iteration 46, loss = 0.23828591\n","Iteration 47, loss = 0.29100354\n","Iteration 48, loss = 0.24714562\n","Iteration 49, loss = 0.27381678\n","Iteration 50, loss = 0.27010531\n","Iteration 51, loss = 0.28299432\n","Iteration 52, loss = 0.27722488\n","Iteration 53, loss = 0.26387925\n","Iteration 54, loss = 0.27018493\n","Iteration 55, loss = 0.24968355\n","Iteration 56, loss = 0.25160319\n","Iteration 57, loss = 0.26780641\n","Training loss did not improve more than tol=0.001000 for 10 consecutive epochs. Stopping.\n","Iteration 1, loss = 1.27332565\n","Iteration 2, loss = 0.96272759\n","Iteration 3, loss = 0.77995915\n","Iteration 4, loss = 0.62397513\n","Iteration 5, loss = 0.48721212\n","Iteration 6, loss = 0.47965055\n","Iteration 7, loss = 0.44428090\n","Iteration 8, loss = 0.41396125\n","Iteration 9, loss = 0.42330408\n","Iteration 10, loss = 0.41289426\n","Iteration 11, loss = 0.38185506\n","Iteration 12, loss = 0.35968557\n","Iteration 13, loss = 0.32335024\n","Iteration 14, loss = 0.26848248\n","Iteration 15, loss = 0.27600803\n","Iteration 16, loss = 0.26163674\n","Iteration 17, loss = 0.23872950\n","Iteration 18, loss = 0.23617847\n","Iteration 19, loss = 0.29306670\n","Iteration 20, loss = 0.25735268\n","Iteration 21, loss = 0.24154651\n","Iteration 22, loss = 0.24554432\n","Iteration 23, loss = 0.25935536\n","Iteration 24, loss = 0.22988998\n","Iteration 25, loss = 0.25064212\n","Iteration 26, loss = 0.23428084\n","Iteration 27, loss = 0.24125264\n","Iteration 28, loss = 0.23329827\n","Iteration 29, loss = 0.21990176\n","Iteration 30, loss = 0.23581521\n","Iteration 31, loss = 0.27683010\n","Iteration 32, loss = 0.23043871\n","Iteration 33, loss = 0.25806892\n","Iteration 34, loss = 0.23435873\n","Iteration 35, loss = 0.22973643\n","Iteration 36, loss = 0.22862572\n","Iteration 37, loss = 0.25304890\n","Iteration 38, loss = 0.24293915\n","Iteration 39, loss = 0.23307061\n","Iteration 40, loss = 0.24351159\n","Training loss did not improve more than tol=0.001000 for 10 consecutive epochs. Stopping.\n","Iteration 1, loss = 1.24700352\n","Iteration 2, loss = 0.85977199\n","Iteration 3, loss = 0.63277428\n","Iteration 4, loss = 0.53595511\n","Iteration 5, loss = 0.53952976\n","Iteration 6, loss = 0.48531758\n","Iteration 7, loss = 0.38195483\n","Iteration 8, loss = 0.35028107\n","Iteration 9, loss = 0.35749274\n","Iteration 10, loss = 0.34458413\n","Iteration 11, loss = 0.35339988\n","Iteration 12, loss = 0.32483041\n","Iteration 13, loss = 0.35454019\n","Iteration 14, loss = 0.35967189\n","Iteration 15, loss = 0.34753942\n","Iteration 16, loss = 0.38374749\n","Iteration 17, loss = 0.32526277\n","Iteration 18, loss = 0.29608695\n","Iteration 19, loss = 0.28327202\n","Iteration 20, loss = 0.29313672\n","Iteration 21, loss = 0.27495181\n","Iteration 22, loss = 0.25294515\n","Iteration 23, loss = 0.24995802\n","Iteration 24, loss = 0.24561032\n","Iteration 25, loss = 0.24339835\n","Iteration 26, loss = 0.24524601\n","Iteration 27, loss = 0.24980518\n","Iteration 28, loss = 0.24464820\n","Iteration 29, loss = 0.22684953\n","Iteration 30, loss = 0.27005272\n","Iteration 31, loss = 0.23946239\n","Iteration 32, loss = 0.25502757\n","Iteration 33, loss = 0.24811328\n","Iteration 34, loss = 0.24753218\n","Iteration 35, loss = 0.24227994\n","Iteration 36, loss = 0.22021572\n","Iteration 37, loss = 0.22014925\n","Iteration 38, loss = 0.22111961\n","Iteration 39, loss = 0.22679548\n","Iteration 40, loss = 0.23003072\n","Iteration 41, loss = 0.22296502\n","Iteration 42, loss = 0.27023921\n","Iteration 43, loss = 0.24134881\n","Iteration 44, loss = 0.24389757\n","Iteration 45, loss = 0.23386477\n","Iteration 46, loss = 0.23394501\n","Iteration 47, loss = 0.24516550\n","Training loss did not improve more than tol=0.001000 for 10 consecutive epochs. Stopping.\n","Experimento 2\n","AcurÃ¡cia MÃ©dia: 88.28%\n","PrecisÃ£o MÃ©dia: 91.37%\n","RevocaÃ§Ã£o MÃ©dia: 89.53%\n","F1-Score MÃ©dio: 89.29%\n"]}],"source":["from sklearn.neural_network import MLPClassifier\n","from sklearn.model_selection import cross_validate\n","\n","\n","x_train = df_scaled.iloc[:, 0:16]\n","y_train = df_scaled.iloc[:, 16]\n","classifier = MLPClassifier(activation='logistic', solver='adam', alpha=1e-5, hidden_layer_sizes=(12, 3), random_state=1, verbose=True, learning_rate_init=0.3, tol=1e-3, max_iter=500)\n","scoring = {'acc' : 'accuracy',\n","           'prec' : 'precision_macro',\n","           'recall' : 'recall_macro',\n","           'f1' : 'f1_macro'}\n","\n","\n","y_pred = cross_validate(classifier, x_train, y_train, cv=10, scoring=scoring, return_train_score=True)\n","print('Experimento 2')\n","print('AcurÃ¡cia MÃ©dia: ' + '%.2f' % (np.mean(y_pred['test_acc'])*100) + '%')\n","print('PrecisÃ£o MÃ©dia: ' + '%.2f' % (np.mean(y_pred['test_prec'])*100) + '%')\n","print('RevocaÃ§Ã£o MÃ©dia: ' + '%.2f' % (np.mean(y_pred['test_recall'])*100) + '%')\n","print('F1-Score MÃ©dio: ' + '%.2f' % (np.mean(y_pred['test_f1'])*100) + '%')\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOcxPcBSxBGnyxp1DZzHnhO","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":0}
