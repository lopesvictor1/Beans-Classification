{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn.objects as so\n",
    "from ucimlrepo import fetch_ucirepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "beans = fetch_ucirepo(id=602)\n",
    "df = beans.data.features\n",
    "targets = beans.data.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Area', 'Perimeter', 'MajorAxisLength', 'MinorAxisLength', 'AspectRatio', 'Eccentricity', 'ConvexArea', 'EquivDiameter', 'Extent', 'Solidity', 'Roundness', 'Compactness', 'ShapeFactor1', 'ShapeFactor2', 'ShapeFactor3', 'ShapeFactor4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.39141671\n",
      "Iteration 2, loss = 1.03304955\n",
      "Iteration 3, loss = 0.96023082\n",
      "Iteration 4, loss = 0.86651706\n",
      "Iteration 5, loss = 0.82105824\n",
      "Iteration 6, loss = 0.79003165\n",
      "Iteration 7, loss = 0.77562245\n",
      "Iteration 8, loss = 0.79078257\n",
      "Iteration 9, loss = 0.76586878\n",
      "Iteration 10, loss = 0.73905027\n",
      "Iteration 11, loss = 0.74094906\n",
      "Iteration 12, loss = 0.73931242\n",
      "Iteration 13, loss = 0.72808170\n",
      "Iteration 14, loss = 0.72651871\n",
      "Iteration 15, loss = 0.72156565\n",
      "Iteration 16, loss = 0.73119984\n",
      "Iteration 17, loss = 0.72374600\n",
      "Iteration 18, loss = 0.71303625\n",
      "Iteration 19, loss = 0.72941542\n",
      "Iteration 20, loss = 0.69478531\n",
      "Iteration 21, loss = 0.70380477\n",
      "Iteration 22, loss = 0.69875763\n",
      "Iteration 23, loss = 0.71682303\n",
      "Iteration 24, loss = 0.70617741\n",
      "Iteration 25, loss = 0.70696931\n",
      "Iteration 26, loss = 0.68399768\n",
      "Iteration 27, loss = 0.73331474\n",
      "Iteration 28, loss = 0.71176157\n",
      "Iteration 29, loss = 0.71603196\n",
      "Iteration 30, loss = 0.70725045\n",
      "Iteration 31, loss = 0.73028709\n",
      "Iteration 32, loss = 0.71257890\n",
      "Iteration 33, loss = 0.70373183\n",
      "Iteration 34, loss = 0.70574995\n",
      "Iteration 35, loss = 0.72474402\n",
      "Iteration 36, loss = 0.67488888\n",
      "Iteration 37, loss = 0.66927671\n",
      "Iteration 38, loss = 0.74537420\n",
      "Iteration 39, loss = 0.77463394\n",
      "Iteration 40, loss = 0.76712949\n",
      "Iteration 41, loss = 0.66121354\n",
      "Iteration 42, loss = 0.64070447\n",
      "Iteration 43, loss = 0.59485640\n",
      "Iteration 44, loss = 0.57162316\n",
      "Iteration 45, loss = 0.57682453\n",
      "Iteration 46, loss = 0.53456443\n",
      "Iteration 47, loss = 0.50799913\n",
      "Iteration 48, loss = 0.52146017\n",
      "Iteration 49, loss = 0.49946544\n",
      "Iteration 50, loss = 0.47945154\n",
      "Iteration 51, loss = 0.47455712\n",
      "Iteration 52, loss = 0.49323936\n",
      "Iteration 53, loss = 0.48510205\n",
      "Iteration 54, loss = 0.47040059\n",
      "Iteration 55, loss = 0.47240985\n",
      "Iteration 56, loss = 0.43854126\n",
      "Iteration 57, loss = 0.43931781\n",
      "Iteration 58, loss = 0.45558531\n",
      "Iteration 59, loss = 0.43244144\n",
      "Iteration 60, loss = 0.44365368\n",
      "Iteration 61, loss = 0.41373030\n",
      "Iteration 62, loss = 0.42645887\n",
      "Iteration 63, loss = 0.41633337\n",
      "Iteration 64, loss = 0.41827483\n",
      "Iteration 65, loss = 0.43423764\n",
      "Iteration 66, loss = 0.50630728\n",
      "Iteration 67, loss = 0.41916026\n",
      "Iteration 68, loss = 0.42001684\n",
      "Iteration 69, loss = 0.39453544\n",
      "Iteration 70, loss = 0.38252848\n",
      "Iteration 71, loss = 0.40117349\n",
      "Iteration 72, loss = 0.49901676\n",
      "Iteration 73, loss = 0.43708827\n",
      "Iteration 74, loss = 0.39298352\n",
      "Iteration 75, loss = 0.39493626\n",
      "Iteration 76, loss = 0.41835601\n",
      "Iteration 77, loss = 0.38394939\n",
      "Iteration 78, loss = 0.48589437\n",
      "Iteration 79, loss = 0.42253349\n",
      "Iteration 80, loss = 0.39581307\n",
      "Iteration 81, loss = 0.44037836\n",
      "Training loss did not improve more than tol=0.001000 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24716586\n",
      "Iteration 2, loss = 0.94675339\n",
      "Iteration 3, loss = 0.84989987\n",
      "Iteration 4, loss = 0.73636321\n",
      "Iteration 5, loss = 0.58700568\n",
      "Iteration 6, loss = 0.51389724\n",
      "Iteration 7, loss = 0.43624995\n",
      "Iteration 8, loss = 0.41784140\n",
      "Iteration 9, loss = 0.41483122\n",
      "Iteration 10, loss = 0.40517112\n",
      "Iteration 11, loss = 0.38053505\n",
      "Iteration 12, loss = 0.37886901\n",
      "Iteration 13, loss = 0.35187508\n",
      "Iteration 14, loss = 0.34388330\n",
      "Iteration 15, loss = 0.35117174\n",
      "Iteration 16, loss = 0.33582753\n",
      "Iteration 17, loss = 0.33939965\n",
      "Iteration 18, loss = 0.32753269\n",
      "Iteration 19, loss = 0.31892962\n",
      "Iteration 20, loss = 0.32775380\n",
      "Iteration 21, loss = 0.35861476\n",
      "Iteration 22, loss = 0.33194323\n",
      "Iteration 23, loss = 0.33229344\n",
      "Iteration 24, loss = 0.30793935\n",
      "Iteration 25, loss = 0.32042182\n",
      "Iteration 26, loss = 0.31206832\n",
      "Iteration 27, loss = 0.32809051\n",
      "Iteration 28, loss = 0.31334951\n",
      "Iteration 29, loss = 0.28710877\n",
      "Iteration 30, loss = 0.29858312\n",
      "Iteration 31, loss = 0.31454271\n",
      "Iteration 32, loss = 0.31504994\n",
      "Iteration 33, loss = 0.32832471\n",
      "Iteration 34, loss = 0.29956150\n",
      "Iteration 35, loss = 0.31900430\n",
      "Iteration 36, loss = 0.31247984\n",
      "Iteration 37, loss = 0.30237571\n",
      "Iteration 38, loss = 0.31570268\n",
      "Iteration 39, loss = 0.29892240\n",
      "Iteration 40, loss = 0.28803240\n",
      "Training loss did not improve more than tol=0.001000 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25967992\n",
      "Iteration 2, loss = 1.00570285\n",
      "Iteration 3, loss = 0.76647809\n",
      "Iteration 4, loss = 0.62263955\n",
      "Iteration 5, loss = 0.56651127\n",
      "Iteration 6, loss = 0.54697698\n",
      "Iteration 7, loss = 0.52068263\n",
      "Iteration 8, loss = 0.49730290\n",
      "Iteration 9, loss = 0.48665109\n",
      "Iteration 10, loss = 0.45925174\n",
      "Iteration 11, loss = 0.45375577\n",
      "Iteration 12, loss = 0.46446047\n",
      "Iteration 13, loss = 0.42647949\n",
      "Iteration 14, loss = 0.39574344\n",
      "Iteration 15, loss = 0.40889180\n",
      "Iteration 16, loss = 0.46233506\n",
      "Iteration 17, loss = 0.40890774\n",
      "Iteration 18, loss = 0.38431012\n",
      "Iteration 19, loss = 0.44761040\n",
      "Iteration 20, loss = 0.36974024\n",
      "Iteration 21, loss = 0.38543349\n",
      "Iteration 22, loss = 0.37709360\n",
      "Iteration 23, loss = 0.44791983\n",
      "Iteration 24, loss = 0.34930940\n",
      "Iteration 25, loss = 0.38018835\n",
      "Iteration 26, loss = 0.35116935\n",
      "Iteration 27, loss = 0.40569938\n",
      "Iteration 28, loss = 0.37369389\n",
      "Iteration 29, loss = 0.34037110\n",
      "Iteration 30, loss = 0.34286950\n",
      "Iteration 31, loss = 0.34928496\n",
      "Iteration 32, loss = 0.36869510\n",
      "Iteration 33, loss = 0.36621449\n",
      "Iteration 34, loss = 0.34892876\n",
      "Iteration 35, loss = 0.36418782\n",
      "Iteration 36, loss = 0.33889060\n",
      "Iteration 37, loss = 0.33887609\n",
      "Iteration 38, loss = 0.33691589\n",
      "Iteration 39, loss = 0.33227414\n",
      "Iteration 40, loss = 0.34844908\n",
      "Iteration 41, loss = 0.32406867\n",
      "Iteration 42, loss = 0.35040950\n",
      "Iteration 43, loss = 0.37138069\n",
      "Iteration 44, loss = 0.36051146\n",
      "Iteration 45, loss = 0.36489544\n",
      "Iteration 46, loss = 0.34989309\n",
      "Iteration 47, loss = 0.32950429\n",
      "Iteration 48, loss = 0.38983778\n",
      "Iteration 49, loss = 0.33652661\n",
      "Iteration 50, loss = 0.34127467\n",
      "Iteration 51, loss = 0.35808331\n",
      "Iteration 52, loss = 0.35745259\n",
      "Training loss did not improve more than tol=0.001000 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25659305\n",
      "Iteration 2, loss = 0.97121518\n",
      "Iteration 3, loss = 0.80729244\n",
      "Iteration 4, loss = 0.65168609\n",
      "Iteration 5, loss = 0.53886141\n",
      "Iteration 6, loss = 0.52918241\n",
      "Iteration 7, loss = 0.46961823\n",
      "Iteration 8, loss = 0.44585827\n",
      "Iteration 9, loss = 0.43066593\n",
      "Iteration 10, loss = 0.40453111\n",
      "Iteration 11, loss = 0.42985343\n",
      "Iteration 12, loss = 0.39215169\n",
      "Iteration 13, loss = 0.37076642\n",
      "Iteration 14, loss = 0.35141554\n",
      "Iteration 15, loss = 0.36423191\n",
      "Iteration 16, loss = 0.33702511\n",
      "Iteration 17, loss = 0.35921350\n",
      "Iteration 18, loss = 0.32158351\n",
      "Iteration 19, loss = 0.33106311\n",
      "Iteration 20, loss = 0.31938666\n",
      "Iteration 21, loss = 0.35017416\n",
      "Iteration 22, loss = 0.36212240\n",
      "Iteration 23, loss = 0.36368693\n",
      "Iteration 24, loss = 0.32789539\n",
      "Iteration 25, loss = 0.33449572\n",
      "Iteration 26, loss = 0.30866010\n",
      "Iteration 27, loss = 0.32902963\n",
      "Iteration 28, loss = 0.32369308\n",
      "Iteration 29, loss = 0.31988275\n",
      "Iteration 30, loss = 0.31391592\n",
      "Iteration 31, loss = 0.32146995\n",
      "Iteration 32, loss = 0.31870334\n",
      "Iteration 33, loss = 0.37673774\n",
      "Iteration 34, loss = 0.33556327\n",
      "Iteration 35, loss = 0.32647848\n",
      "Iteration 36, loss = 0.31896056\n",
      "Iteration 37, loss = 0.32577567\n",
      "Training loss did not improve more than tol=0.001000 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.26003726\n",
      "Iteration 2, loss = 0.96701988\n",
      "Iteration 3, loss = 0.81744925\n",
      "Iteration 4, loss = 0.71247658\n",
      "Iteration 5, loss = 0.57136226\n",
      "Iteration 6, loss = 0.57119106\n",
      "Iteration 7, loss = 0.55091839\n",
      "Iteration 8, loss = 0.47126349\n",
      "Iteration 9, loss = 0.46998203\n",
      "Iteration 10, loss = 0.45795196\n",
      "Iteration 11, loss = 0.47585347\n",
      "Iteration 12, loss = 0.43838391\n",
      "Iteration 13, loss = 0.42559486\n",
      "Iteration 14, loss = 0.41378807\n",
      "Iteration 15, loss = 0.41465891\n",
      "Iteration 16, loss = 0.39572114\n",
      "Iteration 17, loss = 0.39209304\n",
      "Iteration 18, loss = 0.40311176\n",
      "Iteration 19, loss = 0.37562573\n",
      "Iteration 20, loss = 0.38285313\n",
      "Iteration 21, loss = 0.38728935\n",
      "Iteration 22, loss = 0.37241354\n",
      "Iteration 23, loss = 0.37363902\n",
      "Iteration 24, loss = 0.39483377\n",
      "Iteration 25, loss = 0.36121395\n",
      "Iteration 26, loss = 0.37360868\n",
      "Iteration 27, loss = 0.43602411\n",
      "Iteration 28, loss = 0.35215727\n",
      "Iteration 29, loss = 0.36359315\n",
      "Iteration 30, loss = 0.37517830\n",
      "Iteration 31, loss = 0.35520038\n",
      "Iteration 32, loss = 0.36718505\n",
      "Iteration 33, loss = 0.39375837\n",
      "Iteration 34, loss = 0.36067384\n",
      "Iteration 35, loss = 0.37569742\n",
      "Iteration 36, loss = 0.35904160\n",
      "Iteration 37, loss = 0.36195143\n",
      "Iteration 38, loss = 0.34820829\n",
      "Iteration 39, loss = 0.34812632\n",
      "Iteration 40, loss = 0.35121059\n",
      "Iteration 41, loss = 0.35314092\n",
      "Iteration 42, loss = 0.41795850\n",
      "Iteration 43, loss = 0.36382453\n",
      "Iteration 44, loss = 0.36146502\n",
      "Iteration 45, loss = 0.38165738\n",
      "Iteration 46, loss = 0.37607151\n",
      "Iteration 47, loss = 0.35050254\n",
      "Iteration 48, loss = 0.37953819\n",
      "Iteration 49, loss = 0.35890499\n",
      "Training loss did not improve more than tol=0.001000 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.26984993\n",
      "Iteration 2, loss = 0.92934919\n",
      "Iteration 3, loss = 0.74190820\n",
      "Iteration 4, loss = 0.60328960\n",
      "Iteration 5, loss = 0.51174351\n",
      "Iteration 6, loss = 0.49675775\n",
      "Iteration 7, loss = 0.45262575\n",
      "Iteration 8, loss = 0.44856626\n",
      "Iteration 9, loss = 0.41595844\n",
      "Iteration 10, loss = 0.40494251\n",
      "Iteration 11, loss = 0.40109701\n",
      "Iteration 12, loss = 0.38828214\n",
      "Iteration 13, loss = 0.36272718\n",
      "Iteration 14, loss = 0.36458674\n",
      "Iteration 15, loss = 0.35954921\n",
      "Iteration 16, loss = 0.37561639\n",
      "Iteration 17, loss = 0.39802785\n",
      "Iteration 18, loss = 0.36459064\n",
      "Iteration 19, loss = 0.38099535\n",
      "Iteration 20, loss = 0.35058042\n",
      "Iteration 21, loss = 0.35381674\n",
      "Iteration 22, loss = 0.36584069\n",
      "Iteration 23, loss = 0.37091452\n",
      "Iteration 24, loss = 0.38089635\n",
      "Iteration 25, loss = 0.38227790\n",
      "Iteration 26, loss = 0.41679160\n",
      "Iteration 27, loss = 0.34710257\n",
      "Iteration 28, loss = 0.35182698\n",
      "Iteration 29, loss = 0.37518700\n",
      "Iteration 30, loss = 0.37521713\n",
      "Iteration 31, loss = 0.36944023\n",
      "Iteration 32, loss = 0.36187372\n",
      "Iteration 33, loss = 0.35066864\n",
      "Iteration 34, loss = 0.35679228\n",
      "Iteration 35, loss = 0.35345024\n",
      "Iteration 36, loss = 0.34917566\n",
      "Iteration 37, loss = 0.34704890\n",
      "Iteration 38, loss = 0.34684717\n",
      "Training loss did not improve more than tol=0.001000 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27406838\n",
      "Iteration 2, loss = 0.95132978\n",
      "Iteration 3, loss = 0.80280396\n",
      "Iteration 4, loss = 0.60355281\n",
      "Iteration 5, loss = 0.49116783\n",
      "Iteration 6, loss = 0.46103550\n",
      "Iteration 7, loss = 0.40502698\n",
      "Iteration 8, loss = 0.40613220\n",
      "Iteration 9, loss = 0.44862983\n",
      "Iteration 10, loss = 0.38266789\n",
      "Iteration 11, loss = 0.37669266\n",
      "Iteration 12, loss = 0.37493618\n",
      "Iteration 13, loss = 0.34664926\n",
      "Iteration 14, loss = 0.35563642\n",
      "Iteration 15, loss = 0.36399869\n",
      "Iteration 16, loss = 0.35138314\n",
      "Iteration 17, loss = 0.36245254\n",
      "Iteration 18, loss = 0.34581688\n",
      "Iteration 19, loss = 0.36451421\n",
      "Iteration 20, loss = 0.35919800\n",
      "Iteration 21, loss = 0.33698513\n",
      "Iteration 22, loss = 0.36536171\n",
      "Iteration 23, loss = 0.36363696\n",
      "Iteration 24, loss = 0.33290912\n",
      "Iteration 25, loss = 0.38632634\n",
      "Iteration 26, loss = 0.35908590\n",
      "Iteration 27, loss = 0.36808194\n",
      "Iteration 28, loss = 0.33713794\n",
      "Iteration 29, loss = 0.39064029\n",
      "Iteration 30, loss = 0.35480491\n",
      "Iteration 31, loss = 0.33156189\n",
      "Iteration 32, loss = 0.32919279\n",
      "Iteration 33, loss = 0.33218230\n",
      "Iteration 34, loss = 0.33597903\n",
      "Iteration 35, loss = 0.34423460\n",
      "Iteration 36, loss = 0.32331045\n",
      "Iteration 37, loss = 0.33821393\n",
      "Iteration 38, loss = 0.32890577\n",
      "Iteration 39, loss = 0.32793327\n",
      "Iteration 40, loss = 0.33768821\n",
      "Iteration 41, loss = 0.32376752\n",
      "Iteration 42, loss = 0.32172797\n",
      "Iteration 43, loss = 0.36803742\n",
      "Iteration 44, loss = 0.33101704\n",
      "Iteration 45, loss = 0.34227571\n",
      "Iteration 46, loss = 0.33103784\n",
      "Iteration 47, loss = 0.32746238\n",
      "Iteration 48, loss = 0.35529660\n",
      "Iteration 49, loss = 0.31773707\n",
      "Iteration 50, loss = 0.31596672\n",
      "Iteration 51, loss = 0.34807164\n",
      "Iteration 52, loss = 0.33039981\n",
      "Iteration 53, loss = 0.31622055\n",
      "Iteration 54, loss = 0.34274540\n",
      "Iteration 55, loss = 0.32393608\n",
      "Iteration 56, loss = 0.36978379\n",
      "Iteration 57, loss = 0.31642639\n",
      "Iteration 58, loss = 0.32749650\n",
      "Iteration 59, loss = 0.31963816\n",
      "Iteration 60, loss = 0.34239594\n",
      "Iteration 61, loss = 0.31827071\n",
      "Training loss did not improve more than tol=0.001000 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27321006\n",
      "Iteration 2, loss = 0.98141194\n",
      "Iteration 3, loss = 0.87308301\n",
      "Iteration 4, loss = 0.59626739\n",
      "Iteration 5, loss = 0.50246453\n",
      "Iteration 6, loss = 0.47895163\n",
      "Iteration 7, loss = 0.43969891\n",
      "Iteration 8, loss = 0.41008407\n",
      "Iteration 9, loss = 0.41046453\n",
      "Iteration 10, loss = 0.41604849\n",
      "Iteration 11, loss = 0.40510027\n",
      "Iteration 12, loss = 0.46236827\n",
      "Iteration 13, loss = 0.37439941\n",
      "Iteration 14, loss = 0.38451891\n",
      "Iteration 15, loss = 0.39568816\n",
      "Iteration 16, loss = 0.37637104\n",
      "Iteration 17, loss = 0.39440034\n",
      "Iteration 18, loss = 0.37944470\n",
      "Iteration 19, loss = 0.36708987\n",
      "Iteration 20, loss = 0.36005266\n",
      "Iteration 21, loss = 0.39656123\n",
      "Iteration 22, loss = 0.36990721\n",
      "Iteration 23, loss = 0.36624215\n",
      "Iteration 24, loss = 0.35756646\n",
      "Iteration 25, loss = 0.36265529\n",
      "Iteration 26, loss = 0.36598109\n",
      "Iteration 27, loss = 0.41131801\n",
      "Iteration 28, loss = 0.36759967\n",
      "Iteration 29, loss = 0.36888159\n",
      "Iteration 30, loss = 0.35039261\n",
      "Iteration 31, loss = 0.37961265\n",
      "Iteration 32, loss = 0.36573648\n",
      "Iteration 33, loss = 0.33445775\n",
      "Iteration 34, loss = 0.33493403\n",
      "Iteration 35, loss = 0.38914638\n",
      "Iteration 36, loss = 0.33735531\n",
      "Iteration 37, loss = 0.34365570\n",
      "Iteration 38, loss = 0.37187469\n",
      "Iteration 39, loss = 0.34040950\n",
      "Iteration 40, loss = 0.34069219\n",
      "Iteration 41, loss = 0.34292580\n",
      "Iteration 42, loss = 0.36655465\n",
      "Iteration 43, loss = 0.34670195\n",
      "Iteration 44, loss = 0.31702644\n",
      "Iteration 45, loss = 0.35598865\n",
      "Iteration 46, loss = 0.34662958\n",
      "Iteration 47, loss = 0.32517463\n",
      "Iteration 48, loss = 0.37940943\n",
      "Iteration 49, loss = 0.33833103\n",
      "Iteration 50, loss = 0.33874099\n",
      "Iteration 51, loss = 0.36314866\n",
      "Iteration 52, loss = 0.33947234\n",
      "Iteration 53, loss = 0.31573109\n",
      "Iteration 54, loss = 0.31017365\n",
      "Iteration 55, loss = 0.36190727\n",
      "Iteration 56, loss = 0.33854446\n",
      "Iteration 57, loss = 0.34916757\n",
      "Iteration 58, loss = 0.37091135\n",
      "Iteration 59, loss = 0.34896843\n",
      "Iteration 60, loss = 0.34288203\n",
      "Iteration 61, loss = 0.36541283\n",
      "Iteration 62, loss = 0.35206980\n",
      "Iteration 63, loss = 0.33062139\n",
      "Iteration 64, loss = 0.39487801\n",
      "Iteration 65, loss = 0.32851157\n",
      "Training loss did not improve more than tol=0.001000 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.26429330\n",
      "Iteration 2, loss = 0.94998099\n",
      "Iteration 3, loss = 0.77798132\n",
      "Iteration 4, loss = 0.53562328\n",
      "Iteration 5, loss = 0.46362954\n",
      "Iteration 6, loss = 0.43461029\n",
      "Iteration 7, loss = 0.38197177\n",
      "Iteration 8, loss = 0.39693875\n",
      "Iteration 9, loss = 0.37195236\n",
      "Iteration 10, loss = 0.36360361\n",
      "Iteration 11, loss = 0.37188092\n",
      "Iteration 12, loss = 0.38569649\n",
      "Iteration 13, loss = 0.35410571\n",
      "Iteration 14, loss = 0.36782415\n",
      "Iteration 15, loss = 0.35829148\n",
      "Iteration 16, loss = 0.34224058\n",
      "Iteration 17, loss = 0.36218224\n",
      "Iteration 18, loss = 0.33247191\n",
      "Iteration 19, loss = 0.38750414\n",
      "Iteration 20, loss = 0.35773573\n",
      "Iteration 21, loss = 0.33635653\n",
      "Iteration 22, loss = 0.36803233\n",
      "Iteration 23, loss = 0.39870301\n",
      "Iteration 24, loss = 0.34316843\n",
      "Iteration 25, loss = 0.37276679\n",
      "Iteration 26, loss = 0.35295040\n",
      "Iteration 27, loss = 0.32763917\n",
      "Iteration 28, loss = 0.35769809\n",
      "Iteration 29, loss = 0.38166263\n",
      "Iteration 30, loss = 0.35317321\n",
      "Iteration 31, loss = 0.33726154\n",
      "Iteration 32, loss = 0.34954728\n",
      "Iteration 33, loss = 0.42821987\n",
      "Iteration 34, loss = 0.32166463\n",
      "Iteration 35, loss = 0.36470650\n",
      "Iteration 36, loss = 0.32379619\n",
      "Iteration 37, loss = 0.35180765\n",
      "Iteration 38, loss = 0.32444553\n",
      "Iteration 39, loss = 0.33715645\n",
      "Iteration 40, loss = 0.31842463\n",
      "Iteration 41, loss = 0.33108846\n",
      "Iteration 42, loss = 0.34540065\n",
      "Iteration 43, loss = 0.33191206\n",
      "Iteration 44, loss = 0.32504624\n",
      "Iteration 45, loss = 0.34798710\n",
      "Iteration 46, loss = 0.32932054\n",
      "Iteration 47, loss = 0.34310994\n",
      "Iteration 48, loss = 0.34750152\n",
      "Iteration 49, loss = 0.34311050\n",
      "Iteration 50, loss = 0.33357437\n",
      "Iteration 51, loss = 0.35459299\n",
      "Training loss did not improve more than tol=0.001000 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.22192381\n",
      "Iteration 2, loss = 0.88327612\n",
      "Iteration 3, loss = 0.80142100\n",
      "Iteration 4, loss = 0.74820692\n",
      "Iteration 5, loss = 0.59136731\n",
      "Iteration 6, loss = 0.45677030\n",
      "Iteration 7, loss = 0.44219920\n",
      "Iteration 8, loss = 0.39246526\n",
      "Iteration 9, loss = 0.36439405\n",
      "Iteration 10, loss = 0.41010331\n",
      "Iteration 11, loss = 0.38097279\n",
      "Iteration 12, loss = 0.40286681\n",
      "Iteration 13, loss = 0.33401497\n",
      "Iteration 14, loss = 0.33310465\n",
      "Iteration 15, loss = 0.30171279\n",
      "Iteration 16, loss = 0.35092987\n",
      "Iteration 17, loss = 0.31783710\n",
      "Iteration 18, loss = 0.29336881\n",
      "Iteration 19, loss = 0.33166792\n",
      "Iteration 20, loss = 0.30559531\n",
      "Iteration 21, loss = 0.33008098\n",
      "Iteration 22, loss = 0.34531540\n",
      "Iteration 23, loss = 0.27487608\n",
      "Iteration 24, loss = 0.27158332\n",
      "Iteration 25, loss = 0.30098439\n",
      "Iteration 26, loss = 0.32270889\n",
      "Iteration 27, loss = 0.29637019\n",
      "Iteration 28, loss = 0.27174990\n",
      "Iteration 29, loss = 0.26420497\n",
      "Iteration 30, loss = 0.30810594\n",
      "Iteration 31, loss = 0.26035960\n",
      "Iteration 32, loss = 0.28563310\n",
      "Iteration 33, loss = 0.25806289\n",
      "Iteration 34, loss = 0.25915382\n",
      "Iteration 35, loss = 0.25095109\n",
      "Iteration 36, loss = 0.25494602\n",
      "Iteration 37, loss = 0.35053094\n",
      "Iteration 38, loss = 0.27768051\n",
      "Iteration 39, loss = 0.25861126\n",
      "Iteration 40, loss = 0.27202421\n",
      "Iteration 41, loss = 0.30992472\n",
      "Iteration 42, loss = 0.26945366\n",
      "Iteration 43, loss = 0.24962722\n",
      "Iteration 44, loss = 0.24630763\n",
      "Iteration 45, loss = 0.29445174\n",
      "Iteration 46, loss = 0.30906920\n",
      "Iteration 47, loss = 0.27610088\n",
      "Iteration 48, loss = 0.29309787\n",
      "Iteration 49, loss = 0.24774376\n",
      "Iteration 50, loss = 0.25386436\n",
      "Iteration 51, loss = 0.26267197\n",
      "Iteration 52, loss = 0.25271739\n",
      "Iteration 53, loss = 0.25953172\n",
      "Iteration 54, loss = 0.26539442\n",
      "Iteration 55, loss = 0.26724490\n",
      "Training loss did not improve more than tol=0.001000 for 10 consecutive epochs. Stopping.\n",
      "Experimento 2\n",
      "Acurácia Média: 86.79%\n",
      "Precisão Média: 89.59%\n",
      "Revocação Média: 87.86%\n",
      "F1-Score Médio: 87.57%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "df['Class'] = targets \n",
    "\n",
    "#The is scaler is used to better represent the experiments done by Koklu\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit_transform(df[cols])\n",
    "df_scaled = pd.DataFrame(scaler.transform(df[cols]), columns = cols)\n",
    "\n",
    "df_scaled['Class'] = df['Class']\n",
    "df_scaled\n",
    "\n",
    "x_train = df_scaled.iloc[:, 0:16]\n",
    "y_train = df_scaled.iloc[:, 16]\n",
    "classifier = MLPClassifier(activation='logistic', solver='adam', alpha=1e-5, hidden_layer_sizes=(12, 3), random_state=1, verbose=True, learning_rate_init=0.3, tol=1e-3, max_iter=500)\n",
    "scoring = {'acc' : 'accuracy',\n",
    "           'prec' : 'precision_macro',\n",
    "           'recall' : 'recall_macro',\n",
    "           'f1' : 'f1_macro'}\n",
    "\n",
    "\n",
    "y_pred = cross_validate(classifier, x_train, y_train, cv=10, scoring=scoring, return_train_score=True)\n",
    "print('Experimento 2')\n",
    "print('Acurácia Média: ' + '%.2f' % (np.mean(y_pred['test_acc'])*100) + '%')\n",
    "print('Precisão Média: ' + '%.2f' % (np.mean(y_pred['test_prec'])*100) + '%')\n",
    "print('Revocação Média: ' + '%.2f' % (np.mean(y_pred['test_recall'])*100) + '%')\n",
    "print('F1-Score Médio: ' + '%.2f' % (np.mean(y_pred['test_f1'])*100) + '%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
