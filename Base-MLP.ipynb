{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn.objects as so\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn import preprocessing\n",
    "from ucimlrepo import fetch_ucirepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "beans = fetch_ucirepo(id=602)\n",
    "df = beans.data.features\n",
    "targets = beans.data.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Area', 'Perimeter', 'MajorAxisLength', 'MinorAxisLength', 'AspectRatio', 'Eccentricity', 'ConvexArea', 'EquivDiameter', 'Extent', 'Solidity', 'Roundness', 'Compactness', 'ShapeFactor1', 'ShapeFactor2', 'ShapeFactor3', 'ShapeFactor4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fetch_ucirepo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m beans \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_ucirepo\u001b[49m(\u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m602\u001b[39m)\n\u001b[1;32m      2\u001b[0m df \u001b[38;5;241m=\u001b[39m beans\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfeatures\n\u001b[1;32m      3\u001b[0m targets \u001b[38;5;241m=\u001b[39m beans\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mtargets\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fetch_ucirepo' is not defined"
     ]
    }
   ],
   "source": [
    "beans = fetch_ucirepo(id=602)\n",
    "df = beans.data.features\n",
    "targets = beans.data.targets\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit_transform(df)\n",
    "df = pd.DataFrame(scaler.transform(df))\n",
    "\n",
    "df['Class'] = targets\n",
    "x_train = df.iloc[:, 0:16]\n",
    "y_train = df.iloc[:, 16]\n",
    "learning_rates = [0.3, 0.03, 0.003]\n",
    "activation_functions = ['logistic', 'relu', 'tanh']\n",
    "scoring = {'acc' : 'accuracy',\n",
    "           'prec' : 'precision_macro',\n",
    "           'recall' : 'recall_macro',\n",
    "           'f1' : 'f1_macro'}\n",
    "\n",
    "\n",
    "best_combination = []\n",
    "best_acc = -1\n",
    "best_pred = []\n",
    "best_test = -1\n",
    "test = -1\n",
    "with open('best_mlp.txt', 'w') as f:\n",
    "  print('Starting Tests...')\n",
    "  for first in range(10, 16):\n",
    "    for second in range(3, 16):\n",
    "      for lr in learning_rates:\n",
    "        for af in activation_functions:\n",
    "          test = test + 1\n",
    "          print(f'Itializing test {test}...')\n",
    "          print(f'Test Parameters: First Layer Neurons={first}, Second Layers Neurons={second}, Learning Rate={lr}, Activation Functions={af}.')\n",
    "          classifier = MLPClassifier(activation=af, solver='adam', alpha=1e-5, hidden_layer_sizes=(first, second), random_state=1, verbose=False, learning_rate_init=lr, tol=1e-3, max_iter=500)\n",
    "          y_pred = cross_validate(classifier, x_train, y_train, cv=10, scoring=scoring, return_train_score=True)\n",
    "          print('Acurácia Média: ' + '%.2f' % (np.mean(y_pred['test_acc'])*100) + '%')\n",
    "          print('Precisão Média: ' + '%.2f' % (np.mean(y_pred['test_prec'])*100) + '%')\n",
    "          print('Revocação Média: ' + '%.2f' % (np.mean(y_pred['test_recall'])*100) + '%')\n",
    "          print('F1-Score Médio: ' + '%.2f' % (np.mean(y_pred['test_f1'])*100) + '%')\n",
    "          acc = np.mean(y_pred['test_acc'])*100\n",
    "          prec = np.mean(y_pred['test_prec'])*100\n",
    "          rec = np.mean(y_pred['test_recall'])*100\n",
    "          f1 = np.mean(y_pred['test_f1'])*100\n",
    "          f.write(f'{test},{first},{second},{lr},{acc},{prec},{rec},{f1}')\n",
    "          print\n",
    "          if acc > best_acc:\n",
    "            print(f'Test {test} performed better than test {best_test}. Adjusting new best results...')\n",
    "            best_combination = [first, second, lr, af]\n",
    "            best_acc = acc\n",
    "            best_pred = y_pred\n",
    "            best_test = test\n",
    "            best_pred = [acc, prec, rec, f1]\n",
    "\n",
    "print('Best Result')\n",
    "print(f'Test Parameters: First Layer Neurons={best_combination[0]}, Second Layers Neurons={best_combination[1]}, Learning Rate={best_combination[2]}, Activation Functions={best_combination[3]}.')\n",
    "print('Results...')\n",
    "print('Acurácia Média: ' + '%.2f' % (best_pred[0]) + '%')\n",
    "print('Precisão Média: ' + '%.2f' % (best_pred[1]) + '%')\n",
    "print('Revocação Média: ' + '%.2f' % (best_pred[2]) + '%')\n",
    "print('F1-Score Médio: ' + '%.2f' % (best_pred[3]) + '%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
