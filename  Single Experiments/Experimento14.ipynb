{"cells":[{"cell_type":"markdown","metadata":{"id":"VMpZC5eq6HNR"},"source":["Experimento 14 - Linear Interpolation Imputer, MAD outlier detection, min max normalization, MLP classifier"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":24288,"status":"ok","timestamp":1704302598757,"user":{"displayName":"Victor Hugo Schneider Lopes","userId":"10992764016890176856"},"user_tz":180},"id":"cP53TLVS5xq-"},"outputs":[],"source":["import pandas as pd\n","import seaborn as sns\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn.objects as so\n","from ucimlrepo import fetch_ucirepo"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":485,"status":"ok","timestamp":1704302599227,"user":{"displayName":"Victor Hugo Schneider Lopes","userId":"10992764016890176856"},"user_tz":180},"id":"0owuQnJm6Vl5"},"outputs":[],"source":["beans = fetch_ucirepo(id=602)\n","df = beans.data.features\n","targets = beans.data.targets"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1704302599228,"user":{"displayName":"Victor Hugo Schneider Lopes","userId":"10992764016890176856"},"user_tz":180},"id":"_jMLf_dB6aIn"},"outputs":[],"source":["cols = ['Area', 'Perimeter', 'MajorAxisLength', 'MinorAxisLength', 'AspectRatio', 'Eccentricity', 'ConvexArea', 'EquivDiameter', 'Extent', 'Solidity', 'Roundness', 'Compactness', 'ShapeFactor1', 'ShapeFactor2', 'ShapeFactor3', 'ShapeFactor4']"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4750,"status":"ok","timestamp":1704302603973,"user":{"displayName":"Victor Hugo Schneider Lopes","userId":"10992764016890176856"},"user_tz":180},"id":"dCOP0sV96rrX","outputId":"0eca0053-1e8e-41b1-d46b-724b37d15b20"},"outputs":[],"source":["import random\n","\n","#Introducing Missing values (5%)\n","\n","for index, i in enumerate(df):\n","  for jndex, j in enumerate(df[i]):\n","    if random.randint(0,100) < 5:\n","      df.loc[jndex,i] = np.NaN"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34,"status":"ok","timestamp":1704302603974,"user":{"displayName":"Victor Hugo Schneider Lopes","userId":"10992764016890176856"},"user_tz":180},"id":"eUet-44k838X","outputId":"ea3719a0-20a5-4c07-a93e-8b68ab1bc468"},"outputs":[{"data":{"text/plain":["Area               684\n","Perimeter          669\n","MajorAxisLength    678\n","MinorAxisLength    650\n","AspectRatio        679\n","Eccentricity       636\n","ConvexArea         666\n","EquivDiameter      689\n","Extent             681\n","Solidity           714\n","Roundness          670\n","Compactness        636\n","ShapeFactor1       694\n","ShapeFactor2       673\n","ShapeFactor3       649\n","ShapeFactor4       688\n","dtype: int64"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["df.isna().sum()"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":444},"executionInfo":{"elapsed":29,"status":"ok","timestamp":1704302603975,"user":{"displayName":"Victor Hugo Schneider Lopes","userId":"10992764016890176856"},"user_tz":180},"id":"U7Qgx3nODiaS","outputId":"58d29f87-94f7-4d2e-cc1a-d874e335f0ce"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Area</th>\n","      <th>Perimeter</th>\n","      <th>MajorAxisLength</th>\n","      <th>MinorAxisLength</th>\n","      <th>AspectRatio</th>\n","      <th>Eccentricity</th>\n","      <th>ConvexArea</th>\n","      <th>EquivDiameter</th>\n","      <th>Extent</th>\n","      <th>Solidity</th>\n","      <th>Roundness</th>\n","      <th>Compactness</th>\n","      <th>ShapeFactor1</th>\n","      <th>ShapeFactor2</th>\n","      <th>ShapeFactor3</th>\n","      <th>ShapeFactor4</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>28395.0</td>\n","      <td>NaN</td>\n","      <td>208.178117</td>\n","      <td>NaN</td>\n","      <td>1.197191</td>\n","      <td>0.549812</td>\n","      <td>28715.0</td>\n","      <td>190.141097</td>\n","      <td>0.763923</td>\n","      <td>0.988856</td>\n","      <td>0.958027</td>\n","      <td>0.913358</td>\n","      <td>0.007332</td>\n","      <td>0.003147</td>\n","      <td>0.834222</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>28734.0</td>\n","      <td>638.018</td>\n","      <td>200.524796</td>\n","      <td>182.734419</td>\n","      <td>1.097356</td>\n","      <td>0.411785</td>\n","      <td>29172.0</td>\n","      <td>191.272751</td>\n","      <td>0.783968</td>\n","      <td>0.984986</td>\n","      <td>0.887034</td>\n","      <td>0.953861</td>\n","      <td>0.006979</td>\n","      <td>0.003564</td>\n","      <td>NaN</td>\n","      <td>0.998430</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>29380.0</td>\n","      <td>624.110</td>\n","      <td>212.826130</td>\n","      <td>175.931143</td>\n","      <td>1.209713</td>\n","      <td>0.562727</td>\n","      <td>29690.0</td>\n","      <td>193.410904</td>\n","      <td>0.778113</td>\n","      <td>0.989559</td>\n","      <td>0.947849</td>\n","      <td>0.908774</td>\n","      <td>0.007244</td>\n","      <td>0.003048</td>\n","      <td>0.825871</td>\n","      <td>0.999066</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>30008.0</td>\n","      <td>645.884</td>\n","      <td>210.557999</td>\n","      <td>182.516516</td>\n","      <td>1.153638</td>\n","      <td>0.498616</td>\n","      <td>30724.0</td>\n","      <td>195.467062</td>\n","      <td>0.782681</td>\n","      <td>0.976696</td>\n","      <td>0.903936</td>\n","      <td>0.928329</td>\n","      <td>0.007017</td>\n","      <td>0.003215</td>\n","      <td>0.861794</td>\n","      <td>0.994199</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>30140.0</td>\n","      <td>620.134</td>\n","      <td>201.847882</td>\n","      <td>190.279279</td>\n","      <td>1.060798</td>\n","      <td>0.333680</td>\n","      <td>30417.0</td>\n","      <td>195.896503</td>\n","      <td>0.773098</td>\n","      <td>0.990893</td>\n","      <td>0.984877</td>\n","      <td>0.970516</td>\n","      <td>0.006697</td>\n","      <td>0.003665</td>\n","      <td>0.941900</td>\n","      <td>0.999166</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>13606</th>\n","      <td>42097.0</td>\n","      <td>759.696</td>\n","      <td>288.721612</td>\n","      <td>185.944705</td>\n","      <td>1.552728</td>\n","      <td>0.765002</td>\n","      <td>42508.0</td>\n","      <td>231.515799</td>\n","      <td>0.714574</td>\n","      <td>0.990331</td>\n","      <td>0.916603</td>\n","      <td>0.801865</td>\n","      <td>0.006858</td>\n","      <td>0.001749</td>\n","      <td>0.642988</td>\n","      <td>0.998385</td>\n","    </tr>\n","    <tr>\n","      <th>13607</th>\n","      <td>42101.0</td>\n","      <td>757.499</td>\n","      <td>281.576392</td>\n","      <td>190.713136</td>\n","      <td>1.476439</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>231.526798</td>\n","      <td>0.799943</td>\n","      <td>0.990752</td>\n","      <td>0.922015</td>\n","      <td>0.822252</td>\n","      <td>0.006688</td>\n","      <td>NaN</td>\n","      <td>0.676099</td>\n","      <td>0.998219</td>\n","    </tr>\n","    <tr>\n","      <th>13608</th>\n","      <td>42139.0</td>\n","      <td>759.321</td>\n","      <td>281.539928</td>\n","      <td>191.187979</td>\n","      <td>1.472582</td>\n","      <td>0.734065</td>\n","      <td>42569.0</td>\n","      <td>231.631261</td>\n","      <td>0.729932</td>\n","      <td>0.989899</td>\n","      <td>0.918424</td>\n","      <td>0.822730</td>\n","      <td>0.006681</td>\n","      <td>0.001888</td>\n","      <td>0.676884</td>\n","      <td>0.996767</td>\n","    </tr>\n","    <tr>\n","      <th>13609</th>\n","      <td>42147.0</td>\n","      <td>763.779</td>\n","      <td>283.382636</td>\n","      <td>190.275731</td>\n","      <td>1.489326</td>\n","      <td>0.741055</td>\n","      <td>42667.0</td>\n","      <td>231.653247</td>\n","      <td>0.705389</td>\n","      <td>0.987813</td>\n","      <td>0.907906</td>\n","      <td>0.817457</td>\n","      <td>0.006724</td>\n","      <td>0.001852</td>\n","      <td>0.668237</td>\n","      <td>0.995222</td>\n","    </tr>\n","    <tr>\n","      <th>13610</th>\n","      <td>42159.0</td>\n","      <td>772.237</td>\n","      <td>295.142741</td>\n","      <td>NaN</td>\n","      <td>1.619841</td>\n","      <td>0.786693</td>\n","      <td>42600.0</td>\n","      <td>231.686223</td>\n","      <td>0.788962</td>\n","      <td>0.989648</td>\n","      <td>0.888380</td>\n","      <td>0.784997</td>\n","      <td>0.007001</td>\n","      <td>0.001640</td>\n","      <td>0.616221</td>\n","      <td>0.998180</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>13611 rows Ã— 16 columns</p>\n","</div>"],"text/plain":["          Area  Perimeter  MajorAxisLength  MinorAxisLength  AspectRatio  \\\n","0      28395.0        NaN       208.178117              NaN     1.197191   \n","1      28734.0    638.018       200.524796       182.734419     1.097356   \n","2      29380.0    624.110       212.826130       175.931143     1.209713   \n","3      30008.0    645.884       210.557999       182.516516     1.153638   \n","4      30140.0    620.134       201.847882       190.279279     1.060798   \n","...        ...        ...              ...              ...          ...   \n","13606  42097.0    759.696       288.721612       185.944705     1.552728   \n","13607  42101.0    757.499       281.576392       190.713136     1.476439   \n","13608  42139.0    759.321       281.539928       191.187979     1.472582   \n","13609  42147.0    763.779       283.382636       190.275731     1.489326   \n","13610  42159.0    772.237       295.142741              NaN     1.619841   \n","\n","       Eccentricity  ConvexArea  EquivDiameter    Extent  Solidity  Roundness  \\\n","0          0.549812     28715.0     190.141097  0.763923  0.988856   0.958027   \n","1          0.411785     29172.0     191.272751  0.783968  0.984986   0.887034   \n","2          0.562727     29690.0     193.410904  0.778113  0.989559   0.947849   \n","3          0.498616     30724.0     195.467062  0.782681  0.976696   0.903936   \n","4          0.333680     30417.0     195.896503  0.773098  0.990893   0.984877   \n","...             ...         ...            ...       ...       ...        ...   \n","13606      0.765002     42508.0     231.515799  0.714574  0.990331   0.916603   \n","13607           NaN         NaN     231.526798  0.799943  0.990752   0.922015   \n","13608      0.734065     42569.0     231.631261  0.729932  0.989899   0.918424   \n","13609      0.741055     42667.0     231.653247  0.705389  0.987813   0.907906   \n","13610      0.786693     42600.0     231.686223  0.788962  0.989648   0.888380   \n","\n","       Compactness  ShapeFactor1  ShapeFactor2  ShapeFactor3  ShapeFactor4  \n","0         0.913358      0.007332      0.003147      0.834222           NaN  \n","1         0.953861      0.006979      0.003564           NaN      0.998430  \n","2         0.908774      0.007244      0.003048      0.825871      0.999066  \n","3         0.928329      0.007017      0.003215      0.861794      0.994199  \n","4         0.970516      0.006697      0.003665      0.941900      0.999166  \n","...            ...           ...           ...           ...           ...  \n","13606     0.801865      0.006858      0.001749      0.642988      0.998385  \n","13607     0.822252      0.006688           NaN      0.676099      0.998219  \n","13608     0.822730      0.006681      0.001888      0.676884      0.996767  \n","13609     0.817457      0.006724      0.001852      0.668237      0.995222  \n","13610     0.784997      0.007001      0.001640      0.616221      0.998180  \n","\n","[13611 rows x 16 columns]"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["df"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":444},"executionInfo":{"elapsed":605,"status":"ok","timestamp":1704302604561,"user":{"displayName":"Victor Hugo Schneider Lopes","userId":"10992764016890176856"},"user_tz":180},"id":"WJH40wejA9LZ","outputId":"1782878b-8715-4b27-d117-1c9268376657"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Area</th>\n","      <th>Perimeter</th>\n","      <th>MajorAxisLength</th>\n","      <th>MinorAxisLength</th>\n","      <th>AspectRatio</th>\n","      <th>Eccentricity</th>\n","      <th>ConvexArea</th>\n","      <th>EquivDiameter</th>\n","      <th>Extent</th>\n","      <th>Solidity</th>\n","      <th>Roundness</th>\n","      <th>Compactness</th>\n","      <th>ShapeFactor1</th>\n","      <th>ShapeFactor2</th>\n","      <th>ShapeFactor3</th>\n","      <th>ShapeFactor4</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>28395.0</td>\n","      <td>638.018</td>\n","      <td>208.178117</td>\n","      <td>182.734419</td>\n","      <td>1.197191</td>\n","      <td>0.549812</td>\n","      <td>28715.0</td>\n","      <td>190.141097</td>\n","      <td>0.763923</td>\n","      <td>0.988856</td>\n","      <td>0.958027</td>\n","      <td>0.913358</td>\n","      <td>0.007332</td>\n","      <td>0.003147</td>\n","      <td>0.834222</td>\n","      <td>0.998430</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>28734.0</td>\n","      <td>638.018</td>\n","      <td>200.524796</td>\n","      <td>182.734419</td>\n","      <td>1.097356</td>\n","      <td>0.411785</td>\n","      <td>29172.0</td>\n","      <td>191.272751</td>\n","      <td>0.783968</td>\n","      <td>0.984986</td>\n","      <td>0.887034</td>\n","      <td>0.953861</td>\n","      <td>0.006979</td>\n","      <td>0.003564</td>\n","      <td>0.834222</td>\n","      <td>0.998430</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>29380.0</td>\n","      <td>624.110</td>\n","      <td>212.826130</td>\n","      <td>175.931143</td>\n","      <td>1.209713</td>\n","      <td>0.562727</td>\n","      <td>29690.0</td>\n","      <td>193.410904</td>\n","      <td>0.778113</td>\n","      <td>0.989559</td>\n","      <td>0.947849</td>\n","      <td>0.908774</td>\n","      <td>0.007244</td>\n","      <td>0.003048</td>\n","      <td>0.825871</td>\n","      <td>0.999066</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>30008.0</td>\n","      <td>645.884</td>\n","      <td>210.557999</td>\n","      <td>182.516516</td>\n","      <td>1.153638</td>\n","      <td>0.498616</td>\n","      <td>30724.0</td>\n","      <td>195.467062</td>\n","      <td>0.782681</td>\n","      <td>0.976696</td>\n","      <td>0.903936</td>\n","      <td>0.928329</td>\n","      <td>0.007017</td>\n","      <td>0.003215</td>\n","      <td>0.861794</td>\n","      <td>0.994199</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>30140.0</td>\n","      <td>620.134</td>\n","      <td>201.847882</td>\n","      <td>190.279279</td>\n","      <td>1.060798</td>\n","      <td>0.333680</td>\n","      <td>30417.0</td>\n","      <td>195.896503</td>\n","      <td>0.773098</td>\n","      <td>0.990893</td>\n","      <td>0.984877</td>\n","      <td>0.970516</td>\n","      <td>0.006697</td>\n","      <td>0.003665</td>\n","      <td>0.941900</td>\n","      <td>0.999166</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>13606</th>\n","      <td>42097.0</td>\n","      <td>759.696</td>\n","      <td>288.721612</td>\n","      <td>185.944705</td>\n","      <td>1.552728</td>\n","      <td>0.765002</td>\n","      <td>42508.0</td>\n","      <td>231.515799</td>\n","      <td>0.714574</td>\n","      <td>0.990331</td>\n","      <td>0.916603</td>\n","      <td>0.801865</td>\n","      <td>0.006858</td>\n","      <td>0.001749</td>\n","      <td>0.642988</td>\n","      <td>0.998385</td>\n","    </tr>\n","    <tr>\n","      <th>13607</th>\n","      <td>42101.0</td>\n","      <td>757.499</td>\n","      <td>281.576392</td>\n","      <td>190.713136</td>\n","      <td>1.476439</td>\n","      <td>0.765002</td>\n","      <td>42508.0</td>\n","      <td>231.526798</td>\n","      <td>0.799943</td>\n","      <td>0.990752</td>\n","      <td>0.922015</td>\n","      <td>0.822252</td>\n","      <td>0.006688</td>\n","      <td>0.001749</td>\n","      <td>0.676099</td>\n","      <td>0.998219</td>\n","    </tr>\n","    <tr>\n","      <th>13608</th>\n","      <td>42139.0</td>\n","      <td>759.321</td>\n","      <td>281.539928</td>\n","      <td>191.187979</td>\n","      <td>1.472582</td>\n","      <td>0.734065</td>\n","      <td>42569.0</td>\n","      <td>231.631261</td>\n","      <td>0.729932</td>\n","      <td>0.989899</td>\n","      <td>0.918424</td>\n","      <td>0.822730</td>\n","      <td>0.006681</td>\n","      <td>0.001888</td>\n","      <td>0.676884</td>\n","      <td>0.996767</td>\n","    </tr>\n","    <tr>\n","      <th>13609</th>\n","      <td>42147.0</td>\n","      <td>763.779</td>\n","      <td>283.382636</td>\n","      <td>190.275731</td>\n","      <td>1.489326</td>\n","      <td>0.741055</td>\n","      <td>42667.0</td>\n","      <td>231.653247</td>\n","      <td>0.705389</td>\n","      <td>0.987813</td>\n","      <td>0.907906</td>\n","      <td>0.817457</td>\n","      <td>0.006724</td>\n","      <td>0.001852</td>\n","      <td>0.668237</td>\n","      <td>0.995222</td>\n","    </tr>\n","    <tr>\n","      <th>13610</th>\n","      <td>42159.0</td>\n","      <td>772.237</td>\n","      <td>295.142741</td>\n","      <td>190.275731</td>\n","      <td>1.619841</td>\n","      <td>0.786693</td>\n","      <td>42600.0</td>\n","      <td>231.686223</td>\n","      <td>0.788962</td>\n","      <td>0.989648</td>\n","      <td>0.888380</td>\n","      <td>0.784997</td>\n","      <td>0.007001</td>\n","      <td>0.001640</td>\n","      <td>0.616221</td>\n","      <td>0.998180</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>13611 rows Ã— 16 columns</p>\n","</div>"],"text/plain":["          Area  Perimeter  MajorAxisLength  MinorAxisLength  AspectRatio  \\\n","0      28395.0    638.018       208.178117       182.734419     1.197191   \n","1      28734.0    638.018       200.524796       182.734419     1.097356   \n","2      29380.0    624.110       212.826130       175.931143     1.209713   \n","3      30008.0    645.884       210.557999       182.516516     1.153638   \n","4      30140.0    620.134       201.847882       190.279279     1.060798   \n","...        ...        ...              ...              ...          ...   \n","13606  42097.0    759.696       288.721612       185.944705     1.552728   \n","13607  42101.0    757.499       281.576392       190.713136     1.476439   \n","13608  42139.0    759.321       281.539928       191.187979     1.472582   \n","13609  42147.0    763.779       283.382636       190.275731     1.489326   \n","13610  42159.0    772.237       295.142741       190.275731     1.619841   \n","\n","       Eccentricity  ConvexArea  EquivDiameter    Extent  Solidity  Roundness  \\\n","0          0.549812     28715.0     190.141097  0.763923  0.988856   0.958027   \n","1          0.411785     29172.0     191.272751  0.783968  0.984986   0.887034   \n","2          0.562727     29690.0     193.410904  0.778113  0.989559   0.947849   \n","3          0.498616     30724.0     195.467062  0.782681  0.976696   0.903936   \n","4          0.333680     30417.0     195.896503  0.773098  0.990893   0.984877   \n","...             ...         ...            ...       ...       ...        ...   \n","13606      0.765002     42508.0     231.515799  0.714574  0.990331   0.916603   \n","13607      0.765002     42508.0     231.526798  0.799943  0.990752   0.922015   \n","13608      0.734065     42569.0     231.631261  0.729932  0.989899   0.918424   \n","13609      0.741055     42667.0     231.653247  0.705389  0.987813   0.907906   \n","13610      0.786693     42600.0     231.686223  0.788962  0.989648   0.888380   \n","\n","       Compactness  ShapeFactor1  ShapeFactor2  ShapeFactor3  ShapeFactor4  \n","0         0.913358      0.007332      0.003147      0.834222      0.998430  \n","1         0.953861      0.006979      0.003564      0.834222      0.998430  \n","2         0.908774      0.007244      0.003048      0.825871      0.999066  \n","3         0.928329      0.007017      0.003215      0.861794      0.994199  \n","4         0.970516      0.006697      0.003665      0.941900      0.999166  \n","...            ...           ...           ...           ...           ...  \n","13606     0.801865      0.006858      0.001749      0.642988      0.998385  \n","13607     0.822252      0.006688      0.001749      0.676099      0.998219  \n","13608     0.822730      0.006681      0.001888      0.676884      0.996767  \n","13609     0.817457      0.006724      0.001852      0.668237      0.995222  \n","13610     0.784997      0.007001      0.001640      0.616221      0.998180  \n","\n","[13611 rows x 16 columns]"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["#Imputing Missing Values with Linear Interpolation\n","df_imputed = df.interpolate(method=\"nearest\", order=3, limit=None,\n","                            limit_direction='both').ffill().bfill()\n","df_imputed"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1704302604562,"user":{"displayName":"Victor Hugo Schneider Lopes","userId":"10992764016890176856"},"user_tz":180},"id":"dsT5e4MCtxV0","outputId":"1f63fbbe-974c-4794-e342-262d1476e04d"},"outputs":[{"name":"stdout","output_type":"stream","text":["          Area Perimeter MajorAxisLength MinorAxisLength AspectRatio  \\\n","         count     count           count           count       count   \n","Class                                                                  \n","BARBUNYA  1322      1322            1322            1322        1322   \n","BOMBAY     522       522             522             522         522   \n","CALI      1630      1630            1630            1630        1630   \n","DERMASON  3546      3546            3546            3546        3546   \n","HOROZ     1928      1928            1928            1928        1928   \n","SEKER     2027      2027            2027            2027        2027   \n","SIRA      2636      2636            2636            2636        2636   \n","\n","         Eccentricity ConvexArea EquivDiameter Extent Solidity Roundness  \\\n","                count      count         count  count    count     count   \n","Class                                                                      \n","BARBUNYA         1322       1322          1322   1322     1322      1322   \n","BOMBAY            522        522           522    522      522       522   \n","CALI             1630       1630          1630   1630     1630      1630   \n","DERMASON         3546       3546          3546   3546     3546      3546   \n","HOROZ            1928       1928          1928   1928     1928      1928   \n","SEKER            2027       2027          2027   2027     2027      2027   \n","SIRA             2636       2636          2636   2636     2636      2636   \n","\n","         Compactness ShapeFactor1 ShapeFactor2 ShapeFactor3 ShapeFactor4  \n","               count        count        count        count        count  \n","Class                                                                     \n","BARBUNYA        1322         1322         1322         1322         1322  \n","BOMBAY           522          522          522          522          522  \n","CALI            1630         1630         1630         1630         1630  \n","DERMASON        3546         3546         3546         3546         3546  \n","HOROZ           1928         1928         1928         1928         1928  \n","SEKER           2027         2027         2027         2027         2027  \n","SIRA            2636         2636         2636         2636         2636  \n"]}],"source":["#adding the labels\n","df_imputed['Class'] = targets\n","df_pre_missing_values = df.copy()\n","print(df_imputed.groupby('Class').agg(['count']))\n","df_imputed['Class'] = df_imputed['Class'].transform(lambda x: 0 if x == 'BARBUNYA' else (1 if x == 'BOMBAY' else (2 if x == 'CALI' else (3 if x == 'DERMASON' else (4 if x == 'HOROZ' else (5 if x == 'SEKER' else 6))))))"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":421,"status":"ok","timestamp":1704302604968,"user":{"displayName":"Victor Hugo Schneider Lopes","userId":"10992764016890176856"},"user_tz":180},"id":"ML8h0BGivuxc","outputId":"c4075f9d-acad-4866-fb7b-1c42e69c5433"},"outputs":[{"name":"stdout","output_type":"stream","text":["Pre Outlier Shape: (13611, 17)\n","[5 0 1 2 4 6 3]\n","Pos Outlier Shape: (12137, 17)\n"]}],"source":["#Outlier Removal with MAD\n","from scipy import stats\n","\n","print(f'Pre Outlier Shape: {df_imputed.shape}')\n","\n","df_no_outliers = df_imputed.copy()\n","print(df_no_outliers['Class'].unique())\n","for i in df_no_outliers['Class'].unique():\n","    class_unique = df_no_outliers[df_no_outliers['Class'] == i]\n","    for feature in class_unique:\n","      mad = 1.4826 * np.median(np.absolute(class_unique[feature] - class_unique[feature].median()))\n","      upper = class_unique[feature].median() + (3 * mad)\n","      lower = class_unique[feature].median() - (3 * mad)\n","      excluded_lower = pd.Series(class_unique[class_unique[feature] < lower].index)\n","      excluded_upper = pd.Series(class_unique[class_unique[feature] > upper].index)\n","      df_no_outliers.drop(excluded_lower.values, inplace = True, errors='ignore')\n","      df_no_outliers.drop(excluded_upper.values, inplace = True, errors='ignore')\n","\n","\n","print(f'Pos Outlier Shape: {df_no_outliers.shape}')"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":284,"status":"ok","timestamp":1704302605246,"user":{"displayName":"Victor Hugo Schneider Lopes","userId":"10992764016890176856"},"user_tz":180},"id":"LlYPv-ra64um","outputId":"6f88d710-7d94-4413-b264-6bf25e94fd55"},"outputs":[{"name":"stdout","output_type":"stream","text":["         index  Area Perimeter MajorAxisLength MinorAxisLength AspectRatio  \\\n","         count count     count           count           count       count   \n","Class                                                                        \n","BARBUNYA  1194  1194      1194            1194            1194        1194   \n","BOMBAY     472   472       472             472             472         472   \n","CALI      1511  1511      1511            1511            1511        1511   \n","DERMASON  3190  3190      3190            3190            3190        3190   \n","HOROZ     1619  1619      1619            1619            1619        1619   \n","SEKER     1752  1752      1752            1752            1752        1752   \n","SIRA      2399  2399      2399            2399            2399        2399   \n","\n","         Eccentricity ConvexArea EquivDiameter Extent Solidity Roundness  \\\n","                count      count         count  count    count     count   \n","Class                                                                      \n","BARBUNYA         1194       1194          1194   1194     1194      1194   \n","BOMBAY            472        472           472    472      472       472   \n","CALI             1511       1511          1511   1511     1511      1511   \n","DERMASON         3190       3190          3190   3190     3190      3190   \n","HOROZ            1619       1619          1619   1619     1619      1619   \n","SEKER            1752       1752          1752   1752     1752      1752   \n","SIRA             2399       2399          2399   2399     2399      2399   \n","\n","         Compactness ShapeFactor1 ShapeFactor2 ShapeFactor3 ShapeFactor4  \n","               count        count        count        count        count  \n","Class                                                                     \n","BARBUNYA        1194         1194         1194         1194         1194  \n","BOMBAY           472          472          472          472          472  \n","CALI            1511         1511         1511         1511         1511  \n","DERMASON        3190         3190         3190         3190         3190  \n","HOROZ           1619         1619         1619         1619         1619  \n","SEKER           1752         1752         1752         1752         1752  \n","SIRA            2399         2399         2399         2399         2399  \n"]}],"source":["df_no_outliers['Class'] = df_no_outliers['Class'].transform(lambda x: 'BARBUNYA' if x == 0 else ('BOMBAY' if x == 1 else ('CALI' if x == 2 else ('DERMASON' if x == 3 else ('HOROZ' if x == 4 else ('SEKER' if x == 5 else 'SIRA'))))))\n","df_no_outliers = df_no_outliers.reset_index()\n","print(df_no_outliers.groupby('Class').agg(['count']))"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":444},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1704302605249,"user":{"displayName":"Victor Hugo Schneider Lopes","userId":"10992764016890176856"},"user_tz":180},"id":"T8INyItCFB8j","outputId":"459eaf6f-e3fe-403a-9199-7280aabc384e"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Area</th>\n","      <th>Perimeter</th>\n","      <th>MajorAxisLength</th>\n","      <th>MinorAxisLength</th>\n","      <th>AspectRatio</th>\n","      <th>Eccentricity</th>\n","      <th>ConvexArea</th>\n","      <th>EquivDiameter</th>\n","      <th>Extent</th>\n","      <th>Solidity</th>\n","      <th>Roundness</th>\n","      <th>Compactness</th>\n","      <th>ShapeFactor1</th>\n","      <th>ShapeFactor2</th>\n","      <th>ShapeFactor3</th>\n","      <th>ShapeFactor4</th>\n","      <th>Class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>28395.0</td>\n","      <td>638.018</td>\n","      <td>208.178117</td>\n","      <td>182.734419</td>\n","      <td>1.197191</td>\n","      <td>0.549812</td>\n","      <td>28715.0</td>\n","      <td>190.141097</td>\n","      <td>0.763923</td>\n","      <td>0.988856</td>\n","      <td>0.958027</td>\n","      <td>0.913358</td>\n","      <td>0.007332</td>\n","      <td>0.003147</td>\n","      <td>0.834222</td>\n","      <td>0.998430</td>\n","      <td>SEKER</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>29380.0</td>\n","      <td>624.110</td>\n","      <td>212.826130</td>\n","      <td>175.931143</td>\n","      <td>1.209713</td>\n","      <td>0.562727</td>\n","      <td>29690.0</td>\n","      <td>193.410904</td>\n","      <td>0.778113</td>\n","      <td>0.989559</td>\n","      <td>0.947849</td>\n","      <td>0.908774</td>\n","      <td>0.007244</td>\n","      <td>0.003048</td>\n","      <td>0.825871</td>\n","      <td>0.999066</td>\n","      <td>SEKER</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>30140.0</td>\n","      <td>634.927</td>\n","      <td>212.560556</td>\n","      <td>181.510182</td>\n","      <td>1.060798</td>\n","      <td>0.520401</td>\n","      <td>30600.0</td>\n","      <td>196.347702</td>\n","      <td>0.775688</td>\n","      <td>0.989510</td>\n","      <td>0.943852</td>\n","      <td>0.923726</td>\n","      <td>0.006697</td>\n","      <td>0.003153</td>\n","      <td>0.853270</td>\n","      <td>0.999236</td>\n","      <td>SEKER</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>30519.0</td>\n","      <td>670.033</td>\n","      <td>212.996755</td>\n","      <td>182.737204</td>\n","      <td>1.165591</td>\n","      <td>0.513760</td>\n","      <td>30847.0</td>\n","      <td>197.124320</td>\n","      <td>0.770682</td>\n","      <td>0.989367</td>\n","      <td>0.967109</td>\n","      <td>0.925480</td>\n","      <td>0.006979</td>\n","      <td>0.003158</td>\n","      <td>0.856514</td>\n","      <td>0.998345</td>\n","      <td>SEKER</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>30685.0</td>\n","      <td>635.681</td>\n","      <td>213.534145</td>\n","      <td>183.157146</td>\n","      <td>1.165852</td>\n","      <td>0.514081</td>\n","      <td>31044.0</td>\n","      <td>197.659696</td>\n","      <td>0.771561</td>\n","      <td>0.988436</td>\n","      <td>0.954240</td>\n","      <td>0.925658</td>\n","      <td>0.006979</td>\n","      <td>0.003152</td>\n","      <td>0.856844</td>\n","      <td>0.998953</td>\n","      <td>SEKER</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>12132</th>\n","      <td>42097.0</td>\n","      <td>759.696</td>\n","      <td>288.721612</td>\n","      <td>185.944705</td>\n","      <td>1.552728</td>\n","      <td>0.765002</td>\n","      <td>42508.0</td>\n","      <td>231.515799</td>\n","      <td>0.714574</td>\n","      <td>0.990331</td>\n","      <td>0.916603</td>\n","      <td>0.801865</td>\n","      <td>0.006858</td>\n","      <td>0.001749</td>\n","      <td>0.642988</td>\n","      <td>0.998385</td>\n","      <td>DERMASON</td>\n","    </tr>\n","    <tr>\n","      <th>12133</th>\n","      <td>42101.0</td>\n","      <td>757.499</td>\n","      <td>281.576392</td>\n","      <td>190.713136</td>\n","      <td>1.476439</td>\n","      <td>0.765002</td>\n","      <td>42508.0</td>\n","      <td>231.526798</td>\n","      <td>0.799943</td>\n","      <td>0.990752</td>\n","      <td>0.922015</td>\n","      <td>0.822252</td>\n","      <td>0.006688</td>\n","      <td>0.001749</td>\n","      <td>0.676099</td>\n","      <td>0.998219</td>\n","      <td>DERMASON</td>\n","    </tr>\n","    <tr>\n","      <th>12134</th>\n","      <td>42139.0</td>\n","      <td>759.321</td>\n","      <td>281.539928</td>\n","      <td>191.187979</td>\n","      <td>1.472582</td>\n","      <td>0.734065</td>\n","      <td>42569.0</td>\n","      <td>231.631261</td>\n","      <td>0.729932</td>\n","      <td>0.989899</td>\n","      <td>0.918424</td>\n","      <td>0.822730</td>\n","      <td>0.006681</td>\n","      <td>0.001888</td>\n","      <td>0.676884</td>\n","      <td>0.996767</td>\n","      <td>DERMASON</td>\n","    </tr>\n","    <tr>\n","      <th>12135</th>\n","      <td>42147.0</td>\n","      <td>763.779</td>\n","      <td>283.382636</td>\n","      <td>190.275731</td>\n","      <td>1.489326</td>\n","      <td>0.741055</td>\n","      <td>42667.0</td>\n","      <td>231.653247</td>\n","      <td>0.705389</td>\n","      <td>0.987813</td>\n","      <td>0.907906</td>\n","      <td>0.817457</td>\n","      <td>0.006724</td>\n","      <td>0.001852</td>\n","      <td>0.668237</td>\n","      <td>0.995222</td>\n","      <td>DERMASON</td>\n","    </tr>\n","    <tr>\n","      <th>12136</th>\n","      <td>42159.0</td>\n","      <td>772.237</td>\n","      <td>295.142741</td>\n","      <td>190.275731</td>\n","      <td>1.619841</td>\n","      <td>0.786693</td>\n","      <td>42600.0</td>\n","      <td>231.686223</td>\n","      <td>0.788962</td>\n","      <td>0.989648</td>\n","      <td>0.888380</td>\n","      <td>0.784997</td>\n","      <td>0.007001</td>\n","      <td>0.001640</td>\n","      <td>0.616221</td>\n","      <td>0.998180</td>\n","      <td>DERMASON</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>12137 rows Ã— 17 columns</p>\n","</div>"],"text/plain":["          Area  Perimeter  MajorAxisLength  MinorAxisLength  AspectRatio  \\\n","0      28395.0    638.018       208.178117       182.734419     1.197191   \n","1      29380.0    624.110       212.826130       175.931143     1.209713   \n","2      30140.0    634.927       212.560556       181.510182     1.060798   \n","3      30519.0    670.033       212.996755       182.737204     1.165591   \n","4      30685.0    635.681       213.534145       183.157146     1.165852   \n","...        ...        ...              ...              ...          ...   \n","12132  42097.0    759.696       288.721612       185.944705     1.552728   \n","12133  42101.0    757.499       281.576392       190.713136     1.476439   \n","12134  42139.0    759.321       281.539928       191.187979     1.472582   \n","12135  42147.0    763.779       283.382636       190.275731     1.489326   \n","12136  42159.0    772.237       295.142741       190.275731     1.619841   \n","\n","       Eccentricity  ConvexArea  EquivDiameter    Extent  Solidity  Roundness  \\\n","0          0.549812     28715.0     190.141097  0.763923  0.988856   0.958027   \n","1          0.562727     29690.0     193.410904  0.778113  0.989559   0.947849   \n","2          0.520401     30600.0     196.347702  0.775688  0.989510   0.943852   \n","3          0.513760     30847.0     197.124320  0.770682  0.989367   0.967109   \n","4          0.514081     31044.0     197.659696  0.771561  0.988436   0.954240   \n","...             ...         ...            ...       ...       ...        ...   \n","12132      0.765002     42508.0     231.515799  0.714574  0.990331   0.916603   \n","12133      0.765002     42508.0     231.526798  0.799943  0.990752   0.922015   \n","12134      0.734065     42569.0     231.631261  0.729932  0.989899   0.918424   \n","12135      0.741055     42667.0     231.653247  0.705389  0.987813   0.907906   \n","12136      0.786693     42600.0     231.686223  0.788962  0.989648   0.888380   \n","\n","       Compactness  ShapeFactor1  ShapeFactor2  ShapeFactor3  ShapeFactor4  \\\n","0         0.913358      0.007332      0.003147      0.834222      0.998430   \n","1         0.908774      0.007244      0.003048      0.825871      0.999066   \n","2         0.923726      0.006697      0.003153      0.853270      0.999236   \n","3         0.925480      0.006979      0.003158      0.856514      0.998345   \n","4         0.925658      0.006979      0.003152      0.856844      0.998953   \n","...            ...           ...           ...           ...           ...   \n","12132     0.801865      0.006858      0.001749      0.642988      0.998385   \n","12133     0.822252      0.006688      0.001749      0.676099      0.998219   \n","12134     0.822730      0.006681      0.001888      0.676884      0.996767   \n","12135     0.817457      0.006724      0.001852      0.668237      0.995222   \n","12136     0.784997      0.007001      0.001640      0.616221      0.998180   \n","\n","          Class  \n","0         SEKER  \n","1         SEKER  \n","2         SEKER  \n","3         SEKER  \n","4         SEKER  \n","...         ...  \n","12132  DERMASON  \n","12133  DERMASON  \n","12134  DERMASON  \n","12135  DERMASON  \n","12136  DERMASON  \n","\n","[12137 rows x 17 columns]"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["df_no_outliers = df_no_outliers.drop(['index'], axis='columns')\n","df_no_outliers"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":444},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1704302605250,"user":{"displayName":"Victor Hugo Schneider Lopes","userId":"10992764016890176856"},"user_tz":180},"id":"nSe3jkEjynF6","outputId":"4f13bdc8-b0fc-4832-8260-29231a1a842c"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Area</th>\n","      <th>Perimeter</th>\n","      <th>MajorAxisLength</th>\n","      <th>MinorAxisLength</th>\n","      <th>AspectRatio</th>\n","      <th>Eccentricity</th>\n","      <th>ConvexArea</th>\n","      <th>EquivDiameter</th>\n","      <th>Extent</th>\n","      <th>Solidity</th>\n","      <th>Roundness</th>\n","      <th>Compactness</th>\n","      <th>ShapeFactor1</th>\n","      <th>ShapeFactor2</th>\n","      <th>ShapeFactor3</th>\n","      <th>ShapeFactor4</th>\n","      <th>Class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.036581</td>\n","      <td>0.078671</td>\n","      <td>0.030954</td>\n","      <td>0.159089</td>\n","      <td>0.102700</td>\n","      <td>0.298646</td>\n","      <td>0.036121</td>\n","      <td>0.074402</td>\n","      <td>0.671024</td>\n","      <td>0.765887</td>\n","      <td>0.899867</td>\n","      <td>0.852101</td>\n","      <td>0.669818</td>\n","      <td>0.904894</td>\n","      <td>0.833734</td>\n","      <td>0.936054</td>\n","      <td>SEKER</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.041124</td>\n","      <td>0.068688</td>\n","      <td>0.039453</td>\n","      <td>0.136911</td>\n","      <td>0.112128</td>\n","      <td>0.323695</td>\n","      <td>0.040555</td>\n","      <td>0.082821</td>\n","      <td>0.716671</td>\n","      <td>0.794149</td>\n","      <td>0.868661</td>\n","      <td>0.837527</td>\n","      <td>0.656551</td>\n","      <td>0.870018</td>\n","      <td>0.817065</td>\n","      <td>0.967276</td>\n","      <td>SEKER</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.044630</td>\n","      <td>0.076452</td>\n","      <td>0.038968</td>\n","      <td>0.155099</td>\n","      <td>0.000000</td>\n","      <td>0.241601</td>\n","      <td>0.044693</td>\n","      <td>0.090382</td>\n","      <td>0.708871</td>\n","      <td>0.792180</td>\n","      <td>0.856404</td>\n","      <td>0.885067</td>\n","      <td>0.573717</td>\n","      <td>0.906817</td>\n","      <td>0.871750</td>\n","      <td>0.975607</td>\n","      <td>SEKER</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.046378</td>\n","      <td>0.101649</td>\n","      <td>0.039765</td>\n","      <td>0.159099</td>\n","      <td>0.078906</td>\n","      <td>0.228721</td>\n","      <td>0.045816</td>\n","      <td>0.092382</td>\n","      <td>0.692766</td>\n","      <td>0.786432</td>\n","      <td>0.927713</td>\n","      <td>0.890646</td>\n","      <td>0.616450</td>\n","      <td>0.908746</td>\n","      <td>0.878226</td>\n","      <td>0.931842</td>\n","      <td>SEKER</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.047144</td>\n","      <td>0.076993</td>\n","      <td>0.040748</td>\n","      <td>0.160468</td>\n","      <td>0.079103</td>\n","      <td>0.229344</td>\n","      <td>0.046712</td>\n","      <td>0.093760</td>\n","      <td>0.695596</td>\n","      <td>0.748987</td>\n","      <td>0.888254</td>\n","      <td>0.891212</td>\n","      <td>0.616450</td>\n","      <td>0.906386</td>\n","      <td>0.878884</td>\n","      <td>0.961719</td>\n","      <td>SEKER</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>12132</th>\n","      <td>0.099780</td>\n","      <td>0.166003</td>\n","      <td>0.178228</td>\n","      <td>0.169555</td>\n","      <td>0.370408</td>\n","      <td>0.716013</td>\n","      <td>0.098845</td>\n","      <td>0.180930</td>\n","      <td>0.512286</td>\n","      <td>0.825214</td>\n","      <td>0.772857</td>\n","      <td>0.497599</td>\n","      <td>0.598174</td>\n","      <td>0.415091</td>\n","      <td>0.452048</td>\n","      <td>0.933840</td>\n","      <td>DERMASON</td>\n","    </tr>\n","    <tr>\n","      <th>12133</th>\n","      <td>0.099799</td>\n","      <td>0.164426</td>\n","      <td>0.165163</td>\n","      <td>0.185100</td>\n","      <td>0.312965</td>\n","      <td>0.716013</td>\n","      <td>0.098845</td>\n","      <td>0.180958</td>\n","      <td>0.786890</td>\n","      <td>0.842120</td>\n","      <td>0.789451</td>\n","      <td>0.562422</td>\n","      <td>0.572370</td>\n","      <td>0.415091</td>\n","      <td>0.518134</td>\n","      <td>0.925659</td>\n","      <td>DERMASON</td>\n","    </tr>\n","    <tr>\n","      <th>12134</th>\n","      <td>0.099974</td>\n","      <td>0.165734</td>\n","      <td>0.165097</td>\n","      <td>0.186648</td>\n","      <td>0.310060</td>\n","      <td>0.656009</td>\n","      <td>0.099123</td>\n","      <td>0.181227</td>\n","      <td>0.561689</td>\n","      <td>0.807821</td>\n","      <td>0.778440</td>\n","      <td>0.563940</td>\n","      <td>0.571325</td>\n","      <td>0.463847</td>\n","      <td>0.519702</td>\n","      <td>0.854387</td>\n","      <td>DERMASON</td>\n","    </tr>\n","    <tr>\n","      <th>12135</th>\n","      <td>0.100011</td>\n","      <td>0.168933</td>\n","      <td>0.168466</td>\n","      <td>0.183674</td>\n","      <td>0.322669</td>\n","      <td>0.669566</td>\n","      <td>0.099568</td>\n","      <td>0.181284</td>\n","      <td>0.482741</td>\n","      <td>0.723926</td>\n","      <td>0.746192</td>\n","      <td>0.547176</td>\n","      <td>0.577755</td>\n","      <td>0.451149</td>\n","      <td>0.502443</td>\n","      <td>0.778525</td>\n","      <td>DERMASON</td>\n","    </tr>\n","    <tr>\n","      <th>12136</th>\n","      <td>0.100066</td>\n","      <td>0.175004</td>\n","      <td>0.189970</td>\n","      <td>0.183674</td>\n","      <td>0.420942</td>\n","      <td>0.758083</td>\n","      <td>0.099264</td>\n","      <td>0.181369</td>\n","      <td>0.751569</td>\n","      <td>0.797733</td>\n","      <td>0.686323</td>\n","      <td>0.443966</td>\n","      <td>0.619715</td>\n","      <td>0.376809</td>\n","      <td>0.398624</td>\n","      <td>0.923743</td>\n","      <td>DERMASON</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>12137 rows Ã— 17 columns</p>\n","</div>"],"text/plain":["           Area  Perimeter  MajorAxisLength  MinorAxisLength  AspectRatio  \\\n","0      0.036581   0.078671         0.030954         0.159089     0.102700   \n","1      0.041124   0.068688         0.039453         0.136911     0.112128   \n","2      0.044630   0.076452         0.038968         0.155099     0.000000   \n","3      0.046378   0.101649         0.039765         0.159099     0.078906   \n","4      0.047144   0.076993         0.040748         0.160468     0.079103   \n","...         ...        ...              ...              ...          ...   \n","12132  0.099780   0.166003         0.178228         0.169555     0.370408   \n","12133  0.099799   0.164426         0.165163         0.185100     0.312965   \n","12134  0.099974   0.165734         0.165097         0.186648     0.310060   \n","12135  0.100011   0.168933         0.168466         0.183674     0.322669   \n","12136  0.100066   0.175004         0.189970         0.183674     0.420942   \n","\n","       Eccentricity  ConvexArea  EquivDiameter    Extent  Solidity  Roundness  \\\n","0          0.298646    0.036121       0.074402  0.671024  0.765887   0.899867   \n","1          0.323695    0.040555       0.082821  0.716671  0.794149   0.868661   \n","2          0.241601    0.044693       0.090382  0.708871  0.792180   0.856404   \n","3          0.228721    0.045816       0.092382  0.692766  0.786432   0.927713   \n","4          0.229344    0.046712       0.093760  0.695596  0.748987   0.888254   \n","...             ...         ...            ...       ...       ...        ...   \n","12132      0.716013    0.098845       0.180930  0.512286  0.825214   0.772857   \n","12133      0.716013    0.098845       0.180958  0.786890  0.842120   0.789451   \n","12134      0.656009    0.099123       0.181227  0.561689  0.807821   0.778440   \n","12135      0.669566    0.099568       0.181284  0.482741  0.723926   0.746192   \n","12136      0.758083    0.099264       0.181369  0.751569  0.797733   0.686323   \n","\n","       Compactness  ShapeFactor1  ShapeFactor2  ShapeFactor3  ShapeFactor4  \\\n","0         0.852101      0.669818      0.904894      0.833734      0.936054   \n","1         0.837527      0.656551      0.870018      0.817065      0.967276   \n","2         0.885067      0.573717      0.906817      0.871750      0.975607   \n","3         0.890646      0.616450      0.908746      0.878226      0.931842   \n","4         0.891212      0.616450      0.906386      0.878884      0.961719   \n","...            ...           ...           ...           ...           ...   \n","12132     0.497599      0.598174      0.415091      0.452048      0.933840   \n","12133     0.562422      0.572370      0.415091      0.518134      0.925659   \n","12134     0.563940      0.571325      0.463847      0.519702      0.854387   \n","12135     0.547176      0.577755      0.451149      0.502443      0.778525   \n","12136     0.443966      0.619715      0.376809      0.398624      0.923743   \n","\n","          Class  \n","0         SEKER  \n","1         SEKER  \n","2         SEKER  \n","3         SEKER  \n","4         SEKER  \n","...         ...  \n","12132  DERMASON  \n","12133  DERMASON  \n","12134  DERMASON  \n","12135  DERMASON  \n","12136  DERMASON  \n","\n","[12137 rows x 17 columns]"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["#Normalization with min max\n","from sklearn.preprocessing import MinMaxScaler\n","\n","scaler = MinMaxScaler()\n","scaler.fit_transform(df_no_outliers[cols])\n","df_scaled = pd.DataFrame(scaler.transform(df_no_outliers[cols]), columns = cols)\n","\n","df_scaled['Class'] = df_no_outliers['Class']\n","df_scaled"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27997,"status":"ok","timestamp":1704302633229,"user":{"displayName":"Victor Hugo Schneider Lopes","userId":"10992764016890176856"},"user_tz":180},"id":"0dBs8lW22D02","outputId":"d1212a3c-639c-4b24-9615-b226e7a31a29"},"outputs":[{"name":"stdout","output_type":"stream","text":["Iteration 1, loss = 1.24686277\n","Iteration 2, loss = 0.92529658\n","Iteration 3, loss = 0.80450898\n","Iteration 4, loss = 0.53040002\n","Iteration 5, loss = 0.41765903\n","Iteration 6, loss = 0.34357181\n","Iteration 7, loss = 0.32662380\n","Iteration 8, loss = 0.29807747\n","Iteration 9, loss = 0.25812623\n","Iteration 10, loss = 0.24471250\n","Iteration 11, loss = 0.22482008\n","Iteration 12, loss = 0.23866779\n","Iteration 13, loss = 0.24624899\n","Iteration 14, loss = 0.25498441\n","Iteration 15, loss = 0.19716991\n","Iteration 16, loss = 0.20268966\n","Iteration 17, loss = 0.19230465\n","Iteration 18, loss = 0.18828434\n","Iteration 19, loss = 0.19620369\n","Iteration 20, loss = 0.17570542\n","Iteration 21, loss = 0.17893759\n","Iteration 22, loss = 0.16511385\n","Iteration 23, loss = 0.17422840\n","Iteration 24, loss = 0.19686094\n","Iteration 25, loss = 0.18629225\n","Iteration 26, loss = 0.16750299\n","Iteration 27, loss = 0.16210524\n","Iteration 28, loss = 0.18108054\n","Iteration 29, loss = 0.16591131\n","Iteration 30, loss = 0.14945480\n","Iteration 31, loss = 0.18108869\n","Iteration 32, loss = 0.14779572\n","Iteration 33, loss = 0.14890083\n","Iteration 34, loss = 0.15838197\n","Iteration 35, loss = 0.19923808\n","Iteration 36, loss = 0.15970458\n","Iteration 37, loss = 0.14180112\n","Iteration 38, loss = 0.15848844\n","Iteration 39, loss = 0.16616577\n","Iteration 40, loss = 0.19668855\n","Iteration 41, loss = 0.13621906\n","Iteration 42, loss = 0.14887499\n","Iteration 43, loss = 0.13755086\n","Iteration 44, loss = 0.15167325\n","Iteration 45, loss = 0.13456458\n","Iteration 46, loss = 0.13997162\n","Iteration 47, loss = 0.14461074\n","Iteration 48, loss = 0.16065376\n","Iteration 49, loss = 0.14915512\n","Iteration 50, loss = 0.14549745\n","Iteration 51, loss = 0.18333893\n","Iteration 52, loss = 0.16085407\n","Iteration 53, loss = 0.16226760\n","Iteration 54, loss = 0.13233291\n","Iteration 55, loss = 0.15271341\n","Iteration 56, loss = 0.14520046\n","Iteration 57, loss = 0.17576731\n","Iteration 58, loss = 0.14903820\n","Iteration 59, loss = 0.14717926\n","Iteration 60, loss = 0.15057084\n","Iteration 61, loss = 0.14186645\n","Iteration 62, loss = 0.15228601\n","Iteration 63, loss = 0.14463548\n","Iteration 64, loss = 0.17649041\n","Iteration 65, loss = 0.15415839\n","Training loss did not improve more than tol=0.001000 for 10 consecutive epochs. Stopping.\n","Iteration 1, loss = 1.28832399\n","Iteration 2, loss = 0.97871504\n","Iteration 3, loss = 0.87349646\n","Iteration 4, loss = 0.70878890\n","Iteration 5, loss = 0.56933953\n","Iteration 6, loss = 0.51236742\n","Iteration 7, loss = 0.44025884\n","Iteration 8, loss = 0.42784872\n","Iteration 9, loss = 0.42121290\n","Iteration 10, loss = 0.40732515\n","Iteration 11, loss = 0.40562282\n","Iteration 12, loss = 0.39937559\n","Iteration 13, loss = 0.39856876\n","Iteration 14, loss = 0.35810829\n","Iteration 15, loss = 0.36919784\n","Iteration 16, loss = 0.37138381\n","Iteration 17, loss = 0.40106462\n","Iteration 18, loss = 0.43553088\n","Iteration 19, loss = 0.40575590\n","Iteration 20, loss = 0.37616503\n","Iteration 21, loss = 0.35527913\n","Iteration 22, loss = 0.39199120\n","Iteration 23, loss = 0.36857593\n","Iteration 24, loss = 0.39482517\n","Iteration 25, loss = 0.38063859\n","Iteration 26, loss = 0.53853709\n","Iteration 27, loss = 0.43518459\n","Iteration 28, loss = 0.37430516\n","Iteration 29, loss = 0.38963785\n","Iteration 30, loss = 0.36690131\n","Iteration 31, loss = 0.37640748\n","Iteration 32, loss = 0.37914373\n","Training loss did not improve more than tol=0.001000 for 10 consecutive epochs. Stopping.\n","Iteration 1, loss = 1.29350682\n","Iteration 2, loss = 0.95612662\n","Iteration 3, loss = 0.75124357\n","Iteration 4, loss = 0.59806426\n","Iteration 5, loss = 0.49079093\n","Iteration 6, loss = 0.41311338\n","Iteration 7, loss = 0.40606529\n","Iteration 8, loss = 0.45538336\n","Iteration 9, loss = 0.40811707\n","Iteration 10, loss = 0.37252785\n","Iteration 11, loss = 0.36855515\n","Iteration 12, loss = 0.36562370\n","Iteration 13, loss = 0.33803285\n","Iteration 14, loss = 0.31689711\n","Iteration 15, loss = 0.33004324\n","Iteration 16, loss = 0.29439277\n","Iteration 17, loss = 0.29521762\n","Iteration 18, loss = 0.27880117\n","Iteration 19, loss = 0.29982011\n","Iteration 20, loss = 0.30086201\n","Iteration 21, loss = 0.26553449\n","Iteration 22, loss = 0.26725110\n","Iteration 23, loss = 0.26592408\n","Iteration 24, loss = 0.26396384\n","Iteration 25, loss = 0.27555740\n","Iteration 26, loss = 0.29516073\n","Iteration 27, loss = 0.24921211\n","Iteration 28, loss = 0.25238966\n","Iteration 29, loss = 0.26712486\n","Iteration 30, loss = 0.28316058\n","Iteration 31, loss = 0.24216997\n","Iteration 32, loss = 0.23594699\n","Iteration 33, loss = 0.23872226\n","Iteration 34, loss = 0.23622390\n","Iteration 35, loss = 0.22846636\n","Iteration 36, loss = 0.25395609\n","Iteration 37, loss = 0.23729502\n","Iteration 38, loss = 0.22336901\n","Iteration 39, loss = 0.23032852\n","Iteration 40, loss = 0.22984780\n","Iteration 41, loss = 0.21565574\n","Iteration 42, loss = 0.21613297\n","Iteration 43, loss = 0.21362869\n","Iteration 44, loss = 0.21844237\n","Iteration 45, loss = 0.20562341\n","Iteration 46, loss = 0.23787612\n","Iteration 47, loss = 0.27632638\n","Iteration 48, loss = 0.23130430\n","Iteration 49, loss = 0.24099440\n","Iteration 50, loss = 0.26998815\n","Iteration 51, loss = 0.24418310\n","Iteration 52, loss = 0.22290770\n","Iteration 53, loss = 0.22243178\n","Iteration 54, loss = 0.20577865\n","Iteration 55, loss = 0.21351811\n","Iteration 56, loss = 0.23929221\n","Training loss did not improve more than tol=0.001000 for 10 consecutive epochs. Stopping.\n","Iteration 1, loss = 1.29176120\n","Iteration 2, loss = 0.94613755\n","Iteration 3, loss = 0.80662057\n","Iteration 4, loss = 0.70545116\n","Iteration 5, loss = 0.60270727\n","Iteration 6, loss = 0.53713041\n","Iteration 7, loss = 0.45529596\n","Iteration 8, loss = 0.43699711\n","Iteration 9, loss = 0.37239368\n","Iteration 10, loss = 0.46304607\n","Iteration 11, loss = 0.38603473\n","Iteration 12, loss = 0.33408254\n","Iteration 13, loss = 0.31238387\n","Iteration 14, loss = 0.30103357\n","Iteration 15, loss = 0.28887615\n","Iteration 16, loss = 0.26614421\n","Iteration 17, loss = 0.27046425\n","Iteration 18, loss = 0.27545197\n","Iteration 19, loss = 0.27626742\n","Iteration 20, loss = 0.27502095\n","Iteration 21, loss = 0.26871507\n","Iteration 22, loss = 0.26700742\n","Iteration 23, loss = 0.26499544\n","Iteration 24, loss = 0.24670959\n","Iteration 25, loss = 0.23995734\n","Iteration 26, loss = 0.27064974\n","Iteration 27, loss = 0.25639608\n","Iteration 28, loss = 0.30210240\n","Iteration 29, loss = 0.24155484\n","Iteration 30, loss = 0.25214056\n","Iteration 31, loss = 0.25206121\n","Iteration 32, loss = 0.24163404\n","Iteration 33, loss = 0.23861678\n","Iteration 34, loss = 0.24031904\n","Iteration 35, loss = 0.24210742\n","Iteration 36, loss = 0.22921383\n","Iteration 37, loss = 0.26037573\n","Iteration 38, loss = 0.25463167\n","Iteration 39, loss = 0.23178927\n","Iteration 40, loss = 0.24316493\n","Iteration 41, loss = 0.23442207\n","Iteration 42, loss = 0.23982370\n","Iteration 43, loss = 0.24888318\n","Iteration 44, loss = 0.21930519\n","Iteration 45, loss = 0.22052582\n","Iteration 46, loss = 0.23826704\n","Iteration 47, loss = 0.24044883\n","Iteration 48, loss = 0.21417105\n","Iteration 49, loss = 0.23733487\n","Iteration 50, loss = 0.23159140\n","Iteration 51, loss = 0.22250265\n","Iteration 52, loss = 0.21784305\n","Iteration 53, loss = 0.22000880\n","Iteration 54, loss = 0.20898369\n","Iteration 55, loss = 0.20495314\n","Iteration 56, loss = 0.21292403\n","Iteration 57, loss = 0.22535926\n","Iteration 58, loss = 0.22208448\n","Iteration 59, loss = 0.22538794\n","Iteration 60, loss = 0.22285176\n","Iteration 61, loss = 0.22330553\n","Iteration 62, loss = 0.21895162\n","Iteration 63, loss = 0.21536949\n","Iteration 64, loss = 0.20891266\n","Iteration 65, loss = 0.22835253\n","Iteration 66, loss = 0.22895757\n","Training loss did not improve more than tol=0.001000 for 10 consecutive epochs. Stopping.\n","Iteration 1, loss = 1.29589043\n","Iteration 2, loss = 0.94488744\n","Iteration 3, loss = 0.73754009\n","Iteration 4, loss = 0.57382066\n","Iteration 5, loss = 0.51088715\n","Iteration 6, loss = 0.40468560\n","Iteration 7, loss = 0.39670485\n","Iteration 8, loss = 0.39803860\n","Iteration 9, loss = 0.34326234\n","Iteration 10, loss = 0.36534277\n","Iteration 11, loss = 0.36857246\n","Iteration 12, loss = 0.32336921\n","Iteration 13, loss = 0.34736697\n","Iteration 14, loss = 0.30133994\n","Iteration 15, loss = 0.31154089\n","Iteration 16, loss = 0.30016388\n","Iteration 17, loss = 0.32450985\n","Iteration 18, loss = 0.27944482\n","Iteration 19, loss = 0.29587195\n","Iteration 20, loss = 0.27615280\n","Iteration 21, loss = 0.27184907\n","Iteration 22, loss = 0.30061687\n","Iteration 23, loss = 0.28078348\n","Iteration 24, loss = 0.25071081\n","Iteration 25, loss = 0.27916683\n","Iteration 26, loss = 0.29896310\n","Iteration 27, loss = 0.27160038\n","Iteration 28, loss = 0.27255503\n","Iteration 29, loss = 0.30954959\n","Iteration 30, loss = 0.25333585\n","Iteration 31, loss = 0.25274536\n","Iteration 32, loss = 0.23491023\n","Iteration 33, loss = 0.23944126\n","Iteration 34, loss = 0.23841906\n","Iteration 35, loss = 0.23120588\n","Iteration 36, loss = 0.23063340\n","Iteration 37, loss = 0.22116660\n","Iteration 38, loss = 0.22414289\n","Iteration 39, loss = 0.24319481\n","Iteration 40, loss = 0.24115638\n","Iteration 41, loss = 0.21242565\n","Iteration 42, loss = 0.22310141\n","Iteration 43, loss = 0.22943237\n","Iteration 44, loss = 0.23092724\n","Iteration 45, loss = 0.22451275\n","Iteration 46, loss = 0.23044118\n","Iteration 47, loss = 0.24092863\n","Iteration 48, loss = 0.21432938\n","Iteration 49, loss = 0.21957455\n","Iteration 50, loss = 0.27633427\n","Iteration 51, loss = 0.25285839\n","Iteration 52, loss = 0.22306760\n","Training loss did not improve more than tol=0.001000 for 10 consecutive epochs. Stopping.\n","Iteration 1, loss = 1.28405337\n","Iteration 2, loss = 0.96147727\n","Iteration 3, loss = 0.77870380\n","Iteration 4, loss = 0.58212114\n","Iteration 5, loss = 0.46406512\n","Iteration 6, loss = 0.41548120\n","Iteration 7, loss = 0.40719747\n","Iteration 8, loss = 0.42869240\n","Iteration 9, loss = 0.37329213\n","Iteration 10, loss = 0.35022485\n","Iteration 11, loss = 0.34585927\n","Iteration 12, loss = 0.35406801\n","Iteration 13, loss = 0.35211322\n","Iteration 14, loss = 0.32538336\n","Iteration 15, loss = 0.30087828\n","Iteration 16, loss = 0.32946316\n","Iteration 17, loss = 0.32492819\n","Iteration 18, loss = 0.28606261\n","Iteration 19, loss = 0.30349353\n","Iteration 20, loss = 0.29698423\n","Iteration 21, loss = 0.28478621\n","Iteration 22, loss = 0.28021334\n","Iteration 23, loss = 0.27080078\n","Iteration 24, loss = 0.27883565\n","Iteration 25, loss = 0.26568825\n","Iteration 26, loss = 0.27022970\n","Iteration 27, loss = 0.29028677\n","Iteration 28, loss = 0.32856844\n","Iteration 29, loss = 0.28857675\n","Iteration 30, loss = 0.24710032\n","Iteration 31, loss = 0.25724426\n","Iteration 32, loss = 0.24529343\n","Iteration 33, loss = 0.24262629\n","Iteration 34, loss = 0.25120373\n","Iteration 35, loss = 0.25011534\n","Iteration 36, loss = 0.26304874\n","Iteration 37, loss = 0.22891338\n","Iteration 38, loss = 0.24709841\n","Iteration 39, loss = 0.23716905\n","Iteration 40, loss = 0.24905725\n","Iteration 41, loss = 0.21922760\n","Iteration 42, loss = 0.27202954\n","Iteration 43, loss = 0.26686706\n","Iteration 44, loss = 0.23930275\n","Iteration 45, loss = 0.21947656\n","Iteration 46, loss = 0.24714915\n","Iteration 47, loss = 0.28842488\n","Iteration 48, loss = 0.24881454\n","Iteration 49, loss = 0.24852820\n","Iteration 50, loss = 0.27057486\n","Iteration 51, loss = 0.24300804\n","Iteration 52, loss = 0.24525030\n","Training loss did not improve more than tol=0.001000 for 10 consecutive epochs. Stopping.\n","Iteration 1, loss = 1.27992983\n","Iteration 2, loss = 0.95723209\n","Iteration 3, loss = 0.78279201\n","Iteration 4, loss = 0.64921795\n","Iteration 5, loss = 0.50949405\n","Iteration 6, loss = 0.45279261\n","Iteration 7, loss = 0.41150185\n","Iteration 8, loss = 0.44968219\n","Iteration 9, loss = 0.34179953\n","Iteration 10, loss = 0.26196864\n","Iteration 11, loss = 0.26456228\n","Iteration 12, loss = 0.30595345\n","Iteration 13, loss = 0.30792201\n","Iteration 14, loss = 0.30553515\n","Iteration 15, loss = 0.27476034\n","Iteration 16, loss = 0.26083330\n","Iteration 17, loss = 0.32295012\n","Iteration 18, loss = 0.24377450\n","Iteration 19, loss = 0.26515002\n","Iteration 20, loss = 0.23663268\n","Iteration 21, loss = 0.23333689\n","Iteration 22, loss = 0.26312797\n","Iteration 23, loss = 0.24267620\n","Iteration 24, loss = 0.22030653\n","Iteration 25, loss = 0.24965146\n","Iteration 26, loss = 0.22990720\n","Iteration 27, loss = 0.23533148\n","Iteration 28, loss = 0.25724668\n","Iteration 29, loss = 0.24906661\n","Iteration 30, loss = 0.22960278\n","Iteration 31, loss = 0.22180096\n","Iteration 32, loss = 0.22544654\n","Iteration 33, loss = 0.23283358\n","Iteration 34, loss = 0.24890086\n","Iteration 35, loss = 0.27026914\n","Training loss did not improve more than tol=0.001000 for 10 consecutive epochs. Stopping.\n","Iteration 1, loss = 1.28709031\n","Iteration 2, loss = 0.79722077\n","Iteration 3, loss = 0.49521328\n","Iteration 4, loss = 0.35564941\n","Iteration 5, loss = 0.31106289\n","Iteration 6, loss = 0.29921292\n","Iteration 7, loss = 0.30077468\n","Iteration 8, loss = 0.26446076\n","Iteration 9, loss = 0.24704673\n","Iteration 10, loss = 0.25137322\n","Iteration 11, loss = 0.20169111\n","Iteration 12, loss = 0.20107358\n","Iteration 13, loss = 0.20081393\n","Iteration 14, loss = 0.22293907\n","Iteration 15, loss = 0.21225492\n","Iteration 16, loss = 0.19765442\n","Iteration 17, loss = 0.19157390\n","Iteration 18, loss = 0.20591330\n","Iteration 19, loss = 0.19232367\n","Iteration 20, loss = 0.19337721\n","Iteration 21, loss = 0.20245654\n","Iteration 22, loss = 0.19922961\n","Iteration 23, loss = 0.19585298\n","Iteration 24, loss = 0.18190883\n","Iteration 25, loss = 0.20553235\n","Iteration 26, loss = 0.19806474\n","Iteration 27, loss = 0.20010072\n","Iteration 28, loss = 0.19460407\n","Iteration 29, loss = 0.21022983\n","Iteration 30, loss = 0.18988743\n","Iteration 31, loss = 0.19452117\n","Iteration 32, loss = 0.18800855\n","Iteration 33, loss = 0.17557660\n","Iteration 34, loss = 0.18957679\n","Iteration 35, loss = 0.21603711\n","Iteration 36, loss = 0.19264264\n","Iteration 37, loss = 0.19711495\n","Iteration 38, loss = 0.18619503\n","Iteration 39, loss = 0.20207983\n","Iteration 40, loss = 0.20469681\n","Iteration 41, loss = 0.19792962\n","Iteration 42, loss = 0.19677844\n","Iteration 43, loss = 0.18809711\n","Iteration 44, loss = 0.19682952\n","Training loss did not improve more than tol=0.001000 for 10 consecutive epochs. Stopping.\n","Iteration 1, loss = 1.29157066\n","Iteration 2, loss = 0.94542212\n","Iteration 3, loss = 0.75444879\n","Iteration 4, loss = 0.66279430\n","Iteration 5, loss = 0.49558632\n","Iteration 6, loss = 0.49650929\n","Iteration 7, loss = 0.41099154\n","Iteration 8, loss = 0.40123969\n","Iteration 9, loss = 0.40810605\n","Iteration 10, loss = 0.40363657\n","Iteration 11, loss = 0.37327593\n","Iteration 12, loss = 0.40629515\n","Iteration 13, loss = 0.41179414\n","Iteration 14, loss = 0.37238484\n","Iteration 15, loss = 0.37645006\n","Iteration 16, loss = 0.43301422\n","Iteration 17, loss = 0.39845855\n","Iteration 18, loss = 0.36851122\n","Iteration 19, loss = 0.37854800\n","Iteration 20, loss = 0.37999885\n","Iteration 21, loss = 0.38897444\n","Iteration 22, loss = 0.37643209\n","Iteration 23, loss = 0.37381419\n","Iteration 24, loss = 0.38942129\n","Iteration 25, loss = 0.37218646\n","Iteration 26, loss = 0.38917574\n","Iteration 27, loss = 0.37061637\n","Iteration 28, loss = 0.36346596\n","Iteration 29, loss = 0.36072663\n","Iteration 30, loss = 0.38094213\n","Iteration 31, loss = 0.37175085\n","Iteration 32, loss = 0.35261735\n","Iteration 33, loss = 0.37742988\n","Iteration 34, loss = 0.41361047\n","Iteration 35, loss = 0.38465793\n","Iteration 36, loss = 0.37508879\n","Iteration 37, loss = 0.35249151\n","Iteration 38, loss = 0.36480836\n","Iteration 39, loss = 0.36546970\n","Iteration 40, loss = 0.37702920\n","Iteration 41, loss = 0.36718249\n","Iteration 42, loss = 0.37306423\n","Iteration 43, loss = 0.34646735\n","Iteration 44, loss = 0.35253272\n","Iteration 45, loss = 0.37231326\n","Iteration 46, loss = 0.35887424\n","Iteration 47, loss = 0.35707061\n","Iteration 48, loss = 0.36288920\n","Iteration 49, loss = 0.35146991\n","Iteration 50, loss = 0.35256282\n","Iteration 51, loss = 0.35701779\n","Iteration 52, loss = 0.37354476\n","Iteration 53, loss = 0.33785681\n","Iteration 54, loss = 0.34878294\n","Iteration 55, loss = 0.34860825\n","Iteration 56, loss = 0.34233701\n","Iteration 57, loss = 0.36765483\n","Iteration 58, loss = 0.35357117\n","Iteration 59, loss = 0.35457232\n","Iteration 60, loss = 0.35427432\n","Iteration 61, loss = 0.36850051\n","Iteration 62, loss = 0.35772270\n","Iteration 63, loss = 0.34663320\n","Iteration 64, loss = 0.35932958\n","Training loss did not improve more than tol=0.001000 for 10 consecutive epochs. Stopping.\n","Iteration 1, loss = 1.27321420\n","Iteration 2, loss = 0.69919376\n","Iteration 3, loss = 0.35899097\n","Iteration 4, loss = 0.26157731\n","Iteration 5, loss = 0.20017264\n","Iteration 6, loss = 0.17520749\n","Iteration 7, loss = 0.16633417\n","Iteration 8, loss = 0.14944824\n","Iteration 9, loss = 0.18074665\n","Iteration 10, loss = 0.17576637\n","Iteration 11, loss = 0.13479187\n","Iteration 12, loss = 0.14189317\n","Iteration 13, loss = 0.13210332\n","Iteration 14, loss = 0.14774810\n","Iteration 15, loss = 0.14907437\n","Iteration 16, loss = 0.13192057\n","Iteration 17, loss = 0.13363621\n","Iteration 18, loss = 0.13148596\n","Iteration 19, loss = 0.13224874\n","Iteration 20, loss = 0.14188637\n","Iteration 21, loss = 0.14399165\n","Iteration 22, loss = 0.16307891\n","Iteration 23, loss = 0.15401234\n","Iteration 24, loss = 0.12893232\n","Iteration 25, loss = 0.14900705\n","Iteration 26, loss = 0.15169683\n","Iteration 27, loss = 0.14110614\n","Iteration 28, loss = 0.15711622\n","Iteration 29, loss = 0.14518178\n","Iteration 30, loss = 0.14354777\n","Iteration 31, loss = 0.14011563\n","Iteration 32, loss = 0.15027250\n","Iteration 33, loss = 0.14089328\n","Iteration 34, loss = 0.14262207\n","Iteration 35, loss = 0.13142441\n","Training loss did not improve more than tol=0.001000 for 10 consecutive epochs. Stopping.\n","Experimento 14\n","AcurÃ¡cia MÃ©dia: 86.17%\n","PrecisÃ£o MÃ©dia: 90.38%\n","RevocaÃ§Ã£o MÃ©dia: 87.43%\n","F1-Score MÃ©dio: 86.11%\n"]}],"source":["from sklearn.neural_network import MLPClassifier\n","from sklearn.model_selection import cross_validate\n","\n","\n","x_train = df_scaled.iloc[:, 0:16]\n","y_train = df_scaled.iloc[:, 16]\n","classifier = MLPClassifier(activation='logistic', solver='adam', alpha=1e-5, hidden_layer_sizes=(12, 3), random_state=1, verbose=True, learning_rate_init=0.3, tol=1e-3, max_iter=500)\n","scoring = {'acc' : 'accuracy',\n","           'prec' : 'precision_macro',\n","           'recall' : 'recall_macro',\n","           'f1' : 'f1_macro'}\n","\n","\n","y_pred = cross_validate(classifier, x_train, y_train, cv=10, scoring=scoring, return_train_score=True)\n","print('Experimento 14')\n","print('AcurÃ¡cia MÃ©dia: ' + '%.2f' % (np.mean(y_pred['test_acc'])*100) + '%')\n","print('PrecisÃ£o MÃ©dia: ' + '%.2f' % (np.mean(y_pred['test_prec'])*100) + '%')\n","print('RevocaÃ§Ã£o MÃ©dia: ' + '%.2f' % (np.mean(y_pred['test_recall'])*100) + '%')\n","print('F1-Score MÃ©dio: ' + '%.2f' % (np.mean(y_pred['test_f1'])*100) + '%')\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPmJU6AKQX35TyRMEDUYeud","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":0}
